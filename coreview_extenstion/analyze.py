import sys  
import os
import pandas as pd
import re
import json
import random
from konlpy.tag import Okt
from soynlp.word import WordExtractor
from soynlp.tokenizer import LTokenizer
from krwordrank.sentence import summarize_with_sentences
from krwordrank.word import KRWordRank
from flask import Flask, request, jsonify
from flask_cors import CORS  # CORS ì¶”ê°€

app = Flask(__name__)
CORS(app)  # ì „ì²´ ë„ë©”ì¸ì—ì„œ ìš”ì²­ í—ˆìš©

stopwords_lst = ['ë“±ë¡ëœ', 'ë¦¬ë·°', 'ì¡°ê¸ˆ', 'ìˆ˜', 'ê²ƒ', 'ì—†ìŠµë‹ˆë‹¤', 'ë„ì›€ì´', 'ì •ë§', 'ì‚´ì§', 'ë˜', 'ë„ˆë¬´', 'ì˜', 'ê°™ì•„ìš”', 'ì—„ì²­',  'ë°”ë¡œ', 'í•œ', 'ê³„ì†', 'êµ¬ë§¤', 'ë„£ê³ ', 'ë¨¹ê¸°', 'ìˆì–´ì„œ', 'ë‹¤', 'ë„˜', 'ì €ëŠ”', 'ê·¸ëƒ¥', 'ë§›ì´', 'ì¢‹ì•„ìš”', 
                'ì•„ì£¼', 'íœìŠ¬', 'ì¢€', 'ì¢‹ê³ ', 'ì§„ì§œ', 'ì™„ì „', 'ìˆëŠ”', 'ë•Œ', 'í”„ë¡œíƒ€ì£¼', 'ì´', 'ì¢‹ì•„í•˜ëŠ”', 'ë”', 'ì¢‹ì€', 'ìˆìŠµë‹ˆë‹¤', 'ì…ë‹ˆë‹¤', 
                'ê°™ì•„ìš”', 'ìˆì–´', 'ì¢‹ì€', 'ê°™ìŠµë‹ˆë‹¤', 'ì¢‹ë„¤ìš”', 'ì…ë‹ˆë‹¤', 'ìˆì–´ìš”', 'ê´œì°®', 'ì•„ë‹ˆ', 'ê·¸ëŸ°',
                'ê°™ì•„', 'ì¢‹ìŠµë‹ˆë‹¤', 'ì¢‹ì„', 'ìˆëŠ”ë°', 'ì—†ì–´', 'ì•„ë‹ˆë¼', 'ì¢‹ì€', 'ê°™ì€', 'ì—†ëŠ”', 'ì–´ìš”', 'ì¢‹ì•„', 'ì¢‹ì•—', 'ì…ë‹ˆ', 'ìˆê³ ', 'ì—†ê³ ',
                'ì¢‹ì•˜', 'ì¢‹ìŠµë‹ˆ', 'ìƒê°',  'ìˆì„', 'ìˆìŠµë‹ˆ', 'ìˆì—ˆ', 'ì•„ë‹Œ', 'ê°™ìŠµë‹ˆ', 'ìŠµë‹ˆ', 'ë‹ˆë‹¤', 'ì •ë„', 'ì¿ íŒ¡', 'ì¿ íŒ¡ì²´í—˜ë‹¨', 'ì²´í—˜ë‹¨', 'ìŠ¤ëŸ½', 'ì²´í—˜', 'ì‘ì„±', 'ë¦¬ë·°', 'ì‘ì„±', 'ì´ë²¤íŠ¸']
okt = Okt()

def preprocessing(df, review_column, istokenize=True, pos_tags=None, filter=None):
    #spaceing ê°ì²´ ì •ì˜ ë° ì´ˆê¸°í™”
    # spacing = Spacing()
    processed_reviews  = []
    #ì¸í’‹ë¦¬ë·°
    for idx, r in enumerate(df[review_column]):
        #í•˜ë‚˜ì˜ ë¦¬ë·°ì—ì„œ ë¬¸ì¥ ë‹¨ìœ„ë¡œ ìë¥´ê¸°
        #ë¶ˆí•„ìš”í•œ ì •ë³´ì œê±° nameì˜ ê° ë‹¨ì–´ë¥¼ reviewì—ì„œ ì œê±° 
        # ì´ë¦„ì´ ì£¼ì–´ì¡Œì„ ê²½ìš°ì—ë§Œ ì´ë¦„ ì •ë³´ ì œê±°
        sentence = r

        # #spacing ì ìš© 
        # sentence = sentence.replace(" ", '')
        
        # sentence = spacing(sentence) 

        #íŠ¹ìˆ˜ë¬¸ì, ì˜ì–´ ì•ŒíŒŒë²³, ì´ˆì„±/ì¤‘ì„±/ì¢…ì„±(ì˜ˆ: "ã„±", "ã…" ë“±)ì„ ì œê±°.
        sentence = re.sub('\n','',sentence)
        sentence = re.sub('\u200b','',sentence)
        sentence = re.sub('\xa0','',sentence)
        sentence = re.sub('([a-zA-Z])','',sentence)
        sentence = re.sub('[ã„±-ã…ã…-ã…£]+','',sentence)
        sentence = re.sub('[-=+,#/\?:^$.@*\"â€»~&%ã†!ã€\\â€˜|\(\)\[\]\<\>`\'â€¦ã€‹]','',sentence)
        sentence = re.sub(r'\s+', ' ', sentence)  # ë‹¤ì¤‘ ê³µë°± -> ë‹¨ì¼ ê³µë°±
        sentence = re.sub(r'[^\w\s]', '', sentence)  # íŠ¹ìˆ˜ë¬¸ì ì œê±°
        sentence = re.sub(r'\d+', '', sentence)  # ìˆ«ì ì œê±°
        #ì „ì²˜ë¦¬ í›„ ë¬¸ì¥ì´ ë¹„ì–´ìˆìœ¼ë©´ ë‹¤ìŒ ë¦¬ë·°ë¡œ ë„˜ì–´ê° 
        if len(sentence) == 0:
            continue
        
        # í† í°í™” ì—¬ë¶€ í™•ì¸
        if istokenize:
            tokens = ltokenizer.tokenize(sentence)  # LTokenizerë¥¼ ì´ìš©í•œ í† í°í™”
        else:
            tokens = [sentence]  # í† í°í™”í•˜ì§€ ì•Šê³  ì›ë¬¸ ì‚¬ìš©
        
        # ë¶ˆìš©ì–´ í•„í„°ë§
        if filter:
            tokens = [token for token in tokens if token not in filter]
        # í’ˆì‚¬ í•„í„°ë§
        if pos_tags:
            filtered_tokens = []
            for token in tokens:
                pos = okt.pos(token, norm=True, stem=False)  # í’ˆì‚¬ íƒœê¹…
                filtered_tokens += [word for word, tag in pos if tag in pos_tags]

        else:
            filtered_tokens = []
            for token in tokens:
                pos = okt.pos(token, norm=True, stem=False)  # í’ˆì‚¬ íƒœê¹…
                filtered_tokens += [word for word, tag in pos]


        # ê¸¸ì´ê°€ 1ì¸ ë‹¨ì–´ ì œê±°
        filtered_tokens = [token for token in filtered_tokens if len(token) > 1]

        # í† í°ì„ ê³µë°±ìœ¼ë¡œ ì—°ê²°í•˜ê³  ë§ˆì¹¨í‘œ ì¶”ê°€
        processed_sentence = ' '.join(filtered_tokens)
        processed_reviews.append(processed_sentence)
        
    return pd.Series(processed_reviews)  # ì‹œë¦¬ì¦ˆ í˜•íƒœë¡œ ë°˜í™˜

okt = Okt()
def filter_keywords_by_pos(df, column, pos_tags):
    """
    ë°ì´í„°í”„ë ˆì„ì˜ ì§€ì • ì—´ì—ì„œ ë¦¬ìŠ¤íŠ¸ë¡œ ì €ì¥ëœ í‚¤ì›Œë“œë“¤ì— ëŒ€í•´ íŠ¹ì • í’ˆì‚¬ë§Œ ë‚¨ê¸°ê³ , ë‹¨ì–´ ê¸¸ì´ê°€ 1 ì´í•˜ì¸ ë‹¨ì–´ ì œê±°.

    Args:
        df (pd.DataFrame): ì…ë ¥ ë°ì´í„°í”„ë ˆì„
        column (str): í‚¤ì›Œë“œê°€ ì €ì¥ëœ ì—´ ì´ë¦„
        pos_tags (list[str]): ë‚¨ê¸¸ í’ˆì‚¬ íƒœê·¸ ë¦¬ìŠ¤íŠ¸ (ì˜ˆ: ['Noun', 'Adjective'])

    Returns:
        pd.DataFrame: í’ˆì‚¬ í•„í„°ë§ì´ ì ìš©ëœ ê²°ê³¼
    """
    filtered_results = []
    df = df.copy()

    for keyword_list in df[column]:
        if not isinstance(keyword_list, list):
            filtered_results.append([])
            continue

        filtered_keywords = []
        for keyword in keyword_list:
            # í’ˆì‚¬ íƒœê¹…
            pos = okt.pos(keyword)
            # ì§€ì •í•œ í’ˆì‚¬ë§Œ í•„í„°ë§
            filtered_keywords += [word for word, tag in pos if tag in pos_tags]

        # ë‹¨ì–´ ê¸¸ì´ê°€ 1ì¸ ë‹¨ì–´ ì œê±°
        filtered_keywords = [word for word in filtered_keywords if len(word) > 1]

        # ê²°ê³¼ ì €ì¥
        filtered_results.append(filtered_keywords)

    # ë°ì´í„°í”„ë ˆì„ì— ìƒˆë¡œìš´ ì—´ ì¶”ê°€
    df[f'{column}_filtered'] = filtered_results
    return df

def df_krwordRank(df, review_col, rate_col=None, stopwords=None, top_k=5, num_keywords=10, min_count=1, max_length=50, full_merge=False, rate_merge=False):
    """
    ë°ì´í„°í”„ë ˆì„ì—ì„œ íŠ¹ì • ì—´ì„ ì „ì²˜ë¦¬í•˜ê³  í‚¤ì›Œë“œ ì¶”ì¶œ ê²°ê³¼ë¥¼ ë°ì´í„°í”„ë ˆì„ì— ì €ì¥.

    Parameters:
    - df: pd.DataFrame - ì…ë ¥ ë°ì´í„°í”„ë ˆì„
    - review_col: str - ë¦¬ë·° ë‚´ìš©ì„ í¬í•¨í•˜ëŠ” ì—´ ì´ë¦„
    - rate_col: str - í‰ì  ì—´ì˜ ì´ë¦„ (rate_merge=Trueì¸ ê²½ìš° í•„ìš”)
    - stopwords: list[str] ë¶ˆìš©ì–´ ë¦¬ìŠ¤íŠ¸
    - top_k: int - ê° ë¦¬ë·°ë³„ ìƒìœ„ í‚¤ì›Œë“œ ê°œìˆ˜
    - num_keywords: int - ì¶”ì¶œí•  í‚¤ì›Œë“œ ê°œìˆ˜
    - min_count: int - ë‹¨ì–´ ìµœì†Œ ë“±ì¥ ë¹ˆë„
    - max_length: int - ë‹¨ì–´ ìµœëŒ€ ê¸¸ì´
    - full_merge: bool - Trueì¼ ê²½ìš° ëª¨ë“  ë¦¬ë·°ë¥¼ í•©ì³ì„œ ì²˜ë¦¬
    - rate_merge: bool - Trueì¼ ê²½ìš° í‰ì ë³„ë¡œ ë¦¬ë·°ë¥¼ í•©ì³ì„œ ì²˜ë¦¬

    Returns:
    - result_df: pd.DataFrame - í‚¤ì›Œë“œ ì—´ì´ ì¶”ê°€ëœ ë°ì´í„°í”„ë ˆì„
    """
    if num_keywords < top_k:
        num_keywords = top_k

    def extract_keywords(texts, row=None):
        if not texts or len(' '.join(texts).strip()) == 0:  # í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆê±°ë‚˜ ê³µë°±ë§Œ í¬í•¨ëœ ê²½ìš°
            print("ì…ë ¥ í…ìŠ¤íŠ¸ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            return None
        
        # KRWordRank ëª¨ë¸ ì´ˆê¸°í™”
        krwordrank = KRWordRank(
            min_count=min_count,
            max_length=max_length,
            verbose=True
        )
        
        try:
            result = krwordrank.extract(
                texts, 
                beta=0.85, 
                max_iter=50, 
                num_keywords=num_keywords
            )
            keywords = result[0]

            if keywords is None:
                print("í‚¤ì›Œë“œ ì¶”ì¶œ ì‹¤íŒ¨: ê²°ê³¼ê°€ Noneì…ë‹ˆë‹¤.")
                return None
            
            top_keywords = sorted(keywords.items(), key=lambda x: x[1], reverse=True)[:top_k]
            return [word for word, _ in top_keywords]
        
        except Exception as e:
            print(str(row) + " error occurs:")
            print(e)
            return None

    if full_merge:
        # ëª¨ë“  ë¦¬ë·°ë¥¼ í•˜ë‚˜ë¡œ í•©ì³ ì²˜ë¦¬
        merged_reviews = '. '.join(df[review_col].dropna())
        
        # ë¶ˆìš©ì–´ ì œê±°
        if stopwords:
            for word in stopwords:
                merged_reviews = merged_reviews.replace(word, '')
        
        texts = merged_reviews.split('. ')
        keywords = extract_keywords(texts)
        result_df = pd.DataFrame({'merge_type': ['full'], 'keywords': [keywords]})
        return result_df

    if rate_merge:
        # í‰ì ë³„ë¡œ ë¦¬ë·°ë¥¼ í•©ì³ ì²˜ë¦¬
        if rate_col is None:
            raise ValueError("rate_merge=True ì¸ ê²½ìš°, rate_colì„ ì§€ì •í•´ì•¼ í•©ë‹ˆë‹¤.")
        
        rate_keywords = []
        for rate, group in df.groupby(rate_col):
            merged_reviews = '. '.join(group[review_col].dropna())
            
            # ë¶ˆìš©ì–´ ì œê±°
            if stopwords:
                for word in stopwords:
                    merged_reviews = merged_reviews.replace(word, '')
            
            texts = merged_reviews.split('. ')
            keywords = extract_keywords(texts)
            rate_keywords.append({'rate': rate, 'keywords': keywords})
        
        result_df = pd.DataFrame(rate_keywords)
        return result_df
    
    else:
        # ê¸°ë³¸: ê° ë¦¬ë·°ë³„ ì²˜ë¦¬
        krwordrank_results = []
        for idx, row in df.iterrows():
            review_content = row[review_col]

            if pd.isna(review_content):
                krwordrank_results.append(None)
                continue
            
            # ë¶ˆìš©ì–´ ì œê±°
            if stopwords:
                for word in stopwords:
                    review_content = review_content.replace(word, '')
            
            # ë¬¸ì¥ ë¦¬ìŠ¤íŠ¸
            texts = review_content.split('. ')
            keywords = extract_keywords(texts, row=idx)
            krwordrank_results.append(keywords)

        # ìƒˆë¡œìš´ ì—´ ì¶”ê°€
        df['krwordrank'] = krwordrank_results
        return df
    

def calculate_keyword_average_ratings(df, keyword_lists, review_column, rating_column):
    keyword_scores = {}
    
    for keyword_list in keyword_lists:
        if isinstance(keyword_list, list):  # ë¦¬ìŠ¤íŠ¸ì¸ì§€ í™•ì¸
            for keyword in keyword_list:
                if isinstance(keyword, str) and len(keyword) > 0:  # ë¹ˆ ë¬¸ìì—´ ë°©ì§€
                    mask = df[review_column].str.contains(keyword, na=False)
                    avg_score = df.loc[mask, rating_column].astype(float).mean()
                    keyword_scores[keyword] = avg_score

    return keyword_scores


def filter_sentences(df, keywords, min_length=1, max_length=50000, num_samples=3):
    def get_sentences_with_keyword(review, keywords):
        sentences = re.split(r'(?<!\w\.\w.)(?<![A-Z][a-z]\.)(?<=\.|\?|\!|\-)\s', review)
        return [sentence for sentence in sentences if any(keyword in sentence for keyword in keywords)]
    
    df["filtered_sentences"] = df["reviewContent"].apply(lambda x: get_sentences_with_keyword(str(x), keywords))
    filtered_sentences = [sentence for sentences in df["filtered_sentences"].dropna() for sentence in sentences if min_length <= len(sentence) <= max_length]

    return random.sample(filtered_sentences, min(num_samples, len(filtered_sentences))) if filtered_sentences else []

def save_dict_to_json(dictionary, file_path):
    with open(file_path, 'w', encoding='utf-8-sig') as json_file:
        json.dump(dictionary, json_file, ensure_ascii=False, indent=4)

def calculate_keyword_statistics(df, keyword_lists, review_column, rating_column):
    keyword_stats = {}

    for keyword_list in keyword_lists:
        if isinstance(keyword_list, list):  # ë¦¬ìŠ¤íŠ¸ì¸ì§€ í™•ì¸
            for keyword in keyword_list:
                if isinstance(keyword, str) and len(keyword) > 0:  # ë¹ˆ ë¬¸ìì—´ ë°©ì§€
                    mask = df[review_column].str.contains(keyword, na=False)
                    matched_reviews = df.loc[mask, rating_column].astype(float)

                    avg_score = matched_reviews.mean()
                    count = matched_reviews.count()

                    keyword_stats[keyword] = {
                        "rating": round(avg_score, 2) if not pd.isna(avg_score) else None,
                        "count": int(count)
                    }

    return keyword_stats


@app.route('/analyze', methods=['POST'])
def analyze_reviews():
    """í¬ë¡¬ ìµìŠ¤í…ì…˜ì—ì„œ ë°›ì€ ë¦¬ë·° ë°ì´í„°ë¥¼ ë¶„ì„í•˜ëŠ” API"""
    data = request.json
    reviews = data.get("reviews", [])

    if not reviews:
        return jsonify({"error": "ë¦¬ë·° ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."}), 400

    df = pd.DataFrame(reviews)

    # ë¶ˆí•„ìš”í•œ ë¦¬ë·° ì œê±° ë° ì •ì œ
    df = df[df["reviewContent"] != "ë“±ë¡ëœ ë¦¬ë·° ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤"]
    df["reviewContent"] = df["reviewContent"].str.replace("ì¿ íŒ¡ì²´í—˜ë‹¨ ì´ë²¤íŠ¸ë¡œ ìƒí’ˆì„ ë¬´ë£Œ ì œê³µë°›ì•„ ì‘ì„±í•œ ë¦¬ë·°ì…ë‹ˆë‹¤.", "", regex=False)
    df["reviewContent"] = df["reviewContent"].str.replace(r'[-=_ã…¡â€”ã…‹]{3,}', "", regex=True)
    df["reviewContent"] = df["reviewContent"].str.replace("\n", "", regex=False)

    # soynlpì˜ WordExtractorë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹¨ì–´ ì ìˆ˜ ê³„ì‚°
    word_extractor = WordExtractor()
    word_extractor.train(df['reviewContent'].tolist())
    scores = {word: score.cohesion_forward for word, score in word_extractor.extract().items()}

    global ltokenizer
    ltokenizer = LTokenizer(scores=scores)

    # ë¦¬ë·° í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ ìˆ˜í–‰
    df['preprocessed_review'] = df["reviewContent"].apply(lambda x: ' '.join([word for word in okt.nouns(x) if word not in stopwords_lst]))

    # KRWordRankë¥¼ ì‚¬ìš©í•˜ì—¬ í‚¤ì›Œë“œ ì¶”ì¶œ
    full_merge_df = df_krwordRank(df, review_col='preprocessed_review', stopwords=stopwords_lst, top_k=150, full_merge=True)

    ### ğŸ”¹ ëª…ì‚¬(Noun) í‚¤ì›Œë“œ ì¶”ì¶œ ###
    pos_tags_noun = ['Noun', 'Pronoun']
    df_noun = filter_keywords_by_pos(full_merge_df, column='keywords', pos_tags=pos_tags_noun)
    
    print("\n=== Noun Keywords ===")
    print(df_noun['keywords_filtered'].head(10))  # ì˜¬ë°”ë¥´ê²Œ í•„í„°ë§ë˜ì—ˆëŠ”ì§€ í™•ì¸
    
    # ëª…ì‚¬ í‚¤ì›Œë“œë³„ í†µê³„ ê³„ì‚°
    keyword_stats_noun = calculate_keyword_statistics(df, df_noun['keywords_filtered'].tolist(), 'reviewContent', 'rating')

    # ğŸ”¹ **ìƒìœ„ 10ê°œ ëª…ì‚¬ í‚¤ì›Œë“œ ì„ íƒ + ì˜ˆì œ ë¬¸ì¥ í¬í•¨**
    noun_result = {
        keyword: {
            "rating": keyword_stats_noun[keyword]["rating"],
            "count": keyword_stats_noun[keyword]["count"],
            "examples": filter_sentences(df, [keyword], min_length=1, max_length=8000, num_samples=3)
        }
        for keyword in list(keyword_stats_noun.keys())[:10]  # ìƒìœ„ 10ê°œë§Œ ì„ íƒ
    }

    ### ğŸ”¹ í˜•ìš©ì‚¬(Adjective) í‚¤ì›Œë“œ ì¶”ì¶œ ###
    pos_tags_adj = ['Adjective']
    df_adj = filter_keywords_by_pos(full_merge_df, column='keywords', pos_tags=pos_tags_adj)
    
    print("\n=== Adjective Keywords ===")
    print(df_adj['keywords_filtered'].head(10))  # ì˜¬ë°”ë¥´ê²Œ í•„í„°ë§ë˜ì—ˆëŠ”ì§€ í™•ì¸

    # í˜•ìš©ì‚¬ í‚¤ì›Œë“œë³„ í†µê³„ ê³„ì‚°
    keyword_stats_adj = calculate_keyword_statistics(df, df_adj['keywords_filtered'].tolist(), 'reviewContent', 'rating')

    # ğŸ”¹ **ìƒìœ„ 10ê°œ í˜•ìš©ì‚¬ í‚¤ì›Œë“œ ì„ íƒ + ì˜ˆì œ ë¬¸ì¥ í¬í•¨**
    adj_result = {
        keyword: {
            "rating": keyword_stats_adj[keyword]["rating"],
            "count": keyword_stats_adj[keyword]["count"],
            "examples": filter_sentences(df, [keyword], min_length=1, max_length=8000, num_samples=3)
        }
        for keyword in list(keyword_stats_adj.keys())[:10]  # ìƒìœ„ 10ê°œë§Œ ì„ íƒ
    }

    return jsonify({"nouns": noun_result, "adjectives": adj_result})

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=8000, debug=True)