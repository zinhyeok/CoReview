{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>이름</th>\n",
       "      <th>작성일자</th>\n",
       "      <th>평점</th>\n",
       "      <th>리뷰 내용</th>\n",
       "      <th>맛 만족도</th>\n",
       "      <th>preprocessed_review</th>\n",
       "      <th>krwordrank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>박*혜</td>\n",
       "      <td>2025.01.14</td>\n",
       "      <td>5</td>\n",
       "      <td>짜파게티 마라, 어떤 제품일까?먼저 짜파게티 마라의 기본 정보를 알아보았어요. 이 ...</td>\n",
       "      <td>아주 넉넉해요</td>\n",
       "      <td>짜파게티 마라 어떤 제품 일까먼저 짜파게티 마라 기본 정보를 알아보았어요 제품 유명...</td>\n",
       "      <td>['마라']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dimss</td>\n",
       "      <td>2025.01.13</td>\n",
       "      <td>4</td>\n",
       "      <td>안녕하세요!! 리뷰하는 dimss입니다^^오늘도 솔직 사용후기 들고 왔어요❤️⬇️⬇...</td>\n",
       "      <td>적당히 남았어요</td>\n",
       "      <td>안녕하세요 리뷰 하는 입니다 오늘도 솔직 사용후기 들고 왔어요짜파게티 마라 솔직 후...</td>\n",
       "      <td>['마라', '분들', '짜파']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>이*람</td>\n",
       "      <td>2025.01.12</td>\n",
       "      <td>5</td>\n",
       "      <td>### 구매 계기매운 음식을 좋아하는 저는 최근 마라탕이나 마라샹궈와 같은 마라 요...</td>\n",
       "      <td>적당히 남았어요</td>\n",
       "      <td>구매 계기매운 음식 좋아 하는 저는 최근 마라 탕이나 마라 샹궈와 같은 마라 요리 ...</td>\n",
       "      <td>['마라', '매운', '맛이', '정말', '국물']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>시마에나가</td>\n",
       "      <td>2025.01.11</td>\n",
       "      <td>4</td>\n",
       "      <td>⏹️ 요약 ⏹️✅ 구성 - 면, 후레이크, 짜장스프, 마라조미유✅ 맛 - 맵찔이 먹...</td>\n",
       "      <td>적당히 남았어요</td>\n",
       "      <td>요약 구성 후레이크 짜장스프 마라 조미유 맵찔이 먹으면 안됨 그냥 매운 마라 구매 ...</td>\n",
       "      <td>['마라', '넣고', '짜파', '먹어']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>김*수</td>\n",
       "      <td>2025.01.11</td>\n",
       "      <td>5</td>\n",
       "      <td>짜파게티 마라를 구매한 후기를 이모티콘을 활용하여 작성해 보겠습니다. 아래와 같은 ...</td>\n",
       "      <td>아주 넉넉해요</td>\n",
       "      <td>짜파게티 마라 구매 후기 이모티콘을 활용 하여 작성해 보겠습니다 아래와 같은 방식 ...</td>\n",
       "      <td>['마라', '매운', '맛이']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>잔잔다에</td>\n",
       "      <td>2025.01.01</td>\n",
       "      <td>1</td>\n",
       "      <td>처음 입에 넣을 때 거부감 드는 향과 뒤에 매운 맛만 느껴짐참고서라도 먹고싶지 않은 맛</td>\n",
       "      <td>맛 평가 없음</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>코만도x</td>\n",
       "      <td>2025.01.10</td>\n",
       "      <td>1</td>\n",
       "      <td>맛과 어울리지도 않게 맵기만함고급스러운 매운맛이 아니고 싼매운맛. 유통기한 끝나가는...</td>\n",
       "      <td>적당히 남았어요</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>sssgg</td>\n",
       "      <td>2025.01.04</td>\n",
       "      <td>1</td>\n",
       "      <td>마라향이 뭔가 조화롭지않아서 좀 인위적인?느낌의 향만나고우선 진짜 너무 맵기만해요</td>\n",
       "      <td>적당히 남았어요</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>쿠리사</td>\n",
       "      <td>2025.01.13</td>\n",
       "      <td>1</td>\n",
       "      <td>짜파게티도 맛있고 블랙도 맛있는데이건 영.....마라향이 확 나는게 아니라서 이상함...</td>\n",
       "      <td>아주 넉넉해요</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>rtrtrt</td>\n",
       "      <td>2025.01.07</td>\n",
       "      <td>1</td>\n",
       "      <td>마라의 얼얼함이 아니라 그냥 캡사이신의 매움입니다;</td>\n",
       "      <td>아주 넉넉해요</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>264 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         이름        작성일자  평점  \\\n",
       "0       박*혜  2025.01.14   5   \n",
       "1     dimss  2025.01.13   4   \n",
       "2       이*람  2025.01.12   5   \n",
       "3     시마에나가  2025.01.11   4   \n",
       "4       김*수  2025.01.11   5   \n",
       "..      ...         ...  ..   \n",
       "259    잔잔다에  2025.01.01   1   \n",
       "260    코만도x  2025.01.10   1   \n",
       "261   sssgg  2025.01.04   1   \n",
       "262     쿠리사  2025.01.13   1   \n",
       "263  rtrtrt  2025.01.07   1   \n",
       "\n",
       "                                                 리뷰 내용     맛 만족도  \\\n",
       "0    짜파게티 마라, 어떤 제품일까?먼저 짜파게티 마라의 기본 정보를 알아보았어요. 이 ...   아주 넉넉해요   \n",
       "1    안녕하세요!! 리뷰하는 dimss입니다^^오늘도 솔직 사용후기 들고 왔어요❤️⬇️⬇...  적당히 남았어요   \n",
       "2    ### 구매 계기매운 음식을 좋아하는 저는 최근 마라탕이나 마라샹궈와 같은 마라 요...  적당히 남았어요   \n",
       "3    ⏹️ 요약 ⏹️✅ 구성 - 면, 후레이크, 짜장스프, 마라조미유✅ 맛 - 맵찔이 먹...  적당히 남았어요   \n",
       "4    짜파게티 마라를 구매한 후기를 이모티콘을 활용하여 작성해 보겠습니다. 아래와 같은 ...   아주 넉넉해요   \n",
       "..                                                 ...       ...   \n",
       "259   처음 입에 넣을 때 거부감 드는 향과 뒤에 매운 맛만 느껴짐참고서라도 먹고싶지 않은 맛   맛 평가 없음   \n",
       "260  맛과 어울리지도 않게 맵기만함고급스러운 매운맛이 아니고 싼매운맛. 유통기한 끝나가는...  적당히 남았어요   \n",
       "261      마라향이 뭔가 조화롭지않아서 좀 인위적인?느낌의 향만나고우선 진짜 너무 맵기만해요  적당히 남았어요   \n",
       "262  짜파게티도 맛있고 블랙도 맛있는데이건 영.....마라향이 확 나는게 아니라서 이상함...   아주 넉넉해요   \n",
       "263                       마라의 얼얼함이 아니라 그냥 캡사이신의 매움입니다;   아주 넉넉해요   \n",
       "\n",
       "                                   preprocessed_review  \\\n",
       "0    짜파게티 마라 어떤 제품 일까먼저 짜파게티 마라 기본 정보를 알아보았어요 제품 유명...   \n",
       "1    안녕하세요 리뷰 하는 입니다 오늘도 솔직 사용후기 들고 왔어요짜파게티 마라 솔직 후...   \n",
       "2    구매 계기매운 음식 좋아 하는 저는 최근 마라 탕이나 마라 샹궈와 같은 마라 요리 ...   \n",
       "3    요약 구성 후레이크 짜장스프 마라 조미유 맵찔이 먹으면 안됨 그냥 매운 마라 구매 ...   \n",
       "4    짜파게티 마라 구매 후기 이모티콘을 활용 하여 작성해 보겠습니다 아래와 같은 방식 ...   \n",
       "..                                                 ...   \n",
       "259                                                NaN   \n",
       "260                                                NaN   \n",
       "261                                                NaN   \n",
       "262                                                NaN   \n",
       "263                                                NaN   \n",
       "\n",
       "                         krwordrank  \n",
       "0                            ['마라']  \n",
       "1                ['마라', '분들', '짜파']  \n",
       "2    ['마라', '매운', '맛이', '정말', '국물']  \n",
       "3          ['마라', '넣고', '짜파', '먹어']  \n",
       "4                ['마라', '매운', '맛이']  \n",
       "..                              ...  \n",
       "259                             NaN  \n",
       "260                             NaN  \n",
       "261                             NaN  \n",
       "262                             NaN  \n",
       "263                             NaN  \n",
       "\n",
       "[264 rows x 7 columns]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"/Users/iyeeun/Documents/coreview_3/data/df_sumWordSentence.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      평점                                            summary\n",
      "0      5             최애라면인 짜파게티에 마라가있다고하더라구요마라탕도좋아하는데 최애라면인\n",
      "1      4       2025.12.27일유통기한:2025.06.19일 기본짜파게티의 고소하고풍미있는\n",
      "2      3               ᄏᄏᄏ짜파게티에 대해 영향을줄 알았음 ᄏᄏᄏ짜파게티에 직접예약주문\n",
      "3      2  짜파게티와 마라 냄새가 어우러지지 않으면 짜파게티와 마라 냄새가 생각보다 맵다고 마라볶음\n",
      "4      1               마라샹궈에 굳이 양파도볶아서넣구 했는뎅뎅..마라탕이 짜찝찝한 매움\n",
      "5  Final     2025.12.27일유통기한:2025.12.27일유통기한:2025.06.19일 기본\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from transformers import PreTrainedTokenizerFast, BartForConditionalGeneration\n",
    "\n",
    "# Load tokenizer and model for summarization\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained('digit82/kobart-summarization')\n",
    "model = BartForConditionalGeneration.from_pretrained('digit82/kobart-summarization')\n",
    "\n",
    "\n",
    "# Function to generate n-grams from a text\n",
    "def generate_ngrams(text, n=3):\n",
    "    if pd.isna(text):\n",
    "        return []\n",
    "    words = text.split()\n",
    "    ngrams = [' '.join(words[i:i+n]) for i in range(len(words) - n + 1)]\n",
    "    return ngrams\n",
    "\n",
    "# Function to extract n-grams containing a specific keyword\n",
    "def extract_ngrams_with_keyword(data, keyword, review_column='preprocessed_review', n=3):\n",
    "    # Generate n-grams for each review\n",
    "    data['ngrams'] = data[review_column].apply(lambda x: generate_ngrams(x, n))\n",
    "    \n",
    "    # Filter n-grams containing the keyword\n",
    "    data['filtered_ngrams'] = data['ngrams'].apply(lambda ngrams: [ngram for ngram in ngrams if keyword in ngram])\n",
    "    return data\n",
    "\n",
    "# Function to preprocess text before summarization\n",
    "def preprocess_text(text):\n",
    "    # Remove duplicate words and limit excessive repetition\n",
    "    words = text.split()\n",
    "    deduplicated = []\n",
    "    for word in words:\n",
    "        if len(deduplicated) < 2 or deduplicated[-2:] != [word, word]:\n",
    "            deduplicated.append(word)\n",
    "    return ' '.join(deduplicated)\n",
    "\n",
    "# Function to summarize text using KoBART\n",
    "def summarize_text_kobart(text, max_length=50, min_length=30):\n",
    "    if not text or len(text.strip()) == 0:\n",
    "        return None\n",
    "    # Preprocess text to remove duplicates\n",
    "    text = preprocess_text(text)\n",
    "    inputs = tokenizer.encode(text, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "    summary_ids = model.generate(\n",
    "        inputs,\n",
    "        max_length=max_length,\n",
    "        min_length=min_length,\n",
    "        length_penalty=1.0,\n",
    "        num_beams=4,\n",
    "        repetition_penalty=4.0,  # Higher penalty for repetitive outputs\n",
    "        early_stopping=True\n",
    "    )\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary\n",
    "\n",
    "# Main function to process and summarize the dataset\n",
    "def process_and_summarize(df, keyword, n=5, samples_per_rating=3):\n",
    "    # Extract n-grams with keyword\n",
    "    df = extract_ngrams_with_keyword(df, keyword, review_column='리뷰 내용', n=n)\n",
    "\n",
    "    # Create a new DataFrame to store results\n",
    "    intermediate_results = []\n",
    "\n",
    "    # Process each rating\n",
    "    for rating in sorted(df['평점'].unique(), reverse=True):\n",
    "        rating_df = df[df['평점'] == rating]\n",
    "        all_ngrams = [ngram for ngrams in rating_df['filtered_ngrams'] for ngram in ngrams if ngram.strip() != \"\"]\n",
    "\n",
    "        if not all_ngrams:  # Skip if no valid n-grams are found\n",
    "            continue\n",
    "\n",
    "        # Select the longest n-grams\n",
    "        longest_ngrams = sorted(all_ngrams, key=len, reverse=True)[:samples_per_rating]\n",
    "\n",
    "        # Summarize each longest n-gram\n",
    "        summarized_ngrams = [summarize_text_kobart(ngram) for ngram in longest_ngrams]\n",
    "\n",
    "        # Combine the summarized n-grams into one text\n",
    "        combined_text = ' '.join(summarized_ngrams)\n",
    "\n",
    "        # Summarize the combined text\n",
    "        summary = summarize_text_kobart(combined_text, max_length=30, min_length=10)\n",
    "\n",
    "        # Store intermediate results\n",
    "        intermediate_results.append({\n",
    "            '평점': rating,\n",
    "            'summary': summary\n",
    "        })\n",
    "\n",
    "    # Create a final summary combining all summaries\n",
    "    combined_summaries = ' '.join([result['summary'] for result in intermediate_results if result['summary']])\n",
    "    final_summary = summarize_text_kobart(combined_summaries, max_length=30, min_length=10)\n",
    "\n",
    "    # Append the final summary to the results\n",
    "    intermediate_results.append({\n",
    "        '평점': 'Final',\n",
    "        'summary': final_summary\n",
    "    })\n",
    "\n",
    "    return pd.DataFrame(intermediate_results)\n",
    "\n",
    "# Example usage\n",
    "keyword = '짜파'\n",
    "result_df = process_and_summarize(df, keyword)\n",
    "print(result_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2025.12.27일유통기한:2025.12.27일유통기한:2025.06.19일 기본'"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df['summary'][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'apply'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[174], line 124\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mDataFrame(intermediate_results)\n\u001b[1;32m    123\u001b[0m keyword \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m짜파\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 124\u001b[0m result_df \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_and_summarize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeyword\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28mprint\u001b[39m(result_df)\n",
      "Cell \u001b[0;32mIn[174], line 80\u001b[0m, in \u001b[0;36mprocess_and_summarize\u001b[0;34m(df, keyword, n, samples_per_rating)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_and_summarize\u001b[39m(df, keyword, n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, samples_per_rating\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m):\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;66;03m# Generate n-grams for each review\u001b[39;00m\n\u001b[0;32m---> 80\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mngrams\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m리뷰 내용\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mextract_ngrams_with_keyword\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeyword\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;66;03m# Create a new DataFrame to store results\u001b[39;00m\n\u001b[1;32m     83\u001b[0m     intermediate_results \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/coreview/lib/python3.10/site-packages/pandas/core/series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4800\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4918\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4922\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m-> 4924\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/coreview/lib/python3.10/site-packages/pandas/core/apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/coreview/lib/python3.10/site-packages/pandas/core/apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[1;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/coreview/lib/python3.10/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/coreview/lib/python3.10/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[174], line 80\u001b[0m, in \u001b[0;36mprocess_and_summarize.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_and_summarize\u001b[39m(df, keyword, n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, samples_per_rating\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m):\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;66;03m# Generate n-grams for each review\u001b[39;00m\n\u001b[0;32m---> 80\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mngrams\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m리뷰 내용\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mextract_ngrams_with_keyword\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeyword\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;66;03m# Create a new DataFrame to store results\u001b[39;00m\n\u001b[1;32m     83\u001b[0m     intermediate_results \u001b[38;5;241m=\u001b[39m []\n",
      "Cell \u001b[0;32mIn[174], line 21\u001b[0m, in \u001b[0;36mextract_ngrams_with_keyword\u001b[0;34m(data, keyword, review_column, n)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_ngrams_with_keyword\u001b[39m(data, keyword, review_column\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreprocessed_review\u001b[39m\u001b[38;5;124m'\u001b[39m, n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m):\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;66;03m# Generate n-grams for each review\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m     data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mngrams\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mreview_column\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m(\u001b[38;5;28;01mlambda\u001b[39;00m x: generate_ngrams(x, n))\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;66;03m# Filter n-grams containing the keyword\u001b[39;00m\n\u001b[1;32m     24\u001b[0m     data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfiltered_ngrams\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mngrams\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m ngrams: [ngram \u001b[38;5;28;01mfor\u001b[39;00m ngram \u001b[38;5;129;01min\u001b[39;00m ngrams \u001b[38;5;28;01mif\u001b[39;00m keyword \u001b[38;5;129;01min\u001b[39;00m ngram])\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'apply'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from transformers import PreTrainedTokenizerFast, BartForConditionalGeneration\n",
    "\n",
    "# Load tokenizer and model for summarization\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained('digit82/kobart-summarization')\n",
    "model = BartForConditionalGeneration.from_pretrained('digit82/kobart-summarization')\n",
    "\n",
    "# Function to generate n-grams around a keyword\n",
    "def generate_ngrams_around_keyword(text, keyword, n=3):\n",
    "    if pd.isna(text):\n",
    "        return []\n",
    "    words = text.split()\n",
    "    ngrams = []\n",
    "    for i, word in enumerate(words):\n",
    "        if keyword in word:\n",
    "            start_idx = max(0, i - n // 2)\n",
    "            end_idx = min(len(words), i + n // 2 + 1)\n",
    "            ngrams.append(\" \".join(words[start_idx:end_idx]))\n",
    "    return ngrams\n",
    "\n",
    "\n",
    "# Function to generate n-grams from a text\n",
    "def generate_ngrams(text, n=3):\n",
    "    if pd.isna(text):\n",
    "        return []\n",
    "    words = text.split()\n",
    "    ngrams = [' '.join(words[i:i+n]) for i in range(len(words) - n + 1)]\n",
    "    return ngrams\n",
    "\n",
    "# Function to extract n-grams containing a specific keyword\n",
    "def extract_ngrams_with_keyword(data, keyword, review_column='preprocessed_review', n=3):\n",
    "    # Generate n-grams for each review\n",
    "    data['ngrams'] = data[review_column].apply(lambda x: generate_ngrams(x, n))\n",
    "    \n",
    "    # Filter n-grams containing the keyword\n",
    "    data['filtered_ngrams'] = data['ngrams'].apply(lambda ngrams: [ngram for ngram in ngrams if keyword in ngram])\n",
    "    \n",
    "    # Select relevant columns for output\n",
    "    result = data[[review_column, 'filtered_ngrams']]\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "# Function to summarize text using KoBART\n",
    "def summarize_text_kobart(text, max_length=50, min_length=30):\n",
    "    if not text or len(text.strip()) == 0:\n",
    "        return None\n",
    "    inputs = tokenizer.encode(text, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "    summary_ids = model.generate(\n",
    "        inputs,\n",
    "        max_length=max_length,\n",
    "        min_length=min_length,\n",
    "        length_penalty=3.0,\n",
    "        num_beams=4,\n",
    "        repetition_penalty=2.0,\n",
    "        early_stopping=True\n",
    "    )\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary\n",
    "# Function to preprocess text before summarization\n",
    "def preprocess_text(text):\n",
    "    # Remove duplicate words and limit excessive repetition\n",
    "    words = text.split()\n",
    "    deduplicated = []\n",
    "    for word in words:\n",
    "        if len(deduplicated) < 2 or deduplicated[-2:] != [word, word]:\n",
    "            deduplicated.append(word)\n",
    "    return ' '.join(deduplicated)\n",
    "\n",
    "# Updated function to summarize text using KoBART\n",
    "def summarize_text_kobart(text, max_length=50, min_length=30):\n",
    "    if not text or len(text.strip()) == 0:\n",
    "        return None\n",
    "    # Preprocess text to remove duplicates\n",
    "    text = preprocess_text(text)\n",
    "    inputs = tokenizer.encode(text, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "    summary_ids = model.generate(\n",
    "        inputs,\n",
    "        max_length=max_length,\n",
    "        min_length=min_length,\n",
    "        length_penalty=1.0,\n",
    "        num_beams=4,\n",
    "        repetition_penalty=4.0,  # Higher penalty for repetitive outputs\n",
    "        early_stopping=True\n",
    "    )\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary\n",
    "\n",
    "# Main function to process and summarize the dataset\n",
    "def process_and_summarize(df, keyword, n=5, samples_per_rating=3):\n",
    "    # Generate n-grams for each review\n",
    "    df['ngrams'] = df['리뷰 내용'].apply(lambda x: extract_ngrams_with_keyword(x, keyword, n))\n",
    "\n",
    "    # Create a new DataFrame to store results\n",
    "    intermediate_results = []\n",
    "\n",
    "    # Process each rating\n",
    "    for rating in sorted(df['평점'].unique(), reverse=True):\n",
    "        rating_df = df[df['평점'] == rating]\n",
    "        all_ngrams = [ngram for ngrams in rating_df['ngrams'] for ngram in ngrams if ngram.strip() != \"\"]\n",
    "\n",
    "        if not all_ngrams:  # Skip if no valid n-grams are found\n",
    "            continue\n",
    "\n",
    "        # Select the longest n-grams\n",
    "        longest_ngrams = sorted(all_ngrams, key=len, reverse=True)[:samples_per_rating]\n",
    "\n",
    "        # Summarize each longest n-gram\n",
    "        summarized_ngrams = [summarize_text_kobart(ngram) for ngram in longest_ngrams]\n",
    "\n",
    "        # Combine the summarized n-grams into one text\n",
    "        combined_text = ' '.join(summarized_ngrams)\n",
    "\n",
    "        # Summarize the combined text\n",
    "        summary = summarize_text_kobart(combined_text, max_length=30, min_length=10)\n",
    "\n",
    "        # Store intermediate results\n",
    "        intermediate_results.append({\n",
    "            '평점': rating,\n",
    "            'summary': summary\n",
    "        })\n",
    "\n",
    "    # Create a final summary combining all summaries\n",
    "    combined_summaries = ' '.join([result['summary'] for result in intermediate_results if result['summary']])\n",
    "    final_summary = summarize_text_kobart(combined_summaries, max_length=30, min_length=10)\n",
    "\n",
    "    # Append the final summary to the results\n",
    "    intermediate_results.append({\n",
    "        '평점': 'Final',\n",
    "        'summary': final_summary\n",
    "    })\n",
    "\n",
    "    return pd.DataFrame(intermediate_results)\n",
    "\n",
    "keyword = '짜파'\n",
    "result_df = process_and_summarize(df, keyword)\n",
    "print(result_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2025.06.19일쿠팡에서 짜장라면을 짜파파파파파파파파파파파파파'"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df['summary'][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "짜파게티 마라는 중국 사천 지역의 매운맛과 향신료가 가미된 스타일로 짜파게티 마라를 조리하는 방법은 다른 즉석면과 크게 다르지 않아요\n"
     ]
    }
   ],
   "source": [
    "def summarize_text_kobart(text, max_length=30, min_length=30):\n",
    "    if not text or len(text.strip()) == 0:\n",
    "        return None\n",
    "    inputs = tokenizer.encode(text, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "    summary_ids = model.generate(\n",
    "        inputs,\n",
    "        max_length=max_length,\n",
    "        min_length=min_length,\n",
    "        length_penalty=2.0,\n",
    "        num_beams=4,\n",
    "        repetition_penalty=2.0,\n",
    "        early_stopping=True\n",
    "    )\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary\n",
    "\n",
    "print(summarize_text_kobart(result_df['mara_sentences'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Keyword</th>\n",
       "      <th>Average Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>마라</td>\n",
       "      <td>4.570048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>짜파게티</td>\n",
       "      <td>4.619048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>매운</td>\n",
       "      <td>4.698276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Keyword  Average Rating\n",
       "0      마라        4.570048\n",
       "1    짜파게티        4.619048\n",
       "2      매운        4.698276"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def calculate_keyword_average_ratings(dataframe, keywords, review_column, rating_column):\n",
    "    keyword_scores = {}\n",
    "    for keyword in keywords:\n",
    "        # Filter reviews that contain the keyword\n",
    "        keyword_reviews = dataframe[dataframe[review_column].str.contains(keyword, na=False)]\n",
    "        # Calculate the average rating\n",
    "        avg_score = keyword_reviews[rating_column].mean()\n",
    "        keyword_scores[keyword] = avg_score\n",
    "\n",
    "    # Convert the results to a DataFrame\n",
    "    result_df = pd.DataFrame(list(keyword_scores.items()), columns=['Keyword', 'Average Rating'])\n",
    "    return result_df\n",
    "\n",
    "\n",
    "keywords = ['마라', '짜파게티', '매운']  # keywordrank로 뽑아낸 k개 단어들의 리스트\n",
    "result_df = calculate_keyword_average_ratings(df, keywords, 'preprocessed_review', '평점')\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preprocessed_review</th>\n",
       "      <th>keyword_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>짜파게티 마라 내돈내산으로 솔직 후기 입니다평소에 마라 탕을 엄청 좋아 하는 사람 ...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>구매 이유 평소 짜파게티 즐겨 먹는데 최근 새로운 맛이 출시 되었다는 소식 듣고 궁...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>마라 짜파게티 출시 됐다고 해서 쿠팡 에서 구입했 습니다사전 예약 구매 가능하다는 ...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>구입 상품 짜파게티 마라 개원래 농심 짜파게티 사천짜파게티 즐겨 먹습니다 최근 에는...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>농심 마라 짜파게티 개입 구입 후기에요일요일엔 내가 짜파게티 요리 사짜짜짜짜짜짜파게...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 preprocessed_review  keyword_count\n",
       "0  짜파게티 마라 내돈내산으로 솔직 후기 입니다평소에 마라 탕을 엄청 좋아 하는 사람 ...             16\n",
       "1  구매 이유 평소 짜파게티 즐겨 먹는데 최근 새로운 맛이 출시 되었다는 소식 듣고 궁...             15\n",
       "2  마라 짜파게티 출시 됐다고 해서 쿠팡 에서 구입했 습니다사전 예약 구매 가능하다는 ...             14\n",
       "3  구입 상품 짜파게티 마라 개원래 농심 짜파게티 사천짜파게티 즐겨 먹습니다 최근 에는...             14\n",
       "4  농심 마라 짜파게티 개입 구입 후기에요일요일엔 내가 짜파게티 요리 사짜짜짜짜짜짜파게...             12"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def analyze_keyword_reviews(data, keyword, review_column='preprocessed_review'):\n",
    "    # Function to extract and summarize sentences containing the keyword\n",
    "    def summarize_keyword_reviews(text):\n",
    "        if pd.isna(text):\n",
    "            return None\n",
    "        sentences = re.split(r'[.!?]', text)  # Split into sentences\n",
    "        keyword_sentences = [s.strip() for s in sentences if keyword in s]  # Filter sentences containing the keyword\n",
    "        return keyword_sentences\n",
    "\n",
    "    # Function to count occurrences of the keyword in a text\n",
    "    def count_keyword_mentions(text):\n",
    "        if pd.isna(text):\n",
    "            return 0\n",
    "        return text.count(keyword)\n",
    "\n",
    "    # Extract keyword-related sentences\n",
    "    data['keyword_sentences'] = data[review_column].apply(summarize_keyword_reviews)\n",
    "\n",
    "    # Count keyword mentions in each review\n",
    "    data['keyword_count'] = data[review_column].apply(count_keyword_mentions)\n",
    "\n",
    "    # Sort the data by the number of keyword mentions, descending\n",
    "    top_keyword_reviews = data.sort_values(by='keyword_count', ascending=False).head(5)\n",
    "\n",
    "    # Reset index to ensure numerical order\n",
    "    top_keyword_reviews = top_keyword_reviews.reset_index(drop=True)\n",
    "\n",
    "    # Select relevant columns for output\n",
    "    top_reviews = top_keyword_reviews[[review_column, 'keyword_count']]\n",
    "\n",
    "    return top_reviews\n",
    "\n",
    "# Example usage\n",
    "review_result = analyze_keyword_reviews(df, keyword=word_result['Keyword'][2])\n",
    "review_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>리뷰 내용</th>\n",
       "      <th>filtered_ngrams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>짜파게티 마라, 어떤 제품일까?먼저 짜파게티 마라의 기본 정보를 알아보았어요. 이 ...</td>\n",
       "      <td>[짜파게티 마라, 어떤 제품일까?먼저 짜파게티, 마라, 어떤 제품일까?먼저 짜파게티...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>안녕하세요!! 리뷰하는 dimss입니다^^오늘도 솔직 사용후기 들고 왔어요❤️⬇️⬇...</td>\n",
       "      <td>[dimss입니다^^오늘도 솔직 사용후기 들고 왔어요❤️⬇️⬇️⬇️✨짜파게티, 솔직...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>### 구매 계기매운 음식을 좋아하는 저는 최근 마라탕이나 마라샹궈와 같은 마라 요...</td>\n",
       "      <td>[빠져 있었습니다. 그러던 중 짜파게티의, 있었습니다. 그러던 중 짜파게티의 마라맛...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>⏹️ 요약 ⏹️✅ 구성 - 면, 후레이크, 짜장스프, 마라조미유✅ 맛 - 맵찔이 먹...</td>\n",
       "      <td>[⏹️사전예약 중이길래 궁금해서 신청해보았어요.마침 짜파게티, 중이길래 궁금해서 신...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>짜파게티 마라를 구매한 후기를 이모티콘을 활용하여 작성해 보겠습니다. 아래와 같은 ...</td>\n",
       "      <td>[짜파게티 마라를 구매한 후기를 이모티콘을, 방식으로 작성할 수 있습니다: 짜파게티...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>처음 입에 넣을 때 거부감 드는 향과 뒤에 매운 맛만 느껴짐참고서라도 먹고싶지 않은 맛</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>맛과 어울리지도 않게 맵기만함고급스러운 매운맛이 아니고 싼매운맛. 유통기한 끝나가는...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>마라향이 뭔가 조화롭지않아서 좀 인위적인?느낌의 향만나고우선 진짜 너무 맵기만해요</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>짜파게티도 맛있고 블랙도 맛있는데이건 영.....마라향이 확 나는게 아니라서 이상함...</td>\n",
       "      <td>[짜파게티도 맛있고 블랙도 맛있는데이건 영.....마라향이]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>마라의 얼얼함이 아니라 그냥 캡사이신의 매움입니다;</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>264 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 리뷰 내용  \\\n",
       "0    짜파게티 마라, 어떤 제품일까?먼저 짜파게티 마라의 기본 정보를 알아보았어요. 이 ...   \n",
       "1    안녕하세요!! 리뷰하는 dimss입니다^^오늘도 솔직 사용후기 들고 왔어요❤️⬇️⬇...   \n",
       "2    ### 구매 계기매운 음식을 좋아하는 저는 최근 마라탕이나 마라샹궈와 같은 마라 요...   \n",
       "3    ⏹️ 요약 ⏹️✅ 구성 - 면, 후레이크, 짜장스프, 마라조미유✅ 맛 - 맵찔이 먹...   \n",
       "4    짜파게티 마라를 구매한 후기를 이모티콘을 활용하여 작성해 보겠습니다. 아래와 같은 ...   \n",
       "..                                                 ...   \n",
       "259   처음 입에 넣을 때 거부감 드는 향과 뒤에 매운 맛만 느껴짐참고서라도 먹고싶지 않은 맛   \n",
       "260  맛과 어울리지도 않게 맵기만함고급스러운 매운맛이 아니고 싼매운맛. 유통기한 끝나가는...   \n",
       "261      마라향이 뭔가 조화롭지않아서 좀 인위적인?느낌의 향만나고우선 진짜 너무 맵기만해요   \n",
       "262  짜파게티도 맛있고 블랙도 맛있는데이건 영.....마라향이 확 나는게 아니라서 이상함...   \n",
       "263                       마라의 얼얼함이 아니라 그냥 캡사이신의 매움입니다;   \n",
       "\n",
       "                                       filtered_ngrams  \n",
       "0    [짜파게티 마라, 어떤 제품일까?먼저 짜파게티, 마라, 어떤 제품일까?먼저 짜파게티...  \n",
       "1    [dimss입니다^^오늘도 솔직 사용후기 들고 왔어요❤️⬇️⬇️⬇️✨짜파게티, 솔직...  \n",
       "2    [빠져 있었습니다. 그러던 중 짜파게티의, 있었습니다. 그러던 중 짜파게티의 마라맛...  \n",
       "3    [⏹️사전예약 중이길래 궁금해서 신청해보았어요.마침 짜파게티, 중이길래 궁금해서 신...  \n",
       "4    [짜파게티 마라를 구매한 후기를 이모티콘을, 방식으로 작성할 수 있습니다: 짜파게티...  \n",
       "..                                                 ...  \n",
       "259                                                 []  \n",
       "260                                                 []  \n",
       "261                                                 []  \n",
       "262                  [짜파게티도 맛있고 블랙도 맛있는데이건 영.....마라향이]  \n",
       "263                                                 []  \n",
       "\n",
       "[264 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from itertools import islice\n",
    "\n",
    "# Function to generate n-grams from a text\n",
    "def generate_ngrams(text, n=3):\n",
    "    if pd.isna(text):\n",
    "        return []\n",
    "    words = text.split()\n",
    "    ngrams = [' '.join(words[i:i+n]) for i in range(len(words) - n + 1)]\n",
    "    return ngrams\n",
    "\n",
    "# Function to extract n-grams containing a specific keyword\n",
    "def extract_ngrams_with_keyword(data, keyword, review_column='preprocessed_review', n=3):\n",
    "    # Generate n-grams for each review\n",
    "    data['ngrams'] = data[review_column].apply(lambda x: generate_ngrams(x, n))\n",
    "    \n",
    "    # Filter n-grams containing the keyword\n",
    "    data['filtered_ngrams'] = data['ngrams'].apply(lambda ngrams: [ngram for ngram in ngrams if keyword in ngram])\n",
    "    \n",
    "    # Select relevant columns for output\n",
    "    result = data[[review_column, 'filtered_ngrams']]\n",
    "    return result\n",
    "\n",
    "# Example usage\n",
    "# Assuming your DataFrame is named `df` and you want to extract n-grams with the keyword '마라':\n",
    "result = extract_ngrams_with_keyword(df, keyword=word_result['Keyword'][2], review_column='리뷰 내용', n=5)\n",
    "result\n",
    "# Save the result to a CSV file\n",
    "# result.to_csv('ngram_results.csv', index=False, encoding='utf-8-sig')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coreview",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
