{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import sys\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_oranda= pd.read_csv(\"../data/zapa_total.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>이름</th>\n",
       "      <th>작성일자</th>\n",
       "      <th>평점</th>\n",
       "      <th>리뷰 내용</th>\n",
       "      <th>맛 만족도</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>박*혜</td>\n",
       "      <td>2025.01.14</td>\n",
       "      <td>5</td>\n",
       "      <td>짜파게티 마라, 어떤 제품일까?먼저 짜파게티 마라의 기본 정보를 알아보았어요. 이 ...</td>\n",
       "      <td>아주 넉넉해요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dimss</td>\n",
       "      <td>2025.01.13</td>\n",
       "      <td>4</td>\n",
       "      <td>안녕하세요!! 리뷰하는 dimss입니다^^오늘도 솔직 사용후기 들고 왔어요❤️⬇️⬇...</td>\n",
       "      <td>적당히 남았어요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>이*람</td>\n",
       "      <td>2025.01.12</td>\n",
       "      <td>5</td>\n",
       "      <td>### 구매 계기매운 음식을 좋아하는 저는 최근 마라탕이나 마라샹궈와 같은 마라 요...</td>\n",
       "      <td>적당히 남았어요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>시마에나가</td>\n",
       "      <td>2025.01.11</td>\n",
       "      <td>4</td>\n",
       "      <td>⏹️ 요약 ⏹️✅ 구성 - 면, 후레이크, 짜장스프, 마라조미유✅ 맛 - 맵찔이 먹...</td>\n",
       "      <td>적당히 남았어요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>김*수</td>\n",
       "      <td>2025.01.11</td>\n",
       "      <td>5</td>\n",
       "      <td>짜파게티 마라를 구매한 후기를 이모티콘을 활용하여 작성해 보겠습니다. 아래와 같은 ...</td>\n",
       "      <td>아주 넉넉해요</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      이름        작성일자  평점                                              리뷰 내용  \\\n",
       "0    박*혜  2025.01.14   5  짜파게티 마라, 어떤 제품일까?먼저 짜파게티 마라의 기본 정보를 알아보았어요. 이 ...   \n",
       "1  dimss  2025.01.13   4  안녕하세요!! 리뷰하는 dimss입니다^^오늘도 솔직 사용후기 들고 왔어요❤️⬇️⬇...   \n",
       "2    이*람  2025.01.12   5  ### 구매 계기매운 음식을 좋아하는 저는 최근 마라탕이나 마라샹궈와 같은 마라 요...   \n",
       "3  시마에나가  2025.01.11   4  ⏹️ 요약 ⏹️✅ 구성 - 면, 후레이크, 짜장스프, 마라조미유✅ 맛 - 맵찔이 먹...   \n",
       "4    김*수  2025.01.11   5  짜파게티 마라를 구매한 후기를 이모티콘을 활용하여 작성해 보겠습니다. 아래와 같은 ...   \n",
       "\n",
       "      맛 만족도  \n",
       "0   아주 넉넉해요  \n",
       "1  적당히 남았어요  \n",
       "2  적당히 남았어요  \n",
       "3  적당히 남았어요  \n",
       "4   아주 넉넉해요  "
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data_oranda= pd.read_csv(\"../data/zapa_150.csv\")\n",
    "data_oranda.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(722, 5)"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_oranda.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_oranda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평점별 개수:\n",
      "평점\n",
      "1     41\n",
      "2     24\n",
      "3     42\n",
      "4     86\n",
      "5    529\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 평점별 개수 계산\n",
    "rating_counts = df['평점'].value_counts().sort_index()\n",
    "\n",
    "# 결과 출력\n",
    "print(\"평점별 개수:\")\n",
    "print(rating_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>이름</th>\n",
       "      <th>작성일자</th>\n",
       "      <th>평점</th>\n",
       "      <th>리뷰 내용</th>\n",
       "      <th>맛 만족도</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>김*동</td>\n",
       "      <td>2024.12.29</td>\n",
       "      <td>1</td>\n",
       "      <td>등록된 리뷰내용이 없습니다</td>\n",
       "      <td>맛 평가 없음</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>정*주</td>\n",
       "      <td>2024.12.26</td>\n",
       "      <td>1</td>\n",
       "      <td>등록된 리뷰내용이 없습니다</td>\n",
       "      <td>아주 넉넉해요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>박*은</td>\n",
       "      <td>2024.12.30</td>\n",
       "      <td>1</td>\n",
       "      <td>등록된 리뷰내용이 없습니다</td>\n",
       "      <td>생각보다 별로에요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>박*수</td>\n",
       "      <td>2024.12.26</td>\n",
       "      <td>1</td>\n",
       "      <td>등록된 리뷰내용이 없습니다</td>\n",
       "      <td>적당히 남았어요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>오*철</td>\n",
       "      <td>2024.12.29</td>\n",
       "      <td>1</td>\n",
       "      <td>등록된 리뷰내용이 없습니다</td>\n",
       "      <td>적당히 남았어요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>정*혁</td>\n",
       "      <td>2024.12.28</td>\n",
       "      <td>1</td>\n",
       "      <td>얼마나 던졌으면 다 가루가돼서 오냐</td>\n",
       "      <td>적당히 남았어요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>장*호</td>\n",
       "      <td>2024.12.26</td>\n",
       "      <td>1</td>\n",
       "      <td>맵기만하고 맛없어요</td>\n",
       "      <td>적당히 남았어요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>강*준</td>\n",
       "      <td>2024.12.31</td>\n",
       "      <td>1</td>\n",
       "      <td>등록된 리뷰내용이 없습니다</td>\n",
       "      <td>아주 넉넉해요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>장*혁</td>\n",
       "      <td>2024.12.26</td>\n",
       "      <td>1</td>\n",
       "      <td>먹다가 버림 마라탕 안좋아하면 절대 먹지마</td>\n",
       "      <td>아주 넉넉해요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>황*석</td>\n",
       "      <td>2024.12.29</td>\n",
       "      <td>1</td>\n",
       "      <td>라면이 아주 가루가 되서 도착을 했네요면이아니라 죽처럼 퍼먹게 생겼습니다다른제품 주...</td>\n",
       "      <td>아주 넉넉해요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>유*정</td>\n",
       "      <td>2024.12.25</td>\n",
       "      <td>1</td>\n",
       "      <td>마라 코끝을 스침걍 졸라뤼 매움 맵찔이들 절대 먹지 마세욘맵찔이어도 마라 먹을 때 ...</td>\n",
       "      <td>아주 넉넉해요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>까르까르</td>\n",
       "      <td>2024.12.30</td>\n",
       "      <td>1</td>\n",
       "      <td>마라향이 으마으마하네요 걍 제 입맛엔 별로.. 짜장맛은 전혀 안느껴지고 한들이에 4...</td>\n",
       "      <td>적당히 남았어요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>아티부</td>\n",
       "      <td>2024.12.26</td>\n",
       "      <td>1</td>\n",
       "      <td>생각보다 많이 매워요매운거좋아하는뎅이런 찝찝한 매움은 안좋아해요맛있게먹을라고양파도볶...</td>\n",
       "      <td>아주 넉넉해요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>고양이없어</td>\n",
       "      <td>2024.12.31</td>\n",
       "      <td>1</td>\n",
       "      <td>맵찔이분들은 조심하셔욧 ㅋㅋㅋㅋ까르보나라 불닭보단 매움 ㅜ속이 아프네요. 궁금해서 ...</td>\n",
       "      <td>적당히 남았어요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>김*성</td>\n",
       "      <td>2024.12.28</td>\n",
       "      <td>1</td>\n",
       "      <td>마라 특유의 향과 맛이 짜장에는 어울리지 않는다.짜장은 청양고추 이하의 고추가루 맛...</td>\n",
       "      <td>아주 넉넉해요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>배고프노</td>\n",
       "      <td>2024.12.25</td>\n",
       "      <td>1</td>\n",
       "      <td>돈 아끼세요 --감칠맛 없고 매워요 그렇다고 짜파게티 맛이 나는것도 아님마라 얼얼 ...</td>\n",
       "      <td>적당히 남았어요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>조*제</td>\n",
       "      <td>2024.12.30</td>\n",
       "      <td>1</td>\n",
       "      <td>살다살다 쿠팡 후기를 다쓰지만 쓰레기같은 맛입니다</td>\n",
       "      <td>아주 넉넉해요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>이*림</td>\n",
       "      <td>2024.12.27</td>\n",
       "      <td>1</td>\n",
       "      <td>너무 실망ㅠ 나머진 주위에 맛봐라고 나눠줬어요..또 사고싶지 않은맛애들도 다 남겼네...</td>\n",
       "      <td>아주 넉넉해요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>전*민</td>\n",
       "      <td>2024.12.31</td>\n",
       "      <td>1</td>\n",
       "      <td>정말...얼얼한 맛만 있습니다그냥 일반 또는 사천 드세요사전에 한박스 주믄 있었는데...</td>\n",
       "      <td>아주 넉넉해요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>정당평가</td>\n",
       "      <td>2025.01.03</td>\n",
       "      <td>1</td>\n",
       "      <td>마라성분 혹시하고 구입했어요 맵기도하고 짜장맛은 별로네요 그냥 짜장이 더 나을듯함다</td>\n",
       "      <td>적당히 남았어요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>랑랑리</td>\n",
       "      <td>2024.12.26</td>\n",
       "      <td>1</td>\n",
       "      <td>너무 매워요 ㅠㅠㅠㅠㅠㅠㅠㅠㅠ불닭볶음면급으로 매워요다시는 안먹을거에요</td>\n",
       "      <td>아주 넉넉해요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>박*아</td>\n",
       "      <td>2024.12.30</td>\n",
       "      <td>1</td>\n",
       "      <td>넘 맵고 마라향이 너무 이상해서 한젓가락 먹고 버림. 이후 오일빼고 먹었는데 너무 ...</td>\n",
       "      <td>아주 넉넉해요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>이*태</td>\n",
       "      <td>2024.12.25</td>\n",
       "      <td>1</td>\n",
       "      <td>왠만해서 상품평 안남기는데 나만 당할순 없지~~ 꼭 한번 드셔들 보셔~~존맛탱~~!</td>\n",
       "      <td>얼마 남지 않았어요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>잔잔다에</td>\n",
       "      <td>2025.01.01</td>\n",
       "      <td>1</td>\n",
       "      <td>처음 입에 넣을 때 거부감 드는 향과 뒤에 매운 맛만 느껴짐참고서라도 먹고싶지 않은 맛</td>\n",
       "      <td>맛 평가 없음</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>코만도x</td>\n",
       "      <td>2025.01.10</td>\n",
       "      <td>1</td>\n",
       "      <td>맛과 어울리지도 않게 맵기만함고급스러운 매운맛이 아니고 싼매운맛. 유통기한 끝나가는...</td>\n",
       "      <td>적당히 남았어요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>sssgg</td>\n",
       "      <td>2025.01.04</td>\n",
       "      <td>1</td>\n",
       "      <td>마라향이 뭔가 조화롭지않아서 좀 인위적인?느낌의 향만나고우선 진짜 너무 맵기만해요</td>\n",
       "      <td>적당히 남았어요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>쿠리사</td>\n",
       "      <td>2025.01.13</td>\n",
       "      <td>1</td>\n",
       "      <td>짜파게티도 맛있고 블랙도 맛있는데이건 영.....마라향이 확 나는게 아니라서 이상함...</td>\n",
       "      <td>아주 넉넉해요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>rtrtrt</td>\n",
       "      <td>2025.01.07</td>\n",
       "      <td>1</td>\n",
       "      <td>마라의 얼얼함이 아니라 그냥 캡사이신의 매움입니다;</td>\n",
       "      <td>아주 넉넉해요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>강*수</td>\n",
       "      <td>2024.12.24</td>\n",
       "      <td>1</td>\n",
       "      <td>등록된 리뷰내용이 없습니다</td>\n",
       "      <td>맛 평가 없음</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>방*윤</td>\n",
       "      <td>2024.12.25</td>\n",
       "      <td>1</td>\n",
       "      <td>등록된 리뷰내용이 없습니다</td>\n",
       "      <td>맛 평가 없음</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>이*희</td>\n",
       "      <td>2024.12.25</td>\n",
       "      <td>1</td>\n",
       "      <td>등록된 리뷰내용이 없습니다</td>\n",
       "      <td>맛 평가 없음</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>임*민</td>\n",
       "      <td>2024.12.26</td>\n",
       "      <td>1</td>\n",
       "      <td>등록된 리뷰내용이 없습니다</td>\n",
       "      <td>맛 평가 없음</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>본소</td>\n",
       "      <td>2024.12.28</td>\n",
       "      <td>1</td>\n",
       "      <td>등록된 리뷰내용이 없습니다</td>\n",
       "      <td>생각보다 별로에요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>정*경</td>\n",
       "      <td>2024.12.28</td>\n",
       "      <td>1</td>\n",
       "      <td>등록된 리뷰내용이 없습니다</td>\n",
       "      <td>맛 평가 없음</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>wonj</td>\n",
       "      <td>2024.12.29</td>\n",
       "      <td>1</td>\n",
       "      <td>등록된 리뷰내용이 없습니다</td>\n",
       "      <td>적당히 남았어요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>유은상</td>\n",
       "      <td>2025.01.01</td>\n",
       "      <td>1</td>\n",
       "      <td>등록된 리뷰내용이 없습니다</td>\n",
       "      <td>맛 평가 없음</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>김*여</td>\n",
       "      <td>2025.01.01</td>\n",
       "      <td>1</td>\n",
       "      <td>등록된 리뷰내용이 없습니다</td>\n",
       "      <td>생각보다 별로에요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>정*규</td>\n",
       "      <td>2025.01.03</td>\n",
       "      <td>1</td>\n",
       "      <td>등록된 리뷰내용이 없습니다</td>\n",
       "      <td>맛 평가 없음</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>띠르때르</td>\n",
       "      <td>2025.01.10</td>\n",
       "      <td>1</td>\n",
       "      <td>등록된 리뷰내용이 없습니다</td>\n",
       "      <td>맛 평가 없음</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>김*민</td>\n",
       "      <td>2025.01.11</td>\n",
       "      <td>1</td>\n",
       "      <td>등록된 리뷰내용이 없습니다</td>\n",
       "      <td>맛 평가 없음</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>오*석</td>\n",
       "      <td>2025.01.11</td>\n",
       "      <td>1</td>\n",
       "      <td>등록된 리뷰내용이 없습니다</td>\n",
       "      <td>맛 평가 없음</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         이름        작성일자  평점  \\\n",
       "221     김*동  2024.12.29   1   \n",
       "224     정*주  2024.12.26   1   \n",
       "232     박*은  2024.12.30   1   \n",
       "238     박*수  2024.12.26   1   \n",
       "253     오*철  2024.12.29   1   \n",
       "254     정*혁  2024.12.28   1   \n",
       "257     장*호  2024.12.26   1   \n",
       "261     강*준  2024.12.31   1   \n",
       "263     장*혁  2024.12.26   1   \n",
       "269     황*석  2024.12.29   1   \n",
       "270     유*정  2024.12.25   1   \n",
       "271    까르까르  2024.12.30   1   \n",
       "272     아티부  2024.12.26   1   \n",
       "273   고양이없어  2024.12.31   1   \n",
       "274     김*성  2024.12.28   1   \n",
       "275    배고프노  2024.12.25   1   \n",
       "276     조*제  2024.12.30   1   \n",
       "277     이*림  2024.12.27   1   \n",
       "278     전*민  2024.12.31   1   \n",
       "279    정당평가  2025.01.03   1   \n",
       "280     랑랑리  2024.12.26   1   \n",
       "281     박*아  2024.12.30   1   \n",
       "282     이*태  2024.12.25   1   \n",
       "283    잔잔다에  2025.01.01   1   \n",
       "284    코만도x  2025.01.10   1   \n",
       "285   sssgg  2025.01.04   1   \n",
       "286     쿠리사  2025.01.13   1   \n",
       "287  rtrtrt  2025.01.07   1   \n",
       "709     강*수  2024.12.24   1   \n",
       "710     방*윤  2024.12.25   1   \n",
       "711     이*희  2024.12.25   1   \n",
       "712     임*민  2024.12.26   1   \n",
       "713      본소  2024.12.28   1   \n",
       "714     정*경  2024.12.28   1   \n",
       "715    wonj  2024.12.29   1   \n",
       "716     유은상  2025.01.01   1   \n",
       "717     김*여  2025.01.01   1   \n",
       "718     정*규  2025.01.03   1   \n",
       "719    띠르때르  2025.01.10   1   \n",
       "720     김*민  2025.01.11   1   \n",
       "721     오*석  2025.01.11   1   \n",
       "\n",
       "                                                 리뷰 내용       맛 만족도  \n",
       "221                                     등록된 리뷰내용이 없습니다     맛 평가 없음  \n",
       "224                                     등록된 리뷰내용이 없습니다     아주 넉넉해요  \n",
       "232                                     등록된 리뷰내용이 없습니다   생각보다 별로에요  \n",
       "238                                     등록된 리뷰내용이 없습니다    적당히 남았어요  \n",
       "253                                     등록된 리뷰내용이 없습니다    적당히 남았어요  \n",
       "254                                얼마나 던졌으면 다 가루가돼서 오냐    적당히 남았어요  \n",
       "257                                         맵기만하고 맛없어요    적당히 남았어요  \n",
       "261                                     등록된 리뷰내용이 없습니다     아주 넉넉해요  \n",
       "263                            먹다가 버림 마라탕 안좋아하면 절대 먹지마     아주 넉넉해요  \n",
       "269  라면이 아주 가루가 되서 도착을 했네요면이아니라 죽처럼 퍼먹게 생겼습니다다른제품 주...     아주 넉넉해요  \n",
       "270  마라 코끝을 스침걍 졸라뤼 매움 맵찔이들 절대 먹지 마세욘맵찔이어도 마라 먹을 때 ...     아주 넉넉해요  \n",
       "271  마라향이 으마으마하네요 걍 제 입맛엔 별로.. 짜장맛은 전혀 안느껴지고 한들이에 4...    적당히 남았어요  \n",
       "272  생각보다 많이 매워요매운거좋아하는뎅이런 찝찝한 매움은 안좋아해요맛있게먹을라고양파도볶...     아주 넉넉해요  \n",
       "273  맵찔이분들은 조심하셔욧 ㅋㅋㅋㅋ까르보나라 불닭보단 매움 ㅜ속이 아프네요. 궁금해서 ...    적당히 남았어요  \n",
       "274  마라 특유의 향과 맛이 짜장에는 어울리지 않는다.짜장은 청양고추 이하의 고추가루 맛...     아주 넉넉해요  \n",
       "275  돈 아끼세요 --감칠맛 없고 매워요 그렇다고 짜파게티 맛이 나는것도 아님마라 얼얼 ...    적당히 남았어요  \n",
       "276                        살다살다 쿠팡 후기를 다쓰지만 쓰레기같은 맛입니다     아주 넉넉해요  \n",
       "277  너무 실망ㅠ 나머진 주위에 맛봐라고 나눠줬어요..또 사고싶지 않은맛애들도 다 남겼네...     아주 넉넉해요  \n",
       "278  정말...얼얼한 맛만 있습니다그냥 일반 또는 사천 드세요사전에 한박스 주믄 있었는데...     아주 넉넉해요  \n",
       "279     마라성분 혹시하고 구입했어요 맵기도하고 짜장맛은 별로네요 그냥 짜장이 더 나을듯함다    적당히 남았어요  \n",
       "280             너무 매워요 ㅠㅠㅠㅠㅠㅠㅠㅠㅠ불닭볶음면급으로 매워요다시는 안먹을거에요     아주 넉넉해요  \n",
       "281  넘 맵고 마라향이 너무 이상해서 한젓가락 먹고 버림. 이후 오일빼고 먹었는데 너무 ...     아주 넉넉해요  \n",
       "282     왠만해서 상품평 안남기는데 나만 당할순 없지~~ 꼭 한번 드셔들 보셔~~존맛탱~~!  얼마 남지 않았어요  \n",
       "283   처음 입에 넣을 때 거부감 드는 향과 뒤에 매운 맛만 느껴짐참고서라도 먹고싶지 않은 맛     맛 평가 없음  \n",
       "284  맛과 어울리지도 않게 맵기만함고급스러운 매운맛이 아니고 싼매운맛. 유통기한 끝나가는...    적당히 남았어요  \n",
       "285      마라향이 뭔가 조화롭지않아서 좀 인위적인?느낌의 향만나고우선 진짜 너무 맵기만해요    적당히 남았어요  \n",
       "286  짜파게티도 맛있고 블랙도 맛있는데이건 영.....마라향이 확 나는게 아니라서 이상함...     아주 넉넉해요  \n",
       "287                       마라의 얼얼함이 아니라 그냥 캡사이신의 매움입니다;     아주 넉넉해요  \n",
       "709                                     등록된 리뷰내용이 없습니다     맛 평가 없음  \n",
       "710                                     등록된 리뷰내용이 없습니다     맛 평가 없음  \n",
       "711                                     등록된 리뷰내용이 없습니다     맛 평가 없음  \n",
       "712                                     등록된 리뷰내용이 없습니다     맛 평가 없음  \n",
       "713                                     등록된 리뷰내용이 없습니다   생각보다 별로에요  \n",
       "714                                     등록된 리뷰내용이 없습니다     맛 평가 없음  \n",
       "715                                     등록된 리뷰내용이 없습니다    적당히 남았어요  \n",
       "716                                     등록된 리뷰내용이 없습니다     맛 평가 없음  \n",
       "717                                     등록된 리뷰내용이 없습니다   생각보다 별로에요  \n",
       "718                                     등록된 리뷰내용이 없습니다     맛 평가 없음  \n",
       "719                                     등록된 리뷰내용이 없습니다     맛 평가 없음  \n",
       "720                                     등록된 리뷰내용이 없습니다     맛 평가 없음  \n",
       "721                                     등록된 리뷰내용이 없습니다     맛 평가 없음  "
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 평점별로 데이터프레임 보기 (예: 평점이 5인 데이터)\n",
    "rating_1_df = df[df['평점'] == 1]\n",
    "rating_1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>이름</th>\n",
       "      <th>작성일자</th>\n",
       "      <th>평점</th>\n",
       "      <th>리뷰 내용</th>\n",
       "      <th>맛 만족도</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>lovenpeace</td>\n",
       "      <td>2024.12.27</td>\n",
       "      <td>2</td>\n",
       "      <td>사천짜장까지는 맛있게 잘 먹지만이건 마라 특유의 향이 짜장 맛을 가립니다.마라 7대...</td>\n",
       "      <td>아주 넉넉해요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>김*림</td>\n",
       "      <td>2024.12.25</td>\n",
       "      <td>2</td>\n",
       "      <td>평소에 짜파게티와 사천짜파게티 둘 다 아주 좋아해서 이번 신상품도 기대하고 사전예약...</td>\n",
       "      <td>아주 넉넉해요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>우*준</td>\n",
       "      <td>2024.12.29</td>\n",
       "      <td>2</td>\n",
       "      <td>1개 먹고나서 나머지 3개는 잘 안먹을 것 같은 느낌이 듭니다.라면을 개발하는 과정...</td>\n",
       "      <td>아주 넉넉해요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>김*희</td>\n",
       "      <td>2025.01.01</td>\n",
       "      <td>2</td>\n",
       "      <td>생각보다 맵고 처음 먹어보는거라 3봉 삶을때 액상소스 1개만 넣었는데도 액상소스의 ...</td>\n",
       "      <td>아주 넉넉해요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>홍*진</td>\n",
       "      <td>2024.12.29</td>\n",
       "      <td>2</td>\n",
       "      <td>맵고 맛은그냥그래요 마라맛은약하고 맵기만</td>\n",
       "      <td>아주 넉넉해요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>송*한</td>\n",
       "      <td>2024.12.25</td>\n",
       "      <td>2</td>\n",
       "      <td>이건 아니다 그냥 짜파게티는 못이긴다</td>\n",
       "      <td>아주 넉넉해요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>코코블루</td>\n",
       "      <td>2025.01.03</td>\n",
       "      <td>2</td>\n",
       "      <td>다 깨져있어요</td>\n",
       "      <td>아주 넉넉해요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>djdodhdo</td>\n",
       "      <td>2025.01.07</td>\n",
       "      <td>2</td>\n",
       "      <td>등록된 리뷰내용이 없습니다</td>\n",
       "      <td>적당히 남았어요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>류니네</td>\n",
       "      <td>2025.01.12</td>\n",
       "      <td>2</td>\n",
       "      <td>젊은 입맛에는 잘맞을 거 같아요첫입에 기침이 나올정도 매운맛인데 그다음부터는 많이 ...</td>\n",
       "      <td>아주 넉넉해요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>김*숙</td>\n",
       "      <td>2025.01.14</td>\n",
       "      <td>2</td>\n",
       "      <td>정말 맛없네요.싸지도않고..이걸 사전예약해서 산게 우습게여겨질정도로 별로이구요.마라...</td>\n",
       "      <td>아주 넉넉해요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>손*운</td>\n",
       "      <td>2024.12.28</td>\n",
       "      <td>2</td>\n",
       "      <td>생각보다 맵습니다.짜파게티와 마라 냄새가 어우러지지 않아서요상한 냄새가 납니다. 고...</td>\n",
       "      <td>아주 넉넉해요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>송*성</td>\n",
       "      <td>2025.01.13</td>\n",
       "      <td>2</td>\n",
       "      <td>짜파게티도 좋아하고 마라도 좋아하는데 이건 맵기만 하고 진짜 맛 없어요하나 먹고 방...</td>\n",
       "      <td>아주 넉넉해요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>김*내</td>\n",
       "      <td>2025.01.02</td>\n",
       "      <td>2</td>\n",
       "      <td>호불호 확실한 맛..전 완전 불호이네요ㅜㅜㅜ마라 좋아하시는.분만.드세요ㅠㅠ</td>\n",
       "      <td>적당히 남았어요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>안*선</td>\n",
       "      <td>2024.12.27</td>\n",
       "      <td>2</td>\n",
       "      <td>등록된 리뷰내용이 없습니다</td>\n",
       "      <td>아주 넉넉해요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>강*현</td>\n",
       "      <td>2024.12.29</td>\n",
       "      <td>2</td>\n",
       "      <td>등록된 리뷰내용이 없습니다</td>\n",
       "      <td>맛 평가 없음</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>이*정</td>\n",
       "      <td>2024.12.30</td>\n",
       "      <td>2</td>\n",
       "      <td>등록된 리뷰내용이 없습니다</td>\n",
       "      <td>적당히 남았어요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>윤*아</td>\n",
       "      <td>2025.01.02</td>\n",
       "      <td>2</td>\n",
       "      <td>등록된 리뷰내용이 없습니다</td>\n",
       "      <td>맛 평가 없음</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>라일락탄</td>\n",
       "      <td>2025.01.04</td>\n",
       "      <td>2</td>\n",
       "      <td>등록된 리뷰내용이 없습니다</td>\n",
       "      <td>맛 평가 없음</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>정*영</td>\n",
       "      <td>2025.01.05</td>\n",
       "      <td>2</td>\n",
       "      <td>등록된 리뷰내용이 없습니다</td>\n",
       "      <td>맛 평가 없음</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>서*선</td>\n",
       "      <td>2025.01.11</td>\n",
       "      <td>2</td>\n",
       "      <td>등록된 리뷰내용이 없습니다</td>\n",
       "      <td>얼마 남지 않았어요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>서*우</td>\n",
       "      <td>2025.01.11</td>\n",
       "      <td>2</td>\n",
       "      <td>등록된 리뷰내용이 없습니다</td>\n",
       "      <td>맛 평가 없음</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>곽*영</td>\n",
       "      <td>2025.01.11</td>\n",
       "      <td>2</td>\n",
       "      <td>등록된 리뷰내용이 없습니다</td>\n",
       "      <td>맛 평가 없음</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>박*호</td>\n",
       "      <td>2025.01.12</td>\n",
       "      <td>2</td>\n",
       "      <td>등록된 리뷰내용이 없습니다</td>\n",
       "      <td>맛 평가 없음</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>40percent</td>\n",
       "      <td>2025.01.12</td>\n",
       "      <td>2</td>\n",
       "      <td>등록된 리뷰내용이 없습니다</td>\n",
       "      <td>맛 평가 없음</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             이름        작성일자  평점  \\\n",
       "215  lovenpeace  2024.12.27   2   \n",
       "216         김*림  2024.12.25   2   \n",
       "217         우*준  2024.12.29   2   \n",
       "218         김*희  2025.01.01   2   \n",
       "231         홍*진  2024.12.29   2   \n",
       "236         송*한  2024.12.25   2   \n",
       "244        코코블루  2025.01.03   2   \n",
       "246    djdodhdo  2025.01.07   2   \n",
       "264         류니네  2025.01.12   2   \n",
       "265         김*숙  2025.01.14   2   \n",
       "266         손*운  2024.12.28   2   \n",
       "267         송*성  2025.01.13   2   \n",
       "268         김*내  2025.01.02   2   \n",
       "698         안*선  2024.12.27   2   \n",
       "699         강*현  2024.12.29   2   \n",
       "700         이*정  2024.12.30   2   \n",
       "701         윤*아  2025.01.02   2   \n",
       "702        라일락탄  2025.01.04   2   \n",
       "703         정*영  2025.01.05   2   \n",
       "704         서*선  2025.01.11   2   \n",
       "705         서*우  2025.01.11   2   \n",
       "706         곽*영  2025.01.11   2   \n",
       "707         박*호  2025.01.12   2   \n",
       "708   40percent  2025.01.12   2   \n",
       "\n",
       "                                                 리뷰 내용       맛 만족도  \n",
       "215  사천짜장까지는 맛있게 잘 먹지만이건 마라 특유의 향이 짜장 맛을 가립니다.마라 7대...     아주 넉넉해요  \n",
       "216  평소에 짜파게티와 사천짜파게티 둘 다 아주 좋아해서 이번 신상품도 기대하고 사전예약...     아주 넉넉해요  \n",
       "217  1개 먹고나서 나머지 3개는 잘 안먹을 것 같은 느낌이 듭니다.라면을 개발하는 과정...     아주 넉넉해요  \n",
       "218  생각보다 맵고 처음 먹어보는거라 3봉 삶을때 액상소스 1개만 넣었는데도 액상소스의 ...     아주 넉넉해요  \n",
       "231                             맵고 맛은그냥그래요 마라맛은약하고 맵기만     아주 넉넉해요  \n",
       "236                               이건 아니다 그냥 짜파게티는 못이긴다     아주 넉넉해요  \n",
       "244                                            다 깨져있어요     아주 넉넉해요  \n",
       "246                                     등록된 리뷰내용이 없습니다    적당히 남았어요  \n",
       "264  젊은 입맛에는 잘맞을 거 같아요첫입에 기침이 나올정도 매운맛인데 그다음부터는 많이 ...     아주 넉넉해요  \n",
       "265  정말 맛없네요.싸지도않고..이걸 사전예약해서 산게 우습게여겨질정도로 별로이구요.마라...     아주 넉넉해요  \n",
       "266  생각보다 맵습니다.짜파게티와 마라 냄새가 어우러지지 않아서요상한 냄새가 납니다. 고...     아주 넉넉해요  \n",
       "267  짜파게티도 좋아하고 마라도 좋아하는데 이건 맵기만 하고 진짜 맛 없어요하나 먹고 방...     아주 넉넉해요  \n",
       "268          호불호 확실한 맛..전 완전 불호이네요ㅜㅜㅜ마라 좋아하시는.분만.드세요ㅠㅠ    적당히 남았어요  \n",
       "698                                     등록된 리뷰내용이 없습니다     아주 넉넉해요  \n",
       "699                                     등록된 리뷰내용이 없습니다     맛 평가 없음  \n",
       "700                                     등록된 리뷰내용이 없습니다    적당히 남았어요  \n",
       "701                                     등록된 리뷰내용이 없습니다     맛 평가 없음  \n",
       "702                                     등록된 리뷰내용이 없습니다     맛 평가 없음  \n",
       "703                                     등록된 리뷰내용이 없습니다     맛 평가 없음  \n",
       "704                                     등록된 리뷰내용이 없습니다  얼마 남지 않았어요  \n",
       "705                                     등록된 리뷰내용이 없습니다     맛 평가 없음  \n",
       "706                                     등록된 리뷰내용이 없습니다     맛 평가 없음  \n",
       "707                                     등록된 리뷰내용이 없습니다     맛 평가 없음  \n",
       "708                                     등록된 리뷰내용이 없습니다     맛 평가 없음  "
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 평점별로 데이터프레임 보기 (예: 평점이 5인 데이터)\n",
    "rating_2_df = df[df['평점'] == 2]\n",
    "rating_2_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 필터링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "등록된 리뷰내용이 있는 것만 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>이름</th>\n",
       "      <th>작성일자</th>\n",
       "      <th>평점</th>\n",
       "      <th>리뷰 내용</th>\n",
       "      <th>맛 만족도</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>박*혜</td>\n",
       "      <td>2025.01.14</td>\n",
       "      <td>5</td>\n",
       "      <td>짜파게티 마라, 어떤 제품일까?먼저 짜파게티 마라의 기본 정보를 알아보았어요. 이 ...</td>\n",
       "      <td>아주 넉넉해요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dimss</td>\n",
       "      <td>2025.01.13</td>\n",
       "      <td>4</td>\n",
       "      <td>안녕하세요!! 리뷰하는 dimss입니다^^오늘도 솔직 사용후기 들고 왔어요❤️⬇️⬇...</td>\n",
       "      <td>적당히 남았어요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>이*람</td>\n",
       "      <td>2025.01.12</td>\n",
       "      <td>5</td>\n",
       "      <td>### 구매 계기매운 음식을 좋아하는 저는 최근 마라탕이나 마라샹궈와 같은 마라 요...</td>\n",
       "      <td>적당히 남았어요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>시마에나가</td>\n",
       "      <td>2025.01.11</td>\n",
       "      <td>4</td>\n",
       "      <td>⏹️ 요약 ⏹️✅ 구성 - 면, 후레이크, 짜장스프, 마라조미유✅ 맛 - 맵찔이 먹...</td>\n",
       "      <td>적당히 남았어요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>김*수</td>\n",
       "      <td>2025.01.11</td>\n",
       "      <td>5</td>\n",
       "      <td>짜파게티 마라를 구매한 후기를 이모티콘을 활용하여 작성해 보겠습니다. 아래와 같은 ...</td>\n",
       "      <td>아주 넉넉해요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>잔잔다에</td>\n",
       "      <td>2025.01.01</td>\n",
       "      <td>1</td>\n",
       "      <td>처음 입에 넣을 때 거부감 드는 향과 뒤에 매운 맛만 느껴짐참고서라도 먹고싶지 않은 맛</td>\n",
       "      <td>맛 평가 없음</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>코만도x</td>\n",
       "      <td>2025.01.10</td>\n",
       "      <td>1</td>\n",
       "      <td>맛과 어울리지도 않게 맵기만함고급스러운 매운맛이 아니고 싼매운맛. 유통기한 끝나가는...</td>\n",
       "      <td>적당히 남았어요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>sssgg</td>\n",
       "      <td>2025.01.04</td>\n",
       "      <td>1</td>\n",
       "      <td>마라향이 뭔가 조화롭지않아서 좀 인위적인?느낌의 향만나고우선 진짜 너무 맵기만해요</td>\n",
       "      <td>적당히 남았어요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>쿠리사</td>\n",
       "      <td>2025.01.13</td>\n",
       "      <td>1</td>\n",
       "      <td>짜파게티도 맛있고 블랙도 맛있는데이건 영.....마라향이 확 나는게 아니라서 이상함...</td>\n",
       "      <td>아주 넉넉해요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>rtrtrt</td>\n",
       "      <td>2025.01.07</td>\n",
       "      <td>1</td>\n",
       "      <td>마라의 얼얼함이 아니라 그냥 캡사이신의 매움입니다;</td>\n",
       "      <td>아주 넉넉해요</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>264 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         이름        작성일자  평점  \\\n",
       "0       박*혜  2025.01.14   5   \n",
       "1     dimss  2025.01.13   4   \n",
       "2       이*람  2025.01.12   5   \n",
       "3     시마에나가  2025.01.11   4   \n",
       "4       김*수  2025.01.11   5   \n",
       "..      ...         ...  ..   \n",
       "283    잔잔다에  2025.01.01   1   \n",
       "284    코만도x  2025.01.10   1   \n",
       "285   sssgg  2025.01.04   1   \n",
       "286     쿠리사  2025.01.13   1   \n",
       "287  rtrtrt  2025.01.07   1   \n",
       "\n",
       "                                                 리뷰 내용     맛 만족도  \n",
       "0    짜파게티 마라, 어떤 제품일까?먼저 짜파게티 마라의 기본 정보를 알아보았어요. 이 ...   아주 넉넉해요  \n",
       "1    안녕하세요!! 리뷰하는 dimss입니다^^오늘도 솔직 사용후기 들고 왔어요❤️⬇️⬇...  적당히 남았어요  \n",
       "2    ### 구매 계기매운 음식을 좋아하는 저는 최근 마라탕이나 마라샹궈와 같은 마라 요...  적당히 남았어요  \n",
       "3    ⏹️ 요약 ⏹️✅ 구성 - 면, 후레이크, 짜장스프, 마라조미유✅ 맛 - 맵찔이 먹...  적당히 남았어요  \n",
       "4    짜파게티 마라를 구매한 후기를 이모티콘을 활용하여 작성해 보겠습니다. 아래와 같은 ...   아주 넉넉해요  \n",
       "..                                                 ...       ...  \n",
       "283   처음 입에 넣을 때 거부감 드는 향과 뒤에 매운 맛만 느껴짐참고서라도 먹고싶지 않은 맛   맛 평가 없음  \n",
       "284  맛과 어울리지도 않게 맵기만함고급스러운 매운맛이 아니고 싼매운맛. 유통기한 끝나가는...  적당히 남았어요  \n",
       "285      마라향이 뭔가 조화롭지않아서 좀 인위적인?느낌의 향만나고우선 진짜 너무 맵기만해요  적당히 남았어요  \n",
       "286  짜파게티도 맛있고 블랙도 맛있는데이건 영.....마라향이 확 나는게 아니라서 이상함...   아주 넉넉해요  \n",
       "287                       마라의 얼얼함이 아니라 그냥 캡사이신의 매움입니다;   아주 넉넉해요  \n",
       "\n",
       "[264 rows x 5 columns]"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "filtered_data_oranda = data_oranda[data_oranda[\"리뷰 내용\"] != \"등록된 리뷰내용이 없습니다\"]\n",
    "filtered_data_oranda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = filtered_data_oranda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(264, 5)"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평점별 개수:\n",
      "평점\n",
      "1     22\n",
      "2     12\n",
      "3     21\n",
      "4     34\n",
      "5    175\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 평점별 개수 계산\n",
    "rating_counts = df['평점'].value_counts().sort_index()\n",
    "\n",
    "# 결과 출력\n",
    "print(\"평점별 개수:\")\n",
    "print(rating_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "불용어 제거 & 특수문자 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Kkma #형태소 분석기\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "kkma = Kkma()\n",
    "okt = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>이름</th>\n",
       "      <th>작성일자</th>\n",
       "      <th>평점</th>\n",
       "      <th>리뷰 내용</th>\n",
       "      <th>맛 만족도</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>박*혜</td>\n",
       "      <td>2025.01.14</td>\n",
       "      <td>5</td>\n",
       "      <td>짜파게티 마라, 어떤 제품일까?먼저 짜파게티 마라의 기본 정보를 알아보았어요. 이 ...</td>\n",
       "      <td>아주 넉넉해요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dimss</td>\n",
       "      <td>2025.01.13</td>\n",
       "      <td>4</td>\n",
       "      <td>안녕하세요!! 리뷰하는 dimss입니다^^오늘도 솔직 사용후기 들고 왔어요❤️⬇️⬇...</td>\n",
       "      <td>적당히 남았어요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>이*람</td>\n",
       "      <td>2025.01.12</td>\n",
       "      <td>5</td>\n",
       "      <td>### 구매 계기매운 음식을 좋아하는 저는 최근 마라탕이나 마라샹궈와 같은 마라 요...</td>\n",
       "      <td>적당히 남았어요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>시마에나가</td>\n",
       "      <td>2025.01.11</td>\n",
       "      <td>4</td>\n",
       "      <td>⏹️ 요약 ⏹️✅ 구성 - 면, 후레이크, 짜장스프, 마라조미유✅ 맛 - 맵찔이 먹...</td>\n",
       "      <td>적당히 남았어요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>김*수</td>\n",
       "      <td>2025.01.11</td>\n",
       "      <td>5</td>\n",
       "      <td>짜파게티 마라를 구매한 후기를 이모티콘을 활용하여 작성해 보겠습니다. 아래와 같은 ...</td>\n",
       "      <td>아주 넉넉해요</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      이름        작성일자  평점                                              리뷰 내용  \\\n",
       "0    박*혜  2025.01.14   5  짜파게티 마라, 어떤 제품일까?먼저 짜파게티 마라의 기본 정보를 알아보았어요. 이 ...   \n",
       "1  dimss  2025.01.13   4  안녕하세요!! 리뷰하는 dimss입니다^^오늘도 솔직 사용후기 들고 왔어요❤️⬇️⬇...   \n",
       "2    이*람  2025.01.12   5  ### 구매 계기매운 음식을 좋아하는 저는 최근 마라탕이나 마라샹궈와 같은 마라 요...   \n",
       "3  시마에나가  2025.01.11   4  ⏹️ 요약 ⏹️✅ 구성 - 면, 후레이크, 짜장스프, 마라조미유✅ 맛 - 맵찔이 먹...   \n",
       "4    김*수  2025.01.11   5  짜파게티 마라를 구매한 후기를 이모티콘을 활용하여 작성해 보겠습니다. 아래와 같은 ...   \n",
       "\n",
       "      맛 만족도  \n",
       "0   아주 넉넉해요  \n",
       "1  적당히 남았어요  \n",
       "2  적당히 남았어요  \n",
       "3  적당히 남았어요  \n",
       "4   아주 넉넉해요  "
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training was done. used memory 0.472 Gby 0.472 Gb\n",
      "all cohesion probabilities was computed. # words = 1622\n",
      "all branching entropies was computed # words = 3061\n",
      "all accessor variety was computed # words = 3061\n"
     ]
    }
   ],
   "source": [
    "from soynlp.word import WordExtractor\n",
    "\n",
    "\n",
    "# WordExtractor를 사용하여 scores 생성\n",
    "word_extractor = WordExtractor()\n",
    "word_extractor.train(df['리뷰 내용'].tolist())\n",
    "word_scores = word_extractor.extract()\n",
    "\n",
    "# scores 사전 생성\n",
    "scores = {word: score.cohesion_forward for word, score in word_scores.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "from soynlp.tokenizer import LTokenizer\n",
    "from soynlp.tokenizer import MaxScoreTokenizer\n",
    "\n",
    "# LTokenizer 초기화\n",
    "ltokenizer = LTokenizer(scores=scores)\n",
    "maxscore_tokenizer = MaxScoreTokenizer(scores=scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykospacing import Spacing #한글 문장에서 띄어쓰기 보정 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacing = Spacing()  # Spacing 객체 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sys.path.append(os.path.dirname('PyKoSpacing/'))\n",
    "\n",
    "# spacing = Spacing()  # Spacing 객체 초기화\n",
    "# pip install git+https://github.com/haven-jeon/PyKoSpacing.git\n",
    "\n",
    "\n",
    "def preprocessing(df, review_column, istokenize=True, isnoun=False, filter=None):\n",
    "    \"\"\"\n",
    "    리뷰 데이터 전처리 함수.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): 입력 데이터프레임.\n",
    "        review_column (str): 리뷰 내용이 있는 열의 이름.\n",
    "        isnoun (bool): True일 경우 명사/대명사만 추출, False일 경우 모든 토큰 유지.\n",
    "        istokenize (bool): True일 경우 토큰화 사용, False일 경우 원문을 그대로 처리.\n",
    "        filter (str): 제거할 단어 리스트 (옵션).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: 전처리된 결과를 추가한 데이터프레임.\n",
    "    \"\"\"\n",
    "    #spaceing 객체 정의 및 초기화\n",
    "    spacing = Spacing()\n",
    "    processed_reviews  = []\n",
    "    #인풋리뷰\n",
    "    for idx, r in enumerate(df[review_column]):\n",
    "        #하나의 리뷰에서 문장 단위로 자르기\n",
    "        #불필요한 정보제거 name의 각 단어를 review에서 제거 \n",
    "        # 이름이 주어졌을 경우에만 이름 정보 제거\n",
    "        if filter:\n",
    "            filter_parts = filter.split(' ')\n",
    "            for part in filter_parts:\n",
    "                r = re.sub(part, '', r)\n",
    "        sentence = r\n",
    "\n",
    "        # #spacing 적용 \n",
    "        # sentence = sentence.replace(\" \", '')\n",
    "        \n",
    "        # sentence = spacing(sentence) \n",
    "\n",
    "        #특수문자, 영어 알파벳, 초성/중성/종성(예: \"ㄱ\", \"ㅏ\" 등)을 제거.\n",
    "        sentence = re.sub('\\n','',sentence)\n",
    "        sentence = re.sub('\\u200b','',sentence)\n",
    "        sentence = re.sub('\\xa0','',sentence)\n",
    "        sentence = re.sub('([a-zA-Z])','',sentence)\n",
    "        sentence = re.sub('[ㄱ-ㅎㅏ-ㅣ]+','',sentence)\n",
    "        sentence = re.sub('[-=+,#/\\?:^$.@*\\\"※~&%ㆍ!』\\\\‘|\\(\\)\\[\\]\\<\\>`\\'…》]','',sentence)\n",
    "        sentence = re.sub(r'\\s+', ' ', sentence)  # 다중 공백 -> 단일 공백\n",
    "        sentence = re.sub(r'[^\\w\\s]', '', sentence)  # 특수문자 제거\n",
    "        sentence = re.sub(r'\\d+', '', sentence)  # 숫자 제거\n",
    "        #전처리 후 문장이 비어있으면 다음 리뷰로 넘어감 \n",
    "        if len(sentence) == 0:\n",
    "            continue\n",
    "      \n",
    "      # 토큰화 여부 확인\n",
    "        if istokenize:\n",
    "            tokens = ltokenizer.tokenize(sentence)  # LTokenizer를 이용한 토큰화\n",
    "        else:\n",
    "            tokens = [sentence]  # 토큰화하지 않고 원문 사용\n",
    "        \n",
    "        if isnoun: \n",
    "            # 형태소 분석 및 품사 필터링 (명사/대명사만 추출)\n",
    "            filtered_tokens = []\n",
    "            for token in tokens:\n",
    "                pos = okt.pos(token)  # 품사 태깅\n",
    "                for word, tag in pos:\n",
    "                    if tag in ['Noun', 'Pronoun']:  # 명사 또는 대명사만 선택\n",
    "                        filtered_tokens.append(word)\n",
    "        else:\n",
    "            filtered_tokens = tokens\n",
    "\n",
    "        # 길이가 1인 단어 제거\n",
    "        filtered_tokens = [token for token in filtered_tokens if len(token) > 1]\n",
    "\n",
    "        # 토큰을 공백으로 연결하고 마침표 추가\n",
    "        processed_sentence = ' '.join(filtered_tokens)\n",
    "        processed_reviews.append(processed_sentence)\n",
    "        \n",
    "    return pd.Series(processed_reviews)  # 시리즈 형태로 반환\n",
    "    #     #동사를 기본형으로 변환\n",
    "    #     sentence = okt.pos(sentence, stem = True)\n",
    "    #     word = []\n",
    "    #     #명사가 아닌 경우 건너띔(list에 추가 안함함)\n",
    "    #     for i in sentence:\n",
    "    #         if not i[1] == 'Noun':\n",
    "    #             continue\n",
    "    #         if len(i[0]) == 1:\n",
    "    #             continue\n",
    "    #         word.append(i[0])\n",
    "    #     #단어들을 공백으로 연결하여 하나의 문장으로 변환\n",
    "    #     #문장 끝에 마침표 추가\n",
    "    #     #전체 리뷰에 추가\n",
    "    #     word = ' '.join(word)\n",
    "    #     word += '. '\n",
    "    #     total_review += word\n",
    "    # return total_review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spacing 추가시 꽤 시간이 오래 걸림\n",
    "- 1분 50초~2분20초\n",
    "\n",
    "빼면 0.1초"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zin\\AppData\\Local\\Temp\\ipykernel_20828\\2134030190.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['preprocessed_review'] = preprocessing(\n"
     ]
    }
   ],
   "source": [
    "# 전처리 실행\n",
    "df['preprocessed_review'] = preprocessing(\n",
    "    df, \n",
    "    review_column='리뷰 내용', \n",
    "    isnoun=False,  # 명사와 대명사만 추출\n",
    "    istokenize=True  # 토큰화 사용\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>이름</th>\n",
       "      <th>작성일자</th>\n",
       "      <th>평점</th>\n",
       "      <th>리뷰 내용</th>\n",
       "      <th>맛 만족도</th>\n",
       "      <th>preprocessed_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>박*혜</td>\n",
       "      <td>2025.01.14</td>\n",
       "      <td>5</td>\n",
       "      <td>짜파게티 마라, 어떤 제품일까?먼저 짜파게티 마라의 기본 정보를 알아보았어요. 이 ...</td>\n",
       "      <td>아주 넉넉해요</td>\n",
       "      <td>짜파게티 마라 어떤 제품 일까먼저 짜파게티 마라 기본 정보를 알아보았어요 제품 유명...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dimss</td>\n",
       "      <td>2025.01.13</td>\n",
       "      <td>4</td>\n",
       "      <td>안녕하세요!! 리뷰하는 dimss입니다^^오늘도 솔직 사용후기 들고 왔어요❤️⬇️⬇...</td>\n",
       "      <td>적당히 남았어요</td>\n",
       "      <td>안녕하세요 리뷰 하는 입니다 오늘도 솔직 사용후기 들고 왔어요짜파게티 마라 솔직 후...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>이*람</td>\n",
       "      <td>2025.01.12</td>\n",
       "      <td>5</td>\n",
       "      <td>### 구매 계기매운 음식을 좋아하는 저는 최근 마라탕이나 마라샹궈와 같은 마라 요...</td>\n",
       "      <td>적당히 남았어요</td>\n",
       "      <td>구매 계기매운 음식 좋아 하는 저는 최근 마라 탕이나 마라 샹궈와 같은 마라 요리 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>시마에나가</td>\n",
       "      <td>2025.01.11</td>\n",
       "      <td>4</td>\n",
       "      <td>⏹️ 요약 ⏹️✅ 구성 - 면, 후레이크, 짜장스프, 마라조미유✅ 맛 - 맵찔이 먹...</td>\n",
       "      <td>적당히 남았어요</td>\n",
       "      <td>요약 구성 후레이크 짜장스프 마라 조미유 맵찔이 먹으면 안됨 그냥 매운 마라 구매 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>김*수</td>\n",
       "      <td>2025.01.11</td>\n",
       "      <td>5</td>\n",
       "      <td>짜파게티 마라를 구매한 후기를 이모티콘을 활용하여 작성해 보겠습니다. 아래와 같은 ...</td>\n",
       "      <td>아주 넉넉해요</td>\n",
       "      <td>짜파게티 마라 구매 후기 이모티콘을 활용 하여 작성해 보겠습니다 아래와 같은 방식 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      이름        작성일자  평점                                              리뷰 내용  \\\n",
       "0    박*혜  2025.01.14   5  짜파게티 마라, 어떤 제품일까?먼저 짜파게티 마라의 기본 정보를 알아보았어요. 이 ...   \n",
       "1  dimss  2025.01.13   4  안녕하세요!! 리뷰하는 dimss입니다^^오늘도 솔직 사용후기 들고 왔어요❤️⬇️⬇...   \n",
       "2    이*람  2025.01.12   5  ### 구매 계기매운 음식을 좋아하는 저는 최근 마라탕이나 마라샹궈와 같은 마라 요...   \n",
       "3  시마에나가  2025.01.11   4  ⏹️ 요약 ⏹️✅ 구성 - 면, 후레이크, 짜장스프, 마라조미유✅ 맛 - 맵찔이 먹...   \n",
       "4    김*수  2025.01.11   5  짜파게티 마라를 구매한 후기를 이모티콘을 활용하여 작성해 보겠습니다. 아래와 같은 ...   \n",
       "\n",
       "      맛 만족도                                preprocessed_review  \n",
       "0   아주 넉넉해요  짜파게티 마라 어떤 제품 일까먼저 짜파게티 마라 기본 정보를 알아보았어요 제품 유명...  \n",
       "1  적당히 남았어요  안녕하세요 리뷰 하는 입니다 오늘도 솔직 사용후기 들고 왔어요짜파게티 마라 솔직 후...  \n",
       "2  적당히 남았어요  구매 계기매운 음식 좋아 하는 저는 최근 마라 탕이나 마라 샹궈와 같은 마라 요리 ...  \n",
       "3  적당히 남았어요  요약 구성 후레이크 짜장스프 마라 조미유 맵찔이 먹으면 안됨 그냥 매운 마라 구매 ...  \n",
       "4   아주 넉넉해요  짜파게티 마라 구매 후기 이모티콘을 활용 하여 작성해 보겠습니다 아래와 같은 방식 ...  "
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "특정 단어 제거(이벤트, 체험단 등)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def remove_rows_with_keywords(dataframe, column_name, keywords):\n",
    "#     \"\"\"\n",
    "#     특정 단어가 포함된 문장을 제거하는 함수.\n",
    "\n",
    "#     Args:\n",
    "#         dataframe (pd.DataFrame): 데이터프레임\n",
    "#         column_name (str): 처리할 열 이름\n",
    "#         keywords (list): 제거할 단어 리스트\n",
    "\n",
    "#     Returns:\n",
    "#         pd.DataFrame: 특정 단어가 포함된 행이 제거된 데이터프레임\n",
    "#     \"\"\"\n",
    "#     # 특정 단어가 포함된 행 제거\n",
    "#     pattern = \"|\".join(keywords)  # 키워드 리스트를 정규식 패턴으로 변환\n",
    "#     filtered_df = dataframe[~dataframe[column_name].str.contains(pattern, na=False)]\n",
    "#     return filtered_df\n",
    "\n",
    "# # 사용 예시\n",
    "# keywords = [\"이벤트\", \"체험단\"]\n",
    "# filtered_data_oranda = remove_rows_with_keywords(data_oranda, \"리뷰 내용\", keywords)\n",
    "\n",
    "# # 결과 확인\n",
    "# print(filtered_data_oranda)\n",
    "# len(filtered_data_oranda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 키워드 뽑기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Case1: 리뷰 별점 구분없이 키워드 뽑기 vs 리뷰 평점별로 키워드 뽑기\n",
    "\n",
    "Case2: 문장 별로 나누어서 키워드 뽑기 vs 문장 분리 하지 말기\n",
    "- 일단 문장 분리하면 키워드가 뽑히지 않는 경우도 있음(문장이 너무 짧아서)\n",
    "\n",
    "\n",
    "Case3: 명사만 이용\n",
    "\n",
    "https://chaeeunsong.tistory.com/26 참고고\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "키워드 후보군 DB 만들기 -> 키워드 선정?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model1: summarize_with_sentences / KR-WordRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "from krwordrank.sentence import summarize_with_sentences\n",
    "\n",
    "def df_sumWordSentence(df, review_col, rate_col=None, filter=None, top_k=5, num_keywords=5, num_keysents=2, full_merge=False, rate_merge=False):\n",
    "    \"\"\"\n",
    "    데이터프레임에서 특정 열을 전처리하고 키워드 추출 결과를 데이터프레임에 저장.\n",
    "\n",
    "    Parameters:\n",
    "    - df: pd.DataFrame - 입력 데이터프레임\n",
    "    - review_col: str - 리뷰 내용을 포함하는 열 이름\n",
    "    - rate_col: str - 평점 열의 이름 (rate_merge=True인 경우 필요)\n",
    "    - filter: list[str] - 필터링할 단어 목록\n",
    "    - top_k: int - 각 리뷰별 상위 키워드 개수\n",
    "    - num_keywords: int - 추출할 키워드 개수\n",
    "    - num_keysents: int - 추출할 중요 문장 개수\n",
    "    - full_merge: bool - True일 경우 모든 리뷰를 합쳐서 처리\n",
    "    - rate_merge: bool - True일 경우 평점별로 리뷰를 합쳐서 처리\n",
    "\n",
    "    Returns:\n",
    "    - result_df: pd.DataFrame - 키워드 열이 추가된 데이터프레임\n",
    "    \"\"\"\n",
    "\n",
    "    if num_keywords < top_k:\n",
    "        num_keywords = top_k\n",
    "        \n",
    "    def extract_keywords(texts, stopwords=None):\n",
    "        # 필터링 처리\n",
    "        if filter:\n",
    "            for word in filter:\n",
    "                texts = texts.replace(word, '')\n",
    "        try:\n",
    "            keywords, _ = summarize_with_sentences(\n",
    "                texts,\n",
    "                stopwords=stopwords,\n",
    "                num_keywords=num_keywords,\n",
    "                num_keysents=num_keysents\n",
    "            )\n",
    "            top_keywords = sorted(keywords.items(), key=lambda x: x[1], reverse=True)[:top_k]\n",
    "            return [word for word, _ in top_keywords]\n",
    "        except ValueError:\n",
    "            return None\n",
    "\n",
    "    if full_merge:\n",
    "        # 모든 리뷰를 하나로 합쳐 처리\n",
    "        merged_reviews = '. '.join(df[review_col].dropna())\n",
    "        texts = merged_reviews.split('. ')\n",
    "        keywords = extract_keywords(texts)\n",
    "        result_df = pd.DataFrame({'merge_type': ['full'], 'keywords': [keywords]})\n",
    "        return result_df\n",
    "\n",
    "    if rate_merge:\n",
    "        # 평점별로 리뷰를 합쳐 처리\n",
    "        if rate_col is None:\n",
    "            raise ValueError(\"rate_merge=True 인 경우, rate_col을 지정해야 합니다.\")\n",
    "        \n",
    "        rate_keywords = []\n",
    "        for rate, group in df.groupby(rate_col):\n",
    "            merged_reviews = '. '.join(group[review_col].dropna())\n",
    "            texts = merged_reviews.split('. ')\n",
    "            keywords = extract_keywords(texts)\n",
    "            rate_keywords.append({'rate': rate, 'keywords': keywords})\n",
    "        \n",
    "        result_df = pd.DataFrame(rate_keywords)\n",
    "        return result_df\n",
    "\n",
    "    # 기본: 각 리뷰별 처리\n",
    "    else:\n",
    "        krwordrank_results = []\n",
    "        for idx, row in df.iterrows():\n",
    "            review_content = row[review_col]\n",
    "            if pd.isna(review_content):\n",
    "                krwordrank_results.append(None)\n",
    "                continue\n",
    "            \n",
    "            # 필터링 처리\n",
    "            if filter:\n",
    "                for word in filter:\n",
    "                    review_content = review_content.replace(word, '')\n",
    "            \n",
    "            # 문장 리스트\n",
    "            texts = review_content.split('. ')\n",
    "            keywords = extract_keywords(texts)\n",
    "            krwordrank_results.append(keywords)\n",
    "\n",
    "        # 새로운 열 추가\n",
    "        df['krwordrank'] = krwordrank_results\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>이름</th>\n",
       "      <th>작성일자</th>\n",
       "      <th>평점</th>\n",
       "      <th>리뷰 내용</th>\n",
       "      <th>맛 만족도</th>\n",
       "      <th>preprocessed_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>박*혜</td>\n",
       "      <td>2025.01.14</td>\n",
       "      <td>5</td>\n",
       "      <td>짜파게티 마라, 어떤 제품일까?먼저 짜파게티 마라의 기본 정보를 알아보았어요. 이 ...</td>\n",
       "      <td>아주 넉넉해요</td>\n",
       "      <td>짜파게티 마라 어떤 제품 일까먼저 짜파게티 마라 기본 정보를 알아보았어요 제품 유명...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dimss</td>\n",
       "      <td>2025.01.13</td>\n",
       "      <td>4</td>\n",
       "      <td>안녕하세요!! 리뷰하는 dimss입니다^^오늘도 솔직 사용후기 들고 왔어요❤️⬇️⬇...</td>\n",
       "      <td>적당히 남았어요</td>\n",
       "      <td>안녕하세요 리뷰 하는 입니다 오늘도 솔직 사용후기 들고 왔어요짜파게티 마라 솔직 후...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>이*람</td>\n",
       "      <td>2025.01.12</td>\n",
       "      <td>5</td>\n",
       "      <td>### 구매 계기매운 음식을 좋아하는 저는 최근 마라탕이나 마라샹궈와 같은 마라 요...</td>\n",
       "      <td>적당히 남았어요</td>\n",
       "      <td>구매 계기매운 음식 좋아 하는 저는 최근 마라 탕이나 마라 샹궈와 같은 마라 요리 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>시마에나가</td>\n",
       "      <td>2025.01.11</td>\n",
       "      <td>4</td>\n",
       "      <td>⏹️ 요약 ⏹️✅ 구성 - 면, 후레이크, 짜장스프, 마라조미유✅ 맛 - 맵찔이 먹...</td>\n",
       "      <td>적당히 남았어요</td>\n",
       "      <td>요약 구성 후레이크 짜장스프 마라 조미유 맵찔이 먹으면 안됨 그냥 매운 마라 구매 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>김*수</td>\n",
       "      <td>2025.01.11</td>\n",
       "      <td>5</td>\n",
       "      <td>짜파게티 마라를 구매한 후기를 이모티콘을 활용하여 작성해 보겠습니다. 아래와 같은 ...</td>\n",
       "      <td>아주 넉넉해요</td>\n",
       "      <td>짜파게티 마라 구매 후기 이모티콘을 활용 하여 작성해 보겠습니다 아래와 같은 방식 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      이름        작성일자  평점                                              리뷰 내용  \\\n",
       "0    박*혜  2025.01.14   5  짜파게티 마라, 어떤 제품일까?먼저 짜파게티 마라의 기본 정보를 알아보았어요. 이 ...   \n",
       "1  dimss  2025.01.13   4  안녕하세요!! 리뷰하는 dimss입니다^^오늘도 솔직 사용후기 들고 왔어요❤️⬇️⬇...   \n",
       "2    이*람  2025.01.12   5  ### 구매 계기매운 음식을 좋아하는 저는 최근 마라탕이나 마라샹궈와 같은 마라 요...   \n",
       "3  시마에나가  2025.01.11   4  ⏹️ 요약 ⏹️✅ 구성 - 면, 후레이크, 짜장스프, 마라조미유✅ 맛 - 맵찔이 먹...   \n",
       "4    김*수  2025.01.11   5  짜파게티 마라를 구매한 후기를 이모티콘을 활용하여 작성해 보겠습니다. 아래와 같은 ...   \n",
       "\n",
       "      맛 만족도                                preprocessed_review  \n",
       "0   아주 넉넉해요  짜파게티 마라 어떤 제품 일까먼저 짜파게티 마라 기본 정보를 알아보았어요 제품 유명...  \n",
       "1  적당히 남았어요  안녕하세요 리뷰 하는 입니다 오늘도 솔직 사용후기 들고 왔어요짜파게티 마라 솔직 후...  \n",
       "2  적당히 남았어요  구매 계기매운 음식 좋아 하는 저는 최근 마라 탕이나 마라 샹궈와 같은 마라 요리 ...  \n",
       "3  적당히 남았어요  요약 구성 후레이크 짜장스프 마라 조미유 맵찔이 먹으면 안됨 그냥 매운 마라 구매 ...  \n",
       "4   아주 넉넉해요  짜파게티 마라 구매 후기 이모티콘을 활용 하여 작성해 보겠습니다 아래와 같은 방식 ...  "
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 함수 호출\n",
    "full_merge_df  = df_sumWordSentence(df, review_col='preprocessed_review', top_k=10, full_merge=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.4초"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>merge_type</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>full</td>\n",
       "      <td>[마라, 짜파게티, 매운, 좋아, 맛이, 맛있, 얼얼, 생각, 해서, 하는]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  merge_type                                    keywords\n",
       "0       full  [마라, 짜파게티, 매운, 좋아, 맛이, 맛있, 얼얼, 생각, 해서, 하는]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_merge_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 평점별로 리뷰를 묶어서 키워드 추출\n",
    "rate_merge_df = df_sumWordSentence(df, review_col='preprocessed_review', rate_col='평점', rate_merge=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rate</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[마라, 짜파게티]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[마라, 짜파게티, 맛이, 매운, 불닭]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[마라, 짜파게티, 매운, 맛이, 좋아]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[마라, 짜파게티, 매운, 좋아, 맛이]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rate                keywords\n",
       "0     1                    None\n",
       "1     2              [마라, 짜파게티]\n",
       "2     3  [마라, 짜파게티, 맛이, 매운, 불닭]\n",
       "3     4  [마라, 짜파게티, 매운, 맛이, 좋아]\n",
       "4     5  [마라, 짜파게티, 매운, 좋아, 맛이]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rate_merge_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zin\\AppData\\Local\\Temp\\ipykernel_20828\\907698646.py:85: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['krwordrank'] = krwordrank_results\n"
     ]
    }
   ],
   "source": [
    "# 3. 각 리뷰별로 처리\n",
    "individual_df = df_sumWordSentence(df, review_col='preprocessed_review', top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>이름</th>\n",
       "      <th>작성일자</th>\n",
       "      <th>평점</th>\n",
       "      <th>리뷰 내용</th>\n",
       "      <th>맛 만족도</th>\n",
       "      <th>preprocessed_review</th>\n",
       "      <th>krwordrank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>박*혜</td>\n",
       "      <td>2025.01.14</td>\n",
       "      <td>5</td>\n",
       "      <td>짜파게티 마라, 어떤 제품일까?먼저 짜파게티 마라의 기본 정보를 알아보았어요. 이 ...</td>\n",
       "      <td>아주 넉넉해요</td>\n",
       "      <td>짜파게티 마라 어떤 제품 일까먼저 짜파게티 마라 기본 정보를 알아보았어요 제품 유명...</td>\n",
       "      <td>[마라]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dimss</td>\n",
       "      <td>2025.01.13</td>\n",
       "      <td>4</td>\n",
       "      <td>안녕하세요!! 리뷰하는 dimss입니다^^오늘도 솔직 사용후기 들고 왔어요❤️⬇️⬇...</td>\n",
       "      <td>적당히 남았어요</td>\n",
       "      <td>안녕하세요 리뷰 하는 입니다 오늘도 솔직 사용후기 들고 왔어요짜파게티 마라 솔직 후...</td>\n",
       "      <td>[마라, 분들, 짜파]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>이*람</td>\n",
       "      <td>2025.01.12</td>\n",
       "      <td>5</td>\n",
       "      <td>### 구매 계기매운 음식을 좋아하는 저는 최근 마라탕이나 마라샹궈와 같은 마라 요...</td>\n",
       "      <td>적당히 남았어요</td>\n",
       "      <td>구매 계기매운 음식 좋아 하는 저는 최근 마라 탕이나 마라 샹궈와 같은 마라 요리 ...</td>\n",
       "      <td>[마라, 매운, 맛이, 정말, 국물]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>시마에나가</td>\n",
       "      <td>2025.01.11</td>\n",
       "      <td>4</td>\n",
       "      <td>⏹️ 요약 ⏹️✅ 구성 - 면, 후레이크, 짜장스프, 마라조미유✅ 맛 - 맵찔이 먹...</td>\n",
       "      <td>적당히 남았어요</td>\n",
       "      <td>요약 구성 후레이크 짜장스프 마라 조미유 맵찔이 먹으면 안됨 그냥 매운 마라 구매 ...</td>\n",
       "      <td>[마라, 넣고, 짜파, 먹어]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>김*수</td>\n",
       "      <td>2025.01.11</td>\n",
       "      <td>5</td>\n",
       "      <td>짜파게티 마라를 구매한 후기를 이모티콘을 활용하여 작성해 보겠습니다. 아래와 같은 ...</td>\n",
       "      <td>아주 넉넉해요</td>\n",
       "      <td>짜파게티 마라 구매 후기 이모티콘을 활용 하여 작성해 보겠습니다 아래와 같은 방식 ...</td>\n",
       "      <td>[마라, 매운, 맛이]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      이름        작성일자  평점                                              리뷰 내용  \\\n",
       "0    박*혜  2025.01.14   5  짜파게티 마라, 어떤 제품일까?먼저 짜파게티 마라의 기본 정보를 알아보았어요. 이 ...   \n",
       "1  dimss  2025.01.13   4  안녕하세요!! 리뷰하는 dimss입니다^^오늘도 솔직 사용후기 들고 왔어요❤️⬇️⬇...   \n",
       "2    이*람  2025.01.12   5  ### 구매 계기매운 음식을 좋아하는 저는 최근 마라탕이나 마라샹궈와 같은 마라 요...   \n",
       "3  시마에나가  2025.01.11   4  ⏹️ 요약 ⏹️✅ 구성 - 면, 후레이크, 짜장스프, 마라조미유✅ 맛 - 맵찔이 먹...   \n",
       "4    김*수  2025.01.11   5  짜파게티 마라를 구매한 후기를 이모티콘을 활용하여 작성해 보겠습니다. 아래와 같은 ...   \n",
       "\n",
       "      맛 만족도                                preprocessed_review  \\\n",
       "0   아주 넉넉해요  짜파게티 마라 어떤 제품 일까먼저 짜파게티 마라 기본 정보를 알아보았어요 제품 유명...   \n",
       "1  적당히 남았어요  안녕하세요 리뷰 하는 입니다 오늘도 솔직 사용후기 들고 왔어요짜파게티 마라 솔직 후...   \n",
       "2  적당히 남았어요  구매 계기매운 음식 좋아 하는 저는 최근 마라 탕이나 마라 샹궈와 같은 마라 요리 ...   \n",
       "3  적당히 남았어요  요약 구성 후레이크 짜장스프 마라 조미유 맵찔이 먹으면 안됨 그냥 매운 마라 구매 ...   \n",
       "4   아주 넉넉해요  짜파게티 마라 구매 후기 이모티콘을 활용 하여 작성해 보겠습니다 아래와 같은 방식 ...   \n",
       "\n",
       "             krwordrank  \n",
       "0                  [마라]  \n",
       "1          [마라, 분들, 짜파]  \n",
       "2  [마라, 매운, 맛이, 정말, 국물]  \n",
       "3      [마라, 넣고, 짜파, 먹어]  \n",
       "4          [마라, 매운, 맛이]  "
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "individual_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "individual_df.to_csv(\"../result/df_sumWordSentence.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>이름</th>\n",
       "      <th>작성일자</th>\n",
       "      <th>평점</th>\n",
       "      <th>리뷰 내용</th>\n",
       "      <th>맛 만족도</th>\n",
       "      <th>preprocessed_review</th>\n",
       "      <th>krwordrank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>lovenpeace</td>\n",
       "      <td>2024.12.27</td>\n",
       "      <td>2</td>\n",
       "      <td>사천짜장까지는 맛있게 잘 먹지만이건 마라 특유의 향이 짜장 맛을 가립니다.마라 7대...</td>\n",
       "      <td>아주 넉넉해요</td>\n",
       "      <td>사천짜 장까지는 맛있 먹지만이건 마라 특유의 향이 짜장 맛을 가립니다마라 짜장 정도...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>김*림</td>\n",
       "      <td>2024.12.25</td>\n",
       "      <td>2</td>\n",
       "      <td>평소에 짜파게티와 사천짜파게티 둘 다 아주 좋아해서 이번 신상품도 기대하고 사전예약...</td>\n",
       "      <td>아주 넉넉해요</td>\n",
       "      <td>평소 짜파게티 사천짜파게티 아주 좋아 해서 이번 신상 품도 기대 하고 사전예약 으로...</td>\n",
       "      <td>[짜파]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>우*준</td>\n",
       "      <td>2024.12.29</td>\n",
       "      <td>2</td>\n",
       "      <td>1개 먹고나서 나머지 3개는 잘 안먹을 것 같은 느낌이 듭니다.라면을 개발하는 과정...</td>\n",
       "      <td>아주 넉넉해요</td>\n",
       "      <td>먹고 나서 나머지 개는 안먹 같은 느낌이 듭니다라면을 개발하는 과정에서 본인들도 만...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>김*희</td>\n",
       "      <td>2025.01.01</td>\n",
       "      <td>2</td>\n",
       "      <td>생각보다 맵고 처음 먹어보는거라 3봉 삶을때 액상소스 1개만 넣었는데도 액상소스의 ...</td>\n",
       "      <td>아주 넉넉해요</td>\n",
       "      <td>생각 보다 맵고 처음 먹어보 는거라 삶을때 액상소스 개만 넣었는데 액상소스의 마라 ...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>홍*진</td>\n",
       "      <td>2024.12.29</td>\n",
       "      <td>2</td>\n",
       "      <td>맵고 맛은그냥그래요 마라맛은약하고 맵기만</td>\n",
       "      <td>아주 넉넉해요</td>\n",
       "      <td>너무 매워요</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>송*한</td>\n",
       "      <td>2024.12.25</td>\n",
       "      <td>2</td>\n",
       "      <td>이건 아니다 그냥 짜파게티는 못이긴다</td>\n",
       "      <td>아주 넉넉해요</td>\n",
       "      <td>스프 넣지 않아 할듯 해요</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>코코블루</td>\n",
       "      <td>2025.01.03</td>\n",
       "      <td>2</td>\n",
       "      <td>다 깨져있어요</td>\n",
       "      <td>아주 넉넉해요</td>\n",
       "      <td>호불호 확실 맛전 완전 불호이네요마라 좋아 하시는분만드세요</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>류니네</td>\n",
       "      <td>2025.01.12</td>\n",
       "      <td>2</td>\n",
       "      <td>젊은 입맛에는 잘맞을 거 같아요첫입에 기침이 나올정도 매운맛인데 그다음부터는 많이 ...</td>\n",
       "      <td>아주 넉넉해요</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>김*숙</td>\n",
       "      <td>2025.01.14</td>\n",
       "      <td>2</td>\n",
       "      <td>정말 맛없네요.싸지도않고..이걸 사전예약해서 산게 우습게여겨질정도로 별로이구요.마라...</td>\n",
       "      <td>아주 넉넉해요</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>손*운</td>\n",
       "      <td>2024.12.28</td>\n",
       "      <td>2</td>\n",
       "      <td>생각보다 맵습니다.짜파게티와 마라 냄새가 어우러지지 않아서요상한 냄새가 납니다. 고...</td>\n",
       "      <td>아주 넉넉해요</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>송*성</td>\n",
       "      <td>2025.01.13</td>\n",
       "      <td>2</td>\n",
       "      <td>짜파게티도 좋아하고 마라도 좋아하는데 이건 맵기만 하고 진짜 맛 없어요하나 먹고 방...</td>\n",
       "      <td>아주 넉넉해요</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>김*내</td>\n",
       "      <td>2025.01.02</td>\n",
       "      <td>2</td>\n",
       "      <td>호불호 확실한 맛..전 완전 불호이네요ㅜㅜㅜ마라 좋아하시는.분만.드세요ㅠㅠ</td>\n",
       "      <td>적당히 남았어요</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             이름        작성일자  평점  \\\n",
       "215  lovenpeace  2024.12.27   2   \n",
       "216         김*림  2024.12.25   2   \n",
       "217         우*준  2024.12.29   2   \n",
       "218         김*희  2025.01.01   2   \n",
       "231         홍*진  2024.12.29   2   \n",
       "236         송*한  2024.12.25   2   \n",
       "244        코코블루  2025.01.03   2   \n",
       "264         류니네  2025.01.12   2   \n",
       "265         김*숙  2025.01.14   2   \n",
       "266         손*운  2024.12.28   2   \n",
       "267         송*성  2025.01.13   2   \n",
       "268         김*내  2025.01.02   2   \n",
       "\n",
       "                                                 리뷰 내용     맛 만족도  \\\n",
       "215  사천짜장까지는 맛있게 잘 먹지만이건 마라 특유의 향이 짜장 맛을 가립니다.마라 7대...   아주 넉넉해요   \n",
       "216  평소에 짜파게티와 사천짜파게티 둘 다 아주 좋아해서 이번 신상품도 기대하고 사전예약...   아주 넉넉해요   \n",
       "217  1개 먹고나서 나머지 3개는 잘 안먹을 것 같은 느낌이 듭니다.라면을 개발하는 과정...   아주 넉넉해요   \n",
       "218  생각보다 맵고 처음 먹어보는거라 3봉 삶을때 액상소스 1개만 넣었는데도 액상소스의 ...   아주 넉넉해요   \n",
       "231                             맵고 맛은그냥그래요 마라맛은약하고 맵기만   아주 넉넉해요   \n",
       "236                               이건 아니다 그냥 짜파게티는 못이긴다   아주 넉넉해요   \n",
       "244                                            다 깨져있어요   아주 넉넉해요   \n",
       "264  젊은 입맛에는 잘맞을 거 같아요첫입에 기침이 나올정도 매운맛인데 그다음부터는 많이 ...   아주 넉넉해요   \n",
       "265  정말 맛없네요.싸지도않고..이걸 사전예약해서 산게 우습게여겨질정도로 별로이구요.마라...   아주 넉넉해요   \n",
       "266  생각보다 맵습니다.짜파게티와 마라 냄새가 어우러지지 않아서요상한 냄새가 납니다. 고...   아주 넉넉해요   \n",
       "267  짜파게티도 좋아하고 마라도 좋아하는데 이건 맵기만 하고 진짜 맛 없어요하나 먹고 방...   아주 넉넉해요   \n",
       "268          호불호 확실한 맛..전 완전 불호이네요ㅜㅜㅜ마라 좋아하시는.분만.드세요ㅠㅠ  적당히 남았어요   \n",
       "\n",
       "                                   preprocessed_review krwordrank  \n",
       "215  사천짜 장까지는 맛있 먹지만이건 마라 특유의 향이 짜장 맛을 가립니다마라 짜장 정도...       None  \n",
       "216  평소 짜파게티 사천짜파게티 아주 좋아 해서 이번 신상 품도 기대 하고 사전예약 으로...       [짜파]  \n",
       "217  먹고 나서 나머지 개는 안먹 같은 느낌이 듭니다라면을 개발하는 과정에서 본인들도 만...       None  \n",
       "218  생각 보다 맵고 처음 먹어보 는거라 삶을때 액상소스 개만 넣었는데 액상소스의 마라 ...       None  \n",
       "231                                             너무 매워요       None  \n",
       "236                                     스프 넣지 않아 할듯 해요       None  \n",
       "244                   호불호 확실 맛전 완전 불호이네요마라 좋아 하시는분만드세요       None  \n",
       "264                                                NaN       None  \n",
       "265                                                NaN       None  \n",
       "266                                                NaN       None  \n",
       "267                                                NaN       None  \n",
       "268                                                NaN       None  "
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "individual_df_2 = individual_df[individual_df['평점'] == 2]\n",
    "individual_df_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model2: KR-WordRank / KR-WordRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "from krwordrank.word import KRWordRank\n",
    "\n",
    "def df_krwordRank(df, review_col, rate_col=None, filter=None, top_k=5, num_keywords=10, min_count=1, max_length=10, full_merge=False, rate_merge=False):\n",
    "    \"\"\"\n",
    "    데이터프레임에서 특정 열을 전처리하고 키워드 추출 결과를 데이터프레임에 저장.\n",
    "\n",
    "    Parameters:\n",
    "    - df: pd.DataFrame - 입력 데이터프레임\n",
    "    - review_col: str - 리뷰 내용을 포함하는 열 이름\n",
    "    - rate_col: str - 평점 열의 이름 (rate_merge=True인 경우 필요)\n",
    "    - filter: list[str] - 필터링할 단어 목록\n",
    "    - top_k: int - 각 리뷰별 상위 키워드 개수\n",
    "    - num_keywords: int - 추출할 키워드 개수\n",
    "    - min_count: int - 단어 최소 등장 빈도\n",
    "    - max_length: int - 단어 최대 길이\n",
    "    - full_merge: bool - True일 경우 모든 리뷰를 합쳐서 처리\n",
    "    - rate_merge: bool - True일 경우 평점별로 리뷰를 합쳐서 처리\n",
    "\n",
    "    Returns:\n",
    "    - result_df: pd.DataFrame - 키워드 열이 추가된 데이터프레임\n",
    "    \"\"\"\n",
    "    if num_keywords < top_k:\n",
    "        num_keywords = top_k\n",
    "    # KRWordRank 모델 초기화\n",
    "    krwordrank = KRWordRank(\n",
    "        min_count=min_count,\n",
    "        max_length=max_length,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    def extract_keywords(texts):\n",
    "        if not texts or len(' '.join(texts)) < 5:  # 텍스트가 비어있거나 너무 짧은 경우\n",
    "            print(\"To Short\")\n",
    "            return None\n",
    "        try:\n",
    "            result  = krwordrank.extract(\n",
    "                texts, \n",
    "                beta=0.25, \n",
    "                max_iter=50, \n",
    "                num_keywords=num_keywords\n",
    "            )\n",
    "            keywords = result[0]\n",
    "            top_keywords = sorted(keywords.items(), key=lambda x: x[1], reverse=True)[:top_k]\n",
    "            return [word for word, _ in top_keywords]\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            return None\n",
    "\n",
    "    if full_merge:\n",
    "        # 모든 리뷰를 하나로 합쳐 처리\n",
    "        merged_reviews = '. '.join(df[review_col].dropna())\n",
    "        texts = merged_reviews.split('. ')\n",
    "        keywords = extract_keywords(texts)\n",
    "        result_df = pd.DataFrame({'merge_type': ['full'], 'keywords': [keywords]})\n",
    "        return result_df\n",
    "\n",
    "    if rate_merge:\n",
    "        # 평점별로 리뷰를 합쳐 처리\n",
    "        if rate_col is None:\n",
    "            raise ValueError(\"rate_merge=True 인 경우, rate_col을 지정해야 합니다.\")\n",
    "        \n",
    "        rate_keywords = []\n",
    "        for rate, group in df.groupby(rate_col):\n",
    "            merged_reviews = '. '.join(group[review_col].dropna())\n",
    "            texts = merged_reviews.split('. ')\n",
    "            keywords = extract_keywords(texts)\n",
    "            rate_keywords.append({'rate': rate, 'keywords': keywords})\n",
    "        \n",
    "        result_df = pd.DataFrame(rate_keywords)\n",
    "        return result_df\n",
    "    \n",
    "    else:\n",
    "        # 기본: 각 리뷰별 처리\n",
    "        krwordrank_results = []\n",
    "        for idx, row in df.iterrows():\n",
    "            review_content = row[review_col]\n",
    "            if pd.isna(review_content):\n",
    "                krwordrank_results.append(None)\n",
    "                continue\n",
    "            \n",
    "            # 필터링 처리\n",
    "            if filter:\n",
    "                for word in filter:\n",
    "                    review_content = review_content.replace(word, '')\n",
    "            \n",
    "            # 문장 리스트\n",
    "            texts = review_content.split('. ')\n",
    "            keywords = extract_keywords(texts)\n",
    "            krwordrank_results.append(keywords)\n",
    "\n",
    "        # 새로운 열 추가\n",
    "        df['krwordrank'] = krwordrank_results\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 전체 리뷰를 합쳐 키워드 추출\n",
    "full_merge_df = df_krwordRank(df, review_col='preprocessed_review', top_k=10, full_merge=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2초"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>merge_type</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>full</td>\n",
       "      <td>[마라, 매운, 좋아, 맛이, 맛있, 구매, 짜파, 먹어, 조금, 생각]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  merge_type                                  keywords\n",
       "0       full  [마라, 매운, 좋아, 맛이, 맛있, 구매, 짜파, 먹어, 조금, 생각]"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_merge_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n"
     ]
    }
   ],
   "source": [
    "# 2. 평점별로 리뷰를 묶어서 키워드 추출\n",
    "rate_merge_df = df_krwordRank(df, review_col='preprocessed_review', rate_col='평점', rate_merge=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rate</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[그냥, 너무, 마라, 안한게, 매움입니다]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[마라, 매운, 매워서, 조금, 맛이]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[마라, 매운, 좋아, 맛있, 맛이]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rate                  keywords\n",
       "0     1  [그냥, 너무, 마라, 안한게, 매움입니다]\n",
       "1     2                      None\n",
       "2     3     [마라, 매운, 매워서, 조금, 맛이]\n",
       "3     4                      None\n",
       "4     5      [마라, 매운, 좋아, 맛있, 맛이]"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rate_merge_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n",
      "Error during keyword extraction: 'NoneType' object has no attribute 'items'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zin\\AppData\\Local\\Temp\\ipykernel_20828\\1560678071.py:100: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['krwordrank'] = krwordrank_results\n"
     ]
    }
   ],
   "source": [
    "# 3. 각 리뷰별로 처리\n",
    "individual_df = df_krwordRank(df, review_col='preprocessed_review', top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>이름</th>\n",
       "      <th>작성일자</th>\n",
       "      <th>평점</th>\n",
       "      <th>리뷰 내용</th>\n",
       "      <th>맛 만족도</th>\n",
       "      <th>preprocessed_review</th>\n",
       "      <th>krwordrank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>박*혜</td>\n",
       "      <td>2025.01.14</td>\n",
       "      <td>5</td>\n",
       "      <td>짜파게티 마라, 어떤 제품일까?먼저 짜파게티 마라의 기본 정보를 알아보았어요. 이 ...</td>\n",
       "      <td>아주 넉넉해요</td>\n",
       "      <td>짜파게티 마라 어떤 제품 일까먼저 짜파게티 마라 기본 정보를 알아보았어요 제품 유명...</td>\n",
       "      <td>[마라, 제품, 있어, 정말, 느낀]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dimss</td>\n",
       "      <td>2025.01.13</td>\n",
       "      <td>4</td>\n",
       "      <td>안녕하세요!! 리뷰하는 dimss입니다^^오늘도 솔직 사용후기 들고 왔어요❤️⬇️⬇...</td>\n",
       "      <td>적당히 남았어요</td>\n",
       "      <td>안녕하세요 리뷰 하는 입니다 오늘도 솔직 사용후기 들고 왔어요짜파게티 마라 솔직 후...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>이*람</td>\n",
       "      <td>2025.01.12</td>\n",
       "      <td>5</td>\n",
       "      <td>### 구매 계기매운 음식을 좋아하는 저는 최근 마라탕이나 마라샹궈와 같은 마라 요...</td>\n",
       "      <td>적당히 남았어요</td>\n",
       "      <td>구매 계기매운 음식 좋아 하는 저는 최근 마라 탕이나 마라 샹궈와 같은 마라 요리 ...</td>\n",
       "      <td>[마라, 했습니다, 짜파게티, 정말, 국물]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>시마에나가</td>\n",
       "      <td>2025.01.11</td>\n",
       "      <td>4</td>\n",
       "      <td>⏹️ 요약 ⏹️✅ 구성 - 면, 후레이크, 짜장스프, 마라조미유✅ 맛 - 맵찔이 먹...</td>\n",
       "      <td>적당히 남았어요</td>\n",
       "      <td>요약 구성 후레이크 짜장스프 마라 조미유 맵찔이 먹으면 안됨 그냥 매운 마라 구매 ...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>김*수</td>\n",
       "      <td>2025.01.11</td>\n",
       "      <td>5</td>\n",
       "      <td>짜파게티 마라를 구매한 후기를 이모티콘을 활용하여 작성해 보겠습니다. 아래와 같은 ...</td>\n",
       "      <td>아주 넉넉해요</td>\n",
       "      <td>짜파게티 마라 구매 후기 이모티콘을 활용 하여 작성해 보겠습니다 아래와 같은 방식 ...</td>\n",
       "      <td>[마라, 매운, 맛이, 조금, 하는]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>잔잔다에</td>\n",
       "      <td>2025.01.01</td>\n",
       "      <td>1</td>\n",
       "      <td>처음 입에 넣을 때 거부감 드는 향과 뒤에 매운 맛만 느껴짐참고서라도 먹고싶지 않은 맛</td>\n",
       "      <td>맛 평가 없음</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>코만도x</td>\n",
       "      <td>2025.01.10</td>\n",
       "      <td>1</td>\n",
       "      <td>맛과 어울리지도 않게 맵기만함고급스러운 매운맛이 아니고 싼매운맛. 유통기한 끝나가는...</td>\n",
       "      <td>적당히 남았어요</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>sssgg</td>\n",
       "      <td>2025.01.04</td>\n",
       "      <td>1</td>\n",
       "      <td>마라향이 뭔가 조화롭지않아서 좀 인위적인?느낌의 향만나고우선 진짜 너무 맵기만해요</td>\n",
       "      <td>적당히 남았어요</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>쿠리사</td>\n",
       "      <td>2025.01.13</td>\n",
       "      <td>1</td>\n",
       "      <td>짜파게티도 맛있고 블랙도 맛있는데이건 영.....마라향이 확 나는게 아니라서 이상함...</td>\n",
       "      <td>아주 넉넉해요</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>rtrtrt</td>\n",
       "      <td>2025.01.07</td>\n",
       "      <td>1</td>\n",
       "      <td>마라의 얼얼함이 아니라 그냥 캡사이신의 매움입니다;</td>\n",
       "      <td>아주 넉넉해요</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>264 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         이름        작성일자  평점  \\\n",
       "0       박*혜  2025.01.14   5   \n",
       "1     dimss  2025.01.13   4   \n",
       "2       이*람  2025.01.12   5   \n",
       "3     시마에나가  2025.01.11   4   \n",
       "4       김*수  2025.01.11   5   \n",
       "..      ...         ...  ..   \n",
       "283    잔잔다에  2025.01.01   1   \n",
       "284    코만도x  2025.01.10   1   \n",
       "285   sssgg  2025.01.04   1   \n",
       "286     쿠리사  2025.01.13   1   \n",
       "287  rtrtrt  2025.01.07   1   \n",
       "\n",
       "                                                 리뷰 내용     맛 만족도  \\\n",
       "0    짜파게티 마라, 어떤 제품일까?먼저 짜파게티 마라의 기본 정보를 알아보았어요. 이 ...   아주 넉넉해요   \n",
       "1    안녕하세요!! 리뷰하는 dimss입니다^^오늘도 솔직 사용후기 들고 왔어요❤️⬇️⬇...  적당히 남았어요   \n",
       "2    ### 구매 계기매운 음식을 좋아하는 저는 최근 마라탕이나 마라샹궈와 같은 마라 요...  적당히 남았어요   \n",
       "3    ⏹️ 요약 ⏹️✅ 구성 - 면, 후레이크, 짜장스프, 마라조미유✅ 맛 - 맵찔이 먹...  적당히 남았어요   \n",
       "4    짜파게티 마라를 구매한 후기를 이모티콘을 활용하여 작성해 보겠습니다. 아래와 같은 ...   아주 넉넉해요   \n",
       "..                                                 ...       ...   \n",
       "283   처음 입에 넣을 때 거부감 드는 향과 뒤에 매운 맛만 느껴짐참고서라도 먹고싶지 않은 맛   맛 평가 없음   \n",
       "284  맛과 어울리지도 않게 맵기만함고급스러운 매운맛이 아니고 싼매운맛. 유통기한 끝나가는...  적당히 남았어요   \n",
       "285      마라향이 뭔가 조화롭지않아서 좀 인위적인?느낌의 향만나고우선 진짜 너무 맵기만해요  적당히 남았어요   \n",
       "286  짜파게티도 맛있고 블랙도 맛있는데이건 영.....마라향이 확 나는게 아니라서 이상함...   아주 넉넉해요   \n",
       "287                       마라의 얼얼함이 아니라 그냥 캡사이신의 매움입니다;   아주 넉넉해요   \n",
       "\n",
       "                                   preprocessed_review  \\\n",
       "0    짜파게티 마라 어떤 제품 일까먼저 짜파게티 마라 기본 정보를 알아보았어요 제품 유명...   \n",
       "1    안녕하세요 리뷰 하는 입니다 오늘도 솔직 사용후기 들고 왔어요짜파게티 마라 솔직 후...   \n",
       "2    구매 계기매운 음식 좋아 하는 저는 최근 마라 탕이나 마라 샹궈와 같은 마라 요리 ...   \n",
       "3    요약 구성 후레이크 짜장스프 마라 조미유 맵찔이 먹으면 안됨 그냥 매운 마라 구매 ...   \n",
       "4    짜파게티 마라 구매 후기 이모티콘을 활용 하여 작성해 보겠습니다 아래와 같은 방식 ...   \n",
       "..                                                 ...   \n",
       "283                                                NaN   \n",
       "284                                                NaN   \n",
       "285                                                NaN   \n",
       "286                                                NaN   \n",
       "287                                                NaN   \n",
       "\n",
       "                   krwordrank  \n",
       "0        [마라, 제품, 있어, 정말, 느낀]  \n",
       "1                        None  \n",
       "2    [마라, 했습니다, 짜파게티, 정말, 국물]  \n",
       "3                        None  \n",
       "4        [마라, 매운, 맛이, 조금, 하는]  \n",
       "..                        ...  \n",
       "283                      None  \n",
       "284                      None  \n",
       "285                      None  \n",
       "286                      None  \n",
       "287                      None  \n",
       "\n",
       "[264 rows x 7 columns]"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "individual_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "individual_df.to_csv(\"../result/df_krwordRank.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>이름</th>\n",
       "      <th>작성일자</th>\n",
       "      <th>평점</th>\n",
       "      <th>리뷰 내용</th>\n",
       "      <th>맛 만족도</th>\n",
       "      <th>preprocessed_review</th>\n",
       "      <th>krwordrank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>박*혜</td>\n",
       "      <td>2025.01.14</td>\n",
       "      <td>5</td>\n",
       "      <td>짜파게티 마라, 어떤 제품일까?먼저 짜파게티 마라의 기본 정보를 알아보았어요. 이 ...</td>\n",
       "      <td>아주 넉넉해요</td>\n",
       "      <td>짜파게티 마라 어떤 제품 일까먼저 짜파게티 마라 기본 정보를 알아보았어요 제품 유명...</td>\n",
       "      <td>[마라, 제품, 있어, 정말, 느낀]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>이*람</td>\n",
       "      <td>2025.01.12</td>\n",
       "      <td>5</td>\n",
       "      <td>### 구매 계기매운 음식을 좋아하는 저는 최근 마라탕이나 마라샹궈와 같은 마라 요...</td>\n",
       "      <td>적당히 남았어요</td>\n",
       "      <td>구매 계기매운 음식 좋아 하는 저는 최근 마라 탕이나 마라 샹궈와 같은 마라 요리 ...</td>\n",
       "      <td>[마라, 했습니다, 짜파게티, 정말, 국물]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>김*수</td>\n",
       "      <td>2025.01.11</td>\n",
       "      <td>5</td>\n",
       "      <td>짜파게티 마라를 구매한 후기를 이모티콘을 활용하여 작성해 보겠습니다. 아래와 같은 ...</td>\n",
       "      <td>아주 넉넉해요</td>\n",
       "      <td>짜파게티 마라 구매 후기 이모티콘을 활용 하여 작성해 보겠습니다 아래와 같은 방식 ...</td>\n",
       "      <td>[마라, 매운, 맛이, 조금, 하는]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>겨미둥이</td>\n",
       "      <td>2025.01.07</td>\n",
       "      <td>5</td>\n",
       "      <td>안녕하세요.오늘은 짜파게티 마라에 대한 후기를 남겨보겠습니다.^^&lt;&lt;&lt;장점&gt;&gt;&gt;✔️...</td>\n",
       "      <td>아주 넉넉해요</td>\n",
       "      <td>안녕하세요 오늘은 짜파게티 마라 대한 후기 남겨 보겠습니다장점마라 향신료 독특 풍미...</td>\n",
       "      <td>[마라, 있습니다, 감칠맛, 분들, 맛을]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>간헐적돼지</td>\n",
       "      <td>2025.01.05</td>\n",
       "      <td>5</td>\n",
       "      <td>다양한 마라제품이 판을 치고 있는 시점에서나올듯 나오지 않을 듯하던 제품이 드디어 ...</td>\n",
       "      <td>아주 넉넉해요</td>\n",
       "      <td>다양한 마라 제품이 판을 치고 있는 시점에서나올듯 나오 않을 듯하던 제품 드디어 나...</td>\n",
       "      <td>[마라, 짜파게티, 조금, 먹어, 비벼]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>프리프리리</td>\n",
       "      <td>2025.01.04</td>\n",
       "      <td>5</td>\n",
       "      <td>마라향이 강해요</td>\n",
       "      <td>맛 평가 없음</td>\n",
       "      <td>맵찔이 분들은 조심하셔욧 까르보나라 불닭 보단 매움 속이 아프네요 궁금 해서 시켜 ...</td>\n",
       "      <td>[호기심, 조심하셔욧, 분들은, 까르보나라, 불닭]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>혀비씨</td>\n",
       "      <td>2024.12.26</td>\n",
       "      <td>5</td>\n",
       "      <td>맛나요! 고민은...</td>\n",
       "      <td>아주 넉넉해요</td>\n",
       "      <td>아끼세요 감칠맛 없고 매워요 그렇 다고 짜파게티 맛이 나는 것도 아님마라 얼얼 보단...</td>\n",
       "      <td>[매워요, 반만, 맛이, 다고, 얼얼]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>박민희</td>\n",
       "      <td>2024.12.25</td>\n",
       "      <td>4</td>\n",
       "      <td>가끔 먹으면 맛있을것 같아요 굳굳</td>\n",
       "      <td>아주 넉넉해요</td>\n",
       "      <td>마라 성분 혹시 하고 구입했 어요 맵기 도하고 짜장맛은 별로 네요 그냥 짜장 나을듯함다</td>\n",
       "      <td>[짜장, 마라, 별로, 하고, 도하고]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>고*진</td>\n",
       "      <td>2024.12.27</td>\n",
       "      <td>3</td>\n",
       "      <td>스프를 다 넣지  않아야  할듯 해요.</td>\n",
       "      <td>아주 넉넉해요</td>\n",
       "      <td>왠만해서 상품 안남기는데 나만 당할순 없지 한번 드셔 보셔존맛탱</td>\n",
       "      <td>[상품, 나만, 왠만해서, 드셔, 보셔존맛탱]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>김*화</td>\n",
       "      <td>2024.12.24</td>\n",
       "      <td>3</td>\n",
       "      <td>생각보다 매워요그냥 오리지널 짜빠게티 드세요</td>\n",
       "      <td>적당히 남았어요</td>\n",
       "      <td>짜파게티 맛있 블랙도 맛있 는데이건 영마라향이 나는 아니 라서 이상 너무 없음 마라...</td>\n",
       "      <td>[맛있, 먹어, 짜파게티, 나는, 는데이건]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        이름        작성일자  평점                                              리뷰 내용  \\\n",
       "0      박*혜  2025.01.14   5  짜파게티 마라, 어떤 제품일까?먼저 짜파게티 마라의 기본 정보를 알아보았어요. 이 ...   \n",
       "2      이*람  2025.01.12   5  ### 구매 계기매운 음식을 좋아하는 저는 최근 마라탕이나 마라샹궈와 같은 마라 요...   \n",
       "4      김*수  2025.01.11   5  짜파게티 마라를 구매한 후기를 이모티콘을 활용하여 작성해 보겠습니다. 아래와 같은 ...   \n",
       "6     겨미둥이  2025.01.07   5  안녕하세요.오늘은 짜파게티 마라에 대한 후기를 남겨보겠습니다.^^<<<장점>>>✔️...   \n",
       "8    간헐적돼지  2025.01.05   5  다양한 마라제품이 판을 치고 있는 시점에서나올듯 나오지 않을 듯하던 제품이 드디어 ...   \n",
       "..     ...         ...  ..                                                ...   \n",
       "249  프리프리리  2025.01.04   5                                           마라향이 강해요   \n",
       "251    혀비씨  2024.12.26   5                                        맛나요! 고민은...   \n",
       "255    박민희  2024.12.25   4                                 가끔 먹으면 맛있을것 같아요 굳굳   \n",
       "258    고*진  2024.12.27   3                              스프를 다 넣지  않아야  할듯 해요.   \n",
       "262    김*화  2024.12.24   3                           생각보다 매워요그냥 오리지널 짜빠게티 드세요   \n",
       "\n",
       "        맛 만족도                                preprocessed_review  \\\n",
       "0     아주 넉넉해요  짜파게티 마라 어떤 제품 일까먼저 짜파게티 마라 기본 정보를 알아보았어요 제품 유명...   \n",
       "2    적당히 남았어요  구매 계기매운 음식 좋아 하는 저는 최근 마라 탕이나 마라 샹궈와 같은 마라 요리 ...   \n",
       "4     아주 넉넉해요  짜파게티 마라 구매 후기 이모티콘을 활용 하여 작성해 보겠습니다 아래와 같은 방식 ...   \n",
       "6     아주 넉넉해요  안녕하세요 오늘은 짜파게티 마라 대한 후기 남겨 보겠습니다장점마라 향신료 독특 풍미...   \n",
       "8     아주 넉넉해요  다양한 마라 제품이 판을 치고 있는 시점에서나올듯 나오 않을 듯하던 제품 드디어 나...   \n",
       "..        ...                                                ...   \n",
       "249   맛 평가 없음  맵찔이 분들은 조심하셔욧 까르보나라 불닭 보단 매움 속이 아프네요 궁금 해서 시켜 ...   \n",
       "251   아주 넉넉해요  아끼세요 감칠맛 없고 매워요 그렇 다고 짜파게티 맛이 나는 것도 아님마라 얼얼 보단...   \n",
       "255   아주 넉넉해요   마라 성분 혹시 하고 구입했 어요 맵기 도하고 짜장맛은 별로 네요 그냥 짜장 나을듯함다   \n",
       "258   아주 넉넉해요                왠만해서 상품 안남기는데 나만 당할순 없지 한번 드셔 보셔존맛탱   \n",
       "262  적당히 남았어요  짜파게티 맛있 블랙도 맛있 는데이건 영마라향이 나는 아니 라서 이상 너무 없음 마라...   \n",
       "\n",
       "                       krwordrank  \n",
       "0            [마라, 제품, 있어, 정말, 느낀]  \n",
       "2        [마라, 했습니다, 짜파게티, 정말, 국물]  \n",
       "4            [마라, 매운, 맛이, 조금, 하는]  \n",
       "6         [마라, 있습니다, 감칠맛, 분들, 맛을]  \n",
       "8          [마라, 짜파게티, 조금, 먹어, 비벼]  \n",
       "..                            ...  \n",
       "249  [호기심, 조심하셔욧, 분들은, 까르보나라, 불닭]  \n",
       "251         [매워요, 반만, 맛이, 다고, 얼얼]  \n",
       "255         [짜장, 마라, 별로, 하고, 도하고]  \n",
       "258     [상품, 나만, 왠만해서, 드셔, 보셔존맛탱]  \n",
       "262      [맛있, 먹어, 짜파게티, 나는, 는데이건]  \n",
       "\n",
       "[120 rows x 7 columns]"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df = individual_df[individual_df['krwordrank'].notna()]\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>이름</th>\n",
       "      <th>작성일자</th>\n",
       "      <th>평점</th>\n",
       "      <th>리뷰 내용</th>\n",
       "      <th>맛 만족도</th>\n",
       "      <th>preprocessed_review</th>\n",
       "      <th>krwordrank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>김*림</td>\n",
       "      <td>2024.12.25</td>\n",
       "      <td>2</td>\n",
       "      <td>평소에 짜파게티와 사천짜파게티 둘 다 아주 좋아해서 이번 신상품도 기대하고 사전예약...</td>\n",
       "      <td>아주 넉넉해요</td>\n",
       "      <td>평소 짜파게티 사천짜파게티 아주 좋아 해서 이번 신상 품도 기대 하고 사전예약 으로...</td>\n",
       "      <td>[짜파게티, 마라, 먹어, 맛이, 받았]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>김*희</td>\n",
       "      <td>2025.01.01</td>\n",
       "      <td>2</td>\n",
       "      <td>생각보다 맵고 처음 먹어보는거라 3봉 삶을때 액상소스 1개만 넣었는데도 액상소스의 ...</td>\n",
       "      <td>아주 넉넉해요</td>\n",
       "      <td>생각 보다 맵고 처음 먹어보 는거라 삶을때 액상소스 개만 넣었는데 액상소스의 마라 ...</td>\n",
       "      <td>[일반, 액상소스, 개만, 먹어, 반정도는]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>홍*진</td>\n",
       "      <td>2024.12.29</td>\n",
       "      <td>2</td>\n",
       "      <td>맵고 맛은그냥그래요 마라맛은약하고 맵기만</td>\n",
       "      <td>아주 넉넉해요</td>\n",
       "      <td>너무 매워요</td>\n",
       "      <td>[너무, 매워요]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>송*한</td>\n",
       "      <td>2024.12.25</td>\n",
       "      <td>2</td>\n",
       "      <td>이건 아니다 그냥 짜파게티는 못이긴다</td>\n",
       "      <td>아주 넉넉해요</td>\n",
       "      <td>스프 넣지 않아 할듯 해요</td>\n",
       "      <td>[해요, 넣지, 스프, 않아, 할듯]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>코코블루</td>\n",
       "      <td>2025.01.03</td>\n",
       "      <td>2</td>\n",
       "      <td>다 깨져있어요</td>\n",
       "      <td>아주 넉넉해요</td>\n",
       "      <td>호불호 확실 맛전 완전 불호이네요마라 좋아 하시는분만드세요</td>\n",
       "      <td>[좋아, 호불호, 완전, 하시는분만드세요, 확실]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       이름        작성일자  평점                                              리뷰 내용  \\\n",
       "216   김*림  2024.12.25   2  평소에 짜파게티와 사천짜파게티 둘 다 아주 좋아해서 이번 신상품도 기대하고 사전예약...   \n",
       "218   김*희  2025.01.01   2  생각보다 맵고 처음 먹어보는거라 3봉 삶을때 액상소스 1개만 넣었는데도 액상소스의 ...   \n",
       "231   홍*진  2024.12.29   2                             맵고 맛은그냥그래요 마라맛은약하고 맵기만   \n",
       "236   송*한  2024.12.25   2                               이건 아니다 그냥 짜파게티는 못이긴다   \n",
       "244  코코블루  2025.01.03   2                                            다 깨져있어요   \n",
       "\n",
       "       맛 만족도                                preprocessed_review  \\\n",
       "216  아주 넉넉해요  평소 짜파게티 사천짜파게티 아주 좋아 해서 이번 신상 품도 기대 하고 사전예약 으로...   \n",
       "218  아주 넉넉해요  생각 보다 맵고 처음 먹어보 는거라 삶을때 액상소스 개만 넣었는데 액상소스의 마라 ...   \n",
       "231  아주 넉넉해요                                             너무 매워요   \n",
       "236  아주 넉넉해요                                     스프 넣지 않아 할듯 해요   \n",
       "244  아주 넉넉해요                   호불호 확실 맛전 완전 불호이네요마라 좋아 하시는분만드세요   \n",
       "\n",
       "                      krwordrank  \n",
       "216       [짜파게티, 마라, 먹어, 맛이, 받았]  \n",
       "218     [일반, 액상소스, 개만, 먹어, 반정도는]  \n",
       "231                    [너무, 매워요]  \n",
       "236         [해요, 넣지, 스프, 않아, 할듯]  \n",
       "244  [좋아, 호불호, 완전, 하시는분만드세요, 확실]  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "individual_df_2 = filtered_df[filtered_df['평점'] == 2]\n",
    "individual_df_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3: soynlp - wordextractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from soynlp.noun import LRNounExtractor_v2\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>이름</th>\n",
       "      <th>작성일자</th>\n",
       "      <th>평점</th>\n",
       "      <th>리뷰 내용</th>\n",
       "      <th>맛 만족도</th>\n",
       "      <th>preprocessed_review</th>\n",
       "      <th>krwordrank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>박*혜</td>\n",
       "      <td>2025.01.14</td>\n",
       "      <td>5</td>\n",
       "      <td>짜파게티 마라, 어떤 제품일까?먼저 짜파게티 마라의 기본 정보를 알아보았어요. 이 ...</td>\n",
       "      <td>아주 넉넉해요</td>\n",
       "      <td>짜파게티 마라 어떤 제품 일까먼저 짜파게티 마라 기본 정보를 알아보았어요 제품 유명...</td>\n",
       "      <td>[마라, 제품, 있어, 정말, 느낀]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dimss</td>\n",
       "      <td>2025.01.13</td>\n",
       "      <td>4</td>\n",
       "      <td>안녕하세요!! 리뷰하는 dimss입니다^^오늘도 솔직 사용후기 들고 왔어요❤️⬇️⬇...</td>\n",
       "      <td>적당히 남았어요</td>\n",
       "      <td>안녕하세요 리뷰 하는 입니다 오늘도 솔직 사용후기 들고 왔어요짜파게티 마라 솔직 후...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>이*람</td>\n",
       "      <td>2025.01.12</td>\n",
       "      <td>5</td>\n",
       "      <td>### 구매 계기매운 음식을 좋아하는 저는 최근 마라탕이나 마라샹궈와 같은 마라 요...</td>\n",
       "      <td>적당히 남았어요</td>\n",
       "      <td>구매 계기매운 음식 좋아 하는 저는 최근 마라 탕이나 마라 샹궈와 같은 마라 요리 ...</td>\n",
       "      <td>[마라, 했습니다, 짜파게티, 정말, 국물]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>시마에나가</td>\n",
       "      <td>2025.01.11</td>\n",
       "      <td>4</td>\n",
       "      <td>⏹️ 요약 ⏹️✅ 구성 - 면, 후레이크, 짜장스프, 마라조미유✅ 맛 - 맵찔이 먹...</td>\n",
       "      <td>적당히 남았어요</td>\n",
       "      <td>요약 구성 후레이크 짜장스프 마라 조미유 맵찔이 먹으면 안됨 그냥 매운 마라 구매 ...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>김*수</td>\n",
       "      <td>2025.01.11</td>\n",
       "      <td>5</td>\n",
       "      <td>짜파게티 마라를 구매한 후기를 이모티콘을 활용하여 작성해 보겠습니다. 아래와 같은 ...</td>\n",
       "      <td>아주 넉넉해요</td>\n",
       "      <td>짜파게티 마라 구매 후기 이모티콘을 활용 하여 작성해 보겠습니다 아래와 같은 방식 ...</td>\n",
       "      <td>[마라, 매운, 맛이, 조금, 하는]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      이름        작성일자  평점                                              리뷰 내용  \\\n",
       "0    박*혜  2025.01.14   5  짜파게티 마라, 어떤 제품일까?먼저 짜파게티 마라의 기본 정보를 알아보았어요. 이 ...   \n",
       "1  dimss  2025.01.13   4  안녕하세요!! 리뷰하는 dimss입니다^^오늘도 솔직 사용후기 들고 왔어요❤️⬇️⬇...   \n",
       "2    이*람  2025.01.12   5  ### 구매 계기매운 음식을 좋아하는 저는 최근 마라탕이나 마라샹궈와 같은 마라 요...   \n",
       "3  시마에나가  2025.01.11   4  ⏹️ 요약 ⏹️✅ 구성 - 면, 후레이크, 짜장스프, 마라조미유✅ 맛 - 맵찔이 먹...   \n",
       "4    김*수  2025.01.11   5  짜파게티 마라를 구매한 후기를 이모티콘을 활용하여 작성해 보겠습니다. 아래와 같은 ...   \n",
       "\n",
       "      맛 만족도                                preprocessed_review  \\\n",
       "0   아주 넉넉해요  짜파게티 마라 어떤 제품 일까먼저 짜파게티 마라 기본 정보를 알아보았어요 제품 유명...   \n",
       "1  적당히 남았어요  안녕하세요 리뷰 하는 입니다 오늘도 솔직 사용후기 들고 왔어요짜파게티 마라 솔직 후...   \n",
       "2  적당히 남았어요  구매 계기매운 음식 좋아 하는 저는 최근 마라 탕이나 마라 샹궈와 같은 마라 요리 ...   \n",
       "3  적당히 남았어요  요약 구성 후레이크 짜장스프 마라 조미유 맵찔이 먹으면 안됨 그냥 매운 마라 구매 ...   \n",
       "4   아주 넉넉해요  짜파게티 마라 구매 후기 이모티콘을 활용 하여 작성해 보겠습니다 아래와 같은 방식 ...   \n",
       "\n",
       "                 krwordrank  \n",
       "0      [마라, 제품, 있어, 정말, 느낀]  \n",
       "1                      None  \n",
       "2  [마라, 했습니다, 짜파게티, 정말, 국물]  \n",
       "3                      None  \n",
       "4      [마라, 매운, 맛이, 조금, 하는]  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from soynlp.word import WordExtractor\n",
    "import pandas as pd\n",
    "\n",
    "def df_sumWordSentence_soynlp_WE(df, review_col, rate_col=None, stopwords=None, top_k=5, full_merge=False, rate_merge=False):\n",
    "    \"\"\"\n",
    "    데이터프레임에서 특정 열을 전처리하고 soynlp를 사용해 키워드 추출 결과를 저장.\n",
    "\n",
    "    Parameters:\n",
    "    - df: pd.DataFrame - 입력 데이터프레임\n",
    "    - review_col: str - 리뷰 내용을 포함하는 열 이름\n",
    "    - rate_col: str - 평점 열의 이름 (rate_merge=True인 경우 필요)\n",
    "    - stopwords: list[str] - 필터링할 단어 목록\n",
    "    - top_k: int - 추출할 상위 키워드 개수\n",
    "    - full_merge: bool - True일 경우 모든 리뷰를 합쳐서 처리\n",
    "    - rate_merge: bool - True일 경우 평점별로 리뷰를 합쳐서 처리\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame - 키워드 열이 추가된 데이터프레임\n",
    "    \"\"\"\n",
    "\n",
    "    def extract_keywords_soynlp(texts):\n",
    "        \"\"\"soynlp WordExtractor로 키워드 추출\"\"\"\n",
    "        combined_text = \" \".join(texts)\n",
    "\n",
    "        # 불용어 제거\n",
    "        if stopwords:\n",
    "            for word in stopwords:\n",
    "                combined_text = combined_text.replace(word, '')\n",
    "\n",
    "        # WordExtractor를 사용하여 키워드 추출\n",
    "        word_extractor = WordExtractor()\n",
    "        word_extractor.train([combined_text])\n",
    "        words = word_extractor.extract()\n",
    "\n",
    "        # 중요도 기준으로 상위 키워드 추출\n",
    "        sorted_words = sorted(words.items(), key=lambda x: x[1].cohesion_forward, reverse=True)\n",
    "        return [word for word, score in sorted_words[:top_k]]\n",
    "\n",
    "    # 모든 리뷰를 합쳐서 처리\n",
    "    if full_merge:\n",
    "        merged_reviews = df[review_col].dropna().tolist()\n",
    "        keywords = extract_keywords_soynlp(merged_reviews)\n",
    "        return pd.DataFrame({'merge_type': ['full'], 'keywords': [keywords]})\n",
    "\n",
    "    # 평점별로 리뷰를 합쳐 처리\n",
    "    if rate_merge:\n",
    "        if rate_col is None:\n",
    "            raise ValueError(\"rate_merge=True 인 경우, rate_col을 지정해야 합니다.\")\n",
    "\n",
    "        rate_keywords = []\n",
    "        for rate, group in df.groupby(rate_col):\n",
    "            merged_reviews = group[review_col].dropna().tolist()\n",
    "            keywords = extract_keywords_soynlp(merged_reviews)\n",
    "            rate_keywords.append({'rate': rate, 'keywords': keywords})\n",
    "\n",
    "        return pd.DataFrame(rate_keywords)\n",
    "\n",
    "    # 기본: 각 리뷰별 처리\n",
    "    soynlp_results = []\n",
    "    for idx, row in df.iterrows():\n",
    "        review_content = row[review_col]\n",
    "        if pd.isna(review_content):\n",
    "            soynlp_results.append(None)\n",
    "            continue\n",
    "\n",
    "        # 필터링 및 문장 리스트 생성\n",
    "        if stopwords:\n",
    "            for word in stopwords:\n",
    "                review_content = review_content.replace(word, '')\n",
    "        texts = review_content.split('. ')\n",
    "\n",
    "        # 키워드 추출\n",
    "        keywords = extract_keywords_soynlp(texts)\n",
    "        soynlp_results.append(keywords)\n",
    "\n",
    "    # 새로운 열 추가\n",
    "    df['soynlp_keywords'] = soynlp_results\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training was done. used memory 0.650 Gb0.653 Gb\n",
      "all cohesion probabilities was computed. # words = 1200\n",
      "all branching entropies was computed # words = 2204\n",
      "all accessor variety was computed # words = 2204\n"
     ]
    }
   ],
   "source": [
    "full_merge_df_WE = df_sumWordSentence_soynlp_WE(df, review_col='preprocessed_review', top_k=10, full_merge=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.5초"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>merge_type</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>full</td>\n",
       "      <td>[훌륭, 듣고, 쫄깃, 쿠팡, 씹는, 뭔가, 항상, 취향, 됩니, 꼬들]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  merge_type                                  keywords\n",
       "0       full  [훌륭, 듣고, 쫄깃, 쿠팡, 씹는, 뭔가, 항상, 취향, 됩니, 꼬들]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_merge_df_WE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training was done. used memory 0.650 Gb0.650 Gb\n",
      "all cohesion probabilities was computed. # words = 4\n",
      "all branching entropies was computed # words = 43\n",
      "all accessor variety was computed # words = 43\n",
      "training was done. used memory 0.650 Gb0.650 Gb\n",
      "all cohesion probabilities was computed. # words = 8\n",
      "all branching entropies was computed # words = 49\n",
      "all accessor variety was computed # words = 49\n",
      "training was done. used memory 0.650 Gb0.650 Gb\n",
      "all cohesion probabilities was computed. # words = 35\n",
      "all branching entropies was computed # words = 187\n",
      "all accessor variety was computed # words = 187\n",
      "training was done. used memory 0.650 Gb0.650 Gb\n",
      "all cohesion probabilities was computed. # words = 9\n",
      "all branching entropies was computed # words = 70\n",
      "all accessor variety was computed # words = 70\n",
      "training was done. used memory 0.650 Gb0.650 Gb\n",
      "all cohesion probabilities was computed. # words = 5\n",
      "all branching entropies was computed # words = 60\n",
      "all accessor variety was computed # words = 60\n",
      "training was done. used memory 0.650 Gb0.650 Gb\n",
      "all cohesion probabilities was computed. # words = 6\n",
      "all branching entropies was computed # words = 15\n",
      "all accessor variety was computed # words = 15\n",
      "training was done. used memory 0.650 Gb0.650 Gb\n",
      "all cohesion probabilities was computed. # words = 8\n",
      "all branching entropies was computed # words = 67\n",
      "all accessor variety was computed # words = 67\n",
      "training was done. used memory 0.650 Gb0.650 Gb\n",
      "all cohesion probabilities was computed. # words = 3\n",
      "all branching entropies was computed # words = 38\n",
      "all accessor variety was computed # words = 38\n",
      "training was done. used memory 0.650 Gb0.650 Gb\n",
      "all cohesion probabilities was computed. # words = 13\n",
      "all branching entropies was computed # words = 93\n",
      "all accessor variety was computed # words = 93\n",
      "training was done. used memory 0.650 Gb0.650 Gb\n",
      "all cohesion probabilities was computed. # words = 8\n",
      "all branching entropies was computed # words = 58\n",
      "all accessor variety was computed # words = 58\n",
      "training was done. used memory 0.650 Gb0.650 Gb\n",
      "all cohesion probabilities was computed. # words = 11\n",
      "all branching entropies was computed # words = 128\n",
      "all accessor variety was computed # words = 128\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 7\n",
      "all branching entropies was computed # words = 46\n",
      "all accessor variety was computed # words = 46\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 5\n",
      "all branching entropies was computed # words = 38\n",
      "all accessor variety was computed # words = 38\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 7\n",
      "all branching entropies was computed # words = 33\n",
      "all accessor variety was computed # words = 33\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 13\n",
      "all branching entropies was computed # words = 52\n",
      "all accessor variety was computed # words = 52\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 12\n",
      "all branching entropies was computed # words = 73\n",
      "all accessor variety was computed # words = 73\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 10\n",
      "all branching entropies was computed # words = 46\n",
      "all accessor variety was computed # words = 46\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 8\n",
      "all branching entropies was computed # words = 68\n",
      "all accessor variety was computed # words = 68\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 3\n",
      "all branching entropies was computed # words = 29\n",
      "all accessor variety was computed # words = 29\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 6\n",
      "all branching entropies was computed # words = 38\n",
      "all accessor variety was computed # words = 38\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 24\n",
      "all branching entropies was computed # words = 110\n",
      "all accessor variety was computed # words = 110\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 3\n",
      "all branching entropies was computed # words = 54\n",
      "all accessor variety was computed # words = 54\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 11\n",
      "all branching entropies was computed # words = 65\n",
      "all accessor variety was computed # words = 65\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 9\n",
      "all branching entropies was computed # words = 46\n",
      "all accessor variety was computed # words = 46\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 10\n",
      "all branching entropies was computed # words = 58\n",
      "all accessor variety was computed # words = 58\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 8\n",
      "all branching entropies was computed # words = 29\n",
      "all accessor variety was computed # words = 29\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 7\n",
      "all branching entropies was computed # words = 40\n",
      "all accessor variety was computed # words = 40\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 14\n",
      "all branching entropies was computed # words = 64\n",
      "all accessor variety was computed # words = 64\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 9\n",
      "all branching entropies was computed # words = 79\n",
      "all accessor variety was computed # words = 79\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 8\n",
      "all branching entropies was computed # words = 45\n",
      "all accessor variety was computed # words = 45\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 7\n",
      "all branching entropies was computed # words = 25\n",
      "all accessor variety was computed # words = 25\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 1\n",
      "all branching entropies was computed # words = 18\n",
      "all accessor variety was computed # words = 18\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 6\n",
      "all branching entropies was computed # words = 28\n",
      "all accessor variety was computed # words = 28\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 4\n",
      "all branching entropies was computed # words = 15\n",
      "all accessor variety was computed # words = 15\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 2\n",
      "all branching entropies was computed # words = 24\n",
      "all accessor variety was computed # words = 24\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 3\n",
      "all branching entropies was computed # words = 30\n",
      "all accessor variety was computed # words = 30\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 7\n",
      "all branching entropies was computed # words = 33\n",
      "all accessor variety was computed # words = 33\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 7\n",
      "all branching entropies was computed # words = 36\n",
      "all accessor variety was computed # words = 36\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 1\n",
      "all branching entropies was computed # words = 4\n",
      "all accessor variety was computed # words = 4\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 18\n",
      "all accessor variety was computed # words = 18\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 16\n",
      "all branching entropies was computed # words = 100\n",
      "all accessor variety was computed # words = 100\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 6\n",
      "all branching entropies was computed # words = 14\n",
      "all accessor variety was computed # words = 14\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 1\n",
      "all branching entropies was computed # words = 19\n",
      "all accessor variety was computed # words = 19\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 1\n",
      "all branching entropies was computed # words = 16\n",
      "all accessor variety was computed # words = 16\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 1\n",
      "all branching entropies was computed # words = 16\n",
      "all accessor variety was computed # words = 16\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 6\n",
      "all branching entropies was computed # words = 24\n",
      "all accessor variety was computed # words = 24\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 4\n",
      "all branching entropies was computed # words = 31\n",
      "all accessor variety was computed # words = 31\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 7\n",
      "all branching entropies was computed # words = 19\n",
      "all accessor variety was computed # words = 19\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 13\n",
      "all accessor variety was computed # words = 13\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 9\n",
      "all accessor variety was computed # words = 9\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 1\n",
      "all branching entropies was computed # words = 20\n",
      "all accessor variety was computed # words = 20\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 1\n",
      "all branching entropies was computed # words = 9\n",
      "all accessor variety was computed # words = 9\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 14\n",
      "all accessor variety was computed # words = 14\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 1\n",
      "all branching entropies was computed # words = 10\n",
      "all accessor variety was computed # words = 10\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 2\n",
      "all accessor variety was computed # words = 2\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 4\n",
      "all accessor variety was computed # words = 4\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 1\n",
      "all branching entropies was computed # words = 1\n",
      "all accessor variety was computed # words = 1\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 8\n",
      "all accessor variety was computed # words = 8\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 2\n",
      "all accessor variety was computed # words = 2\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 3\n",
      "all accessor variety was computed # words = 3\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 17\n",
      "all accessor variety was computed # words = 17\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 10\n",
      "all accessor variety was computed # words = 10\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 3\n",
      "all accessor variety was computed # words = 3\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 1\n",
      "all branching entropies was computed # words = 11\n",
      "all accessor variety was computed # words = 11\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 1\n",
      "all branching entropies was computed # words = 17\n",
      "all accessor variety was computed # words = 17\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 3\n",
      "all accessor variety was computed # words = 3\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 4\n",
      "all accessor variety was computed # words = 4\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 1\n",
      "all branching entropies was computed # words = 22\n",
      "all accessor variety was computed # words = 22\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 3\n",
      "all accessor variety was computed # words = 3\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 7\n",
      "all branching entropies was computed # words = 20\n",
      "all accessor variety was computed # words = 20\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 1\n",
      "all branching entropies was computed # words = 19\n",
      "all accessor variety was computed # words = 19\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 9\n",
      "all accessor variety was computed # words = 9\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 6\n",
      "all branching entropies was computed # words = 37\n",
      "all accessor variety was computed # words = 37\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 7\n",
      "all accessor variety was computed # words = 7\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 16\n",
      "all accessor variety was computed # words = 16\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 13\n",
      "all accessor variety was computed # words = 13\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 2\n",
      "all branching entropies was computed # words = 22\n",
      "all accessor variety was computed # words = 22\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 2\n",
      "all branching entropies was computed # words = 23\n",
      "all accessor variety was computed # words = 23\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 17\n",
      "all accessor variety was computed # words = 17\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 11\n",
      "all accessor variety was computed # words = 11\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 5\n",
      "all accessor variety was computed # words = 5\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 1\n",
      "all branching entropies was computed # words = 1\n",
      "all accessor variety was computed # words = 1\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 18\n",
      "all accessor variety was computed # words = 18\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 1\n",
      "all branching entropies was computed # words = 9\n",
      "all accessor variety was computed # words = 9\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 11\n",
      "all accessor variety was computed # words = 11\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 1\n",
      "all branching entropies was computed # words = 8\n",
      "all accessor variety was computed # words = 8\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 2\n",
      "all accessor variety was computed # words = 2\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 3\n",
      "all accessor variety was computed # words = 3\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 6\n",
      "all accessor variety was computed # words = 6\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 2\n",
      "all branching entropies was computed # words = 15\n",
      "all accessor variety was computed # words = 15\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 1\n",
      "all branching entropies was computed # words = 10\n",
      "all accessor variety was computed # words = 10\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 13\n",
      "all accessor variety was computed # words = 13\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 4\n",
      "all accessor variety was computed # words = 4\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 3\n",
      "all accessor variety was computed # words = 3\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 3\n",
      "all accessor variety was computed # words = 3\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 4\n",
      "all accessor variety was computed # words = 4\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 1\n",
      "all branching entropies was computed # words = 4\n",
      "all accessor variety was computed # words = 4\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 24\n",
      "all accessor variety was computed # words = 24\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 9\n",
      "all accessor variety was computed # words = 9\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 3\n",
      "all accessor variety was computed # words = 3\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 3\n",
      "all accessor variety was computed # words = 3\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 3\n",
      "all accessor variety was computed # words = 3\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 10\n",
      "all accessor variety was computed # words = 10\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 4\n",
      "all accessor variety was computed # words = 4\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 3\n",
      "all accessor variety was computed # words = 3\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 6\n",
      "all accessor variety was computed # words = 6\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 1\n",
      "all branching entropies was computed # words = 8\n",
      "all accessor variety was computed # words = 8\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 4\n",
      "all accessor variety was computed # words = 4\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 2\n",
      "all accessor variety was computed # words = 2\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 2\n",
      "all accessor variety was computed # words = 2\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 2\n",
      "all accessor variety was computed # words = 2\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 3\n",
      "all accessor variety was computed # words = 3\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 3\n",
      "all accessor variety was computed # words = 3\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 5\n",
      "all accessor variety was computed # words = 5\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 3\n",
      "all accessor variety was computed # words = 3\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 3\n",
      "all accessor variety was computed # words = 3\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 6\n",
      "all accessor variety was computed # words = 6\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 3\n",
      "all accessor variety was computed # words = 3\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 4\n",
      "all accessor variety was computed # words = 4\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 4\n",
      "all accessor variety was computed # words = 4\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 4\n",
      "all accessor variety was computed # words = 4\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 3\n",
      "all accessor variety was computed # words = 3\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 2\n",
      "all accessor variety was computed # words = 2\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 3\n",
      "all accessor variety was computed # words = 3\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 10\n",
      "all accessor variety was computed # words = 10\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 5\n",
      "all branching entropies was computed # words = 9\n",
      "all accessor variety was computed # words = 9\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 3\n",
      "all accessor variety was computed # words = 3\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 4\n",
      "all accessor variety was computed # words = 4\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n",
      "training was done. used memory 0.649 Gb0.649 Gb\n",
      "all cohesion probabilities was computed. # words = 0\n",
      "all branching entropies was computed # words = 0\n",
      "all accessor variety was computed # words = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zin\\AppData\\Local\\Temp\\ipykernel_20828\\4210191701.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['soynlp_keywords'] = soynlp_results\n"
     ]
    }
   ],
   "source": [
    "individual_df = df_sumWordSentence_soynlp_WE(df, review_col='preprocessed_review', top_k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "individual_df.to_csv(\"../result/df_sumWordSentence_soynlp_WE.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 5: LRNounExtractor_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from soynlp.noun import LRNounExtractor_v2\n",
    "import pandas as pd\n",
    "\n",
    "def df_sumWordSentence_soynlp_LR(df, review_col, rate_col=None, stopwords=None, top_k=5, full_merge=False, rate_merge=False):\n",
    "    \"\"\"\n",
    "    데이터프레임에서 특정 열을 전처리하고 soynlp를 사용해 키워드 추출 결과를 저장.\n",
    "\n",
    "    Parameters:\n",
    "    - df: pd.DataFrame - 입력 데이터프레임\n",
    "    - review_col: str - 리뷰 내용을 포함하는 열 이름\n",
    "    - rate_col: str - 평점 열의 이름 (rate_merge=True인 경우 필요)\n",
    "    - stopwords: list[str] - 필터링할 단어 목록\n",
    "    - top_k: int - 추출할 상위 키워드 개수\n",
    "    - full_merge: bool - True일 경우 모든 리뷰를 합쳐서 처리\n",
    "    - rate_merge: bool - True일 경우 평점별로 리뷰를 합쳐서 처리\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame - 키워드 열이 추가된 데이터프레임\n",
    "    \"\"\"\n",
    "\n",
    "    def extract_keywords_soynlp(texts):\n",
    "        \"\"\"soynlp LRNounExtractor_v2로 키워드 추출\"\"\"\n",
    "        combined_text = \" \".join(texts)\n",
    "\n",
    "        # 불용어 제거\n",
    "        if stopwords:\n",
    "            for word in stopwords:\n",
    "                combined_text = combined_text.replace(word, '')\n",
    "\n",
    "        # LRNounExtractor_v2를 사용하여 키워드 추출\n",
    "        noun_extractor = LRNounExtractor_v2(verbose=False)\n",
    "        nouns = noun_extractor.train_extract([combined_text])\n",
    "\n",
    "        # 중요도 기준으로 상위 키워드 추출\n",
    "        sorted_nouns = sorted(nouns.items(), key=lambda x: x[1].frequency, reverse=True)\n",
    "        return [word for word, score in sorted_nouns[:top_k]]\n",
    "\n",
    "    # 모든 리뷰를 합쳐서 처리\n",
    "    if full_merge:\n",
    "        merged_reviews = df[review_col].dropna().tolist()\n",
    "        keywords = extract_keywords_soynlp(merged_reviews)\n",
    "        return pd.DataFrame({'merge_type': ['full'], 'keywords': [keywords]})\n",
    "\n",
    "    # 평점별로 리뷰를 합쳐 처리\n",
    "    if rate_merge:\n",
    "        if rate_col is None:\n",
    "            raise ValueError(\"rate_merge=True 인 경우, rate_col을 지정해야 합니다.\")\n",
    "\n",
    "        rate_keywords = []\n",
    "        for rate, group in df.groupby(rate_col):\n",
    "            merged_reviews = group[review_col].dropna().tolist()\n",
    "            keywords = extract_keywords_soynlp(merged_reviews)\n",
    "            rate_keywords.append({'rate': rate, 'keywords': keywords})\n",
    "\n",
    "        return pd.DataFrame(rate_keywords)\n",
    "\n",
    "    # 기본: 각 리뷰별 처리\n",
    "    soynlp_results = []\n",
    "    for idx, row in df.iterrows():\n",
    "        review_content = row[review_col]\n",
    "        if pd.isna(review_content):\n",
    "            soynlp_results.append(None)\n",
    "            continue\n",
    "\n",
    "        # 필터링 및 문장 리스트 생성\n",
    "        if stopwords:\n",
    "            for word in stopwords:\n",
    "                review_content = review_content.replace(word, '')\n",
    "        texts = review_content.split('. ')\n",
    "\n",
    "        # 키워드 추출\n",
    "        keywords = extract_keywords_soynlp(texts)\n",
    "        soynlp_results.append(keywords)\n",
    "\n",
    "    # 새로운 열 추가\n",
    "    df['soynlp_keywords'] = soynlp_results\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_merge_df_LR = df_sumWordSentence_soynlp_LR(df, review_col='preprocessed_review', top_k=10, full_merge=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>merge_type</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>full</td>\n",
       "      <td>[짜파게티, 맛, 맛이, 얼얼, 생각, 향, 느낌, 저, 분들, 구매]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  merge_type                                 keywords\n",
       "0       full  [짜파게티, 맛, 맛이, 얼얼, 생각, 향, 느낌, 저, 분들, 구매]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_merge_df_LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zin\\AppData\\Local\\Temp\\ipykernel_20828\\1944135166.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['soynlp_keywords'] = soynlp_results\n"
     ]
    }
   ],
   "source": [
    "individual_df = df_sumWordSentence_soynlp_LR(df, review_col='preprocessed_review', top_k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "individual_df.to_csv(\"../result/df_sumWordSentence_soynlp_LR.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'맛'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_merge_df_LR['keywords'][0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 평점별로 리뷰를 묶어서 키워드 추출\n",
    "rate_merge_df = df_sumWordSentence_soynlp_LR(df, review_col='preprocessed_review', rate_col='평점', rate_merge=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rate</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[얼얼]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[맛, 강, 액상소스, 침샘, 폭발]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[맛, 정도, 느낌, 구매, 볶음면]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[짜파게티, 맛이, 맛, 조미유, 향]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[짜파게티, 맛, 맛이, 얼얼, 생각]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rate               keywords\n",
       "0     1                   [얼얼]\n",
       "1     2   [맛, 강, 액상소스, 침샘, 폭발]\n",
       "2     3   [맛, 정도, 느낌, 구매, 볶음면]\n",
       "3     4  [짜파게티, 맛이, 맛, 조미유, 향]\n",
       "4     5  [짜파게티, 맛, 맛이, 얼얼, 생각]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rate_merge_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zin\\AppData\\Local\\Temp\\ipykernel_20828\\1944135166.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['soynlp_keywords'] = soynlp_results\n"
     ]
    }
   ],
   "source": [
    "# 3. 각 리뷰별로 처리\n",
    "individual_df = df_sumWordSentence_soynlp_LR(df, review_col='preprocessed_review', top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>이름</th>\n",
       "      <th>작성일자</th>\n",
       "      <th>평점</th>\n",
       "      <th>리뷰 내용</th>\n",
       "      <th>맛 만족도</th>\n",
       "      <th>preprocessed_review</th>\n",
       "      <th>krwordrank</th>\n",
       "      <th>soynlp_keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>박*혜</td>\n",
       "      <td>2025.01.14</td>\n",
       "      <td>5</td>\n",
       "      <td>짜파게티 마라, 어떤 제품일까?먼저 짜파게티 마라의 기본 정보를 알아보았어요. 이 ...</td>\n",
       "      <td>아주 넉넉해요</td>\n",
       "      <td>짜파게티 마라 어떤 제품 일까먼저 짜파게티 마라 기본 정보를 알아보았어요 제품 유명...</td>\n",
       "      <td>[마라, 제품, 있어, 정말, 느낀]</td>\n",
       "      <td>[맛, 저, 간편, 느낌, 점]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dimss</td>\n",
       "      <td>2025.01.13</td>\n",
       "      <td>4</td>\n",
       "      <td>안녕하세요!! 리뷰하는 dimss입니다^^오늘도 솔직 사용후기 들고 왔어요❤️⬇️⬇...</td>\n",
       "      <td>적당히 남았어요</td>\n",
       "      <td>안녕하세요 리뷰 하는 입니다 오늘도 솔직 사용후기 들고 왔어요짜파게티 마라 솔직 후...</td>\n",
       "      <td>None</td>\n",
       "      <td>[추, 보]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>이*람</td>\n",
       "      <td>2025.01.12</td>\n",
       "      <td>5</td>\n",
       "      <td>### 구매 계기매운 음식을 좋아하는 저는 최근 마라탕이나 마라샹궈와 같은 마라 요...</td>\n",
       "      <td>적당히 남았어요</td>\n",
       "      <td>구매 계기매운 음식 좋아 하는 저는 최근 마라 탕이나 마라 샹궈와 같은 마라 요리 ...</td>\n",
       "      <td>[마라, 했습니다, 짜파게티, 정말, 국물]</td>\n",
       "      <td>[맛, 점, 끓, 밥, 사용]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>시마에나가</td>\n",
       "      <td>2025.01.11</td>\n",
       "      <td>4</td>\n",
       "      <td>⏹️ 요약 ⏹️✅ 구성 - 면, 후레이크, 짜장스프, 마라조미유✅ 맛 - 맵찔이 먹...</td>\n",
       "      <td>적당히 남았어요</td>\n",
       "      <td>요약 구성 후레이크 짜장스프 마라 조미유 맵찔이 먹으면 안됨 그냥 매운 마라 구매 ...</td>\n",
       "      <td>None</td>\n",
       "      <td>[맛, 조미유, 면, 강, 추]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>김*수</td>\n",
       "      <td>2025.01.11</td>\n",
       "      <td>5</td>\n",
       "      <td>짜파게티 마라를 구매한 후기를 이모티콘을 활용하여 작성해 보겠습니다. 아래와 같은 ...</td>\n",
       "      <td>아주 넉넉해요</td>\n",
       "      <td>짜파게티 마라 구매 후기 이모티콘을 활용 하여 작성해 보겠습니다 아래와 같은 방식 ...</td>\n",
       "      <td>[마라, 매운, 맛이, 조금, 하는]</td>\n",
       "      <td>[맛, 사람, 강, 작성, 면]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      이름        작성일자  평점                                              리뷰 내용  \\\n",
       "0    박*혜  2025.01.14   5  짜파게티 마라, 어떤 제품일까?먼저 짜파게티 마라의 기본 정보를 알아보았어요. 이 ...   \n",
       "1  dimss  2025.01.13   4  안녕하세요!! 리뷰하는 dimss입니다^^오늘도 솔직 사용후기 들고 왔어요❤️⬇️⬇...   \n",
       "2    이*람  2025.01.12   5  ### 구매 계기매운 음식을 좋아하는 저는 최근 마라탕이나 마라샹궈와 같은 마라 요...   \n",
       "3  시마에나가  2025.01.11   4  ⏹️ 요약 ⏹️✅ 구성 - 면, 후레이크, 짜장스프, 마라조미유✅ 맛 - 맵찔이 먹...   \n",
       "4    김*수  2025.01.11   5  짜파게티 마라를 구매한 후기를 이모티콘을 활용하여 작성해 보겠습니다. 아래와 같은 ...   \n",
       "\n",
       "      맛 만족도                                preprocessed_review  \\\n",
       "0   아주 넉넉해요  짜파게티 마라 어떤 제품 일까먼저 짜파게티 마라 기본 정보를 알아보았어요 제품 유명...   \n",
       "1  적당히 남았어요  안녕하세요 리뷰 하는 입니다 오늘도 솔직 사용후기 들고 왔어요짜파게티 마라 솔직 후...   \n",
       "2  적당히 남았어요  구매 계기매운 음식 좋아 하는 저는 최근 마라 탕이나 마라 샹궈와 같은 마라 요리 ...   \n",
       "3  적당히 남았어요  요약 구성 후레이크 짜장스프 마라 조미유 맵찔이 먹으면 안됨 그냥 매운 마라 구매 ...   \n",
       "4   아주 넉넉해요  짜파게티 마라 구매 후기 이모티콘을 활용 하여 작성해 보겠습니다 아래와 같은 방식 ...   \n",
       "\n",
       "                 krwordrank    soynlp_keywords  \n",
       "0      [마라, 제품, 있어, 정말, 느낀]  [맛, 저, 간편, 느낌, 점]  \n",
       "1                      None             [추, 보]  \n",
       "2  [마라, 했습니다, 짜파게티, 정말, 국물]   [맛, 점, 끓, 밥, 사용]  \n",
       "3                      None  [맛, 조미유, 면, 강, 추]  \n",
       "4      [마라, 매운, 맛이, 조금, 하는]  [맛, 사람, 강, 작성, 면]  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "individual_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 별첨: KEYBERT 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keybert import KeyBERT\n",
    "# import pandas as pd\n",
    "\n",
    "# # KeyBERT 모델 초기화\n",
    "# kw_model = KeyBERT()\n",
    "\n",
    "# def df_keybert_keywords(df, review_col, rate_col=None, filter=None, top_k=5, full_merge=False, rate_merge=False):\n",
    "#     \"\"\"\n",
    "#     데이터프레임에서 KeyBERT를 사용해 키워드 추출 결과를 데이터프레임에 저장.\n",
    "\n",
    "#     Parameters:\n",
    "#     - df: pd.DataFrame - 입력 데이터프레임\n",
    "#     - review_col: str - 리뷰 내용을 포함하는 열 이름\n",
    "#     - rate_col: str - 평점 열의 이름 (rate_merge=True인 경우 필요)\n",
    "#     - filter: list[str] - 필터링할 단어 목록\n",
    "#     - top_k: int - 각 리뷰별 상위 키워드 개수\n",
    "#     - full_merge: bool - True일 경우 모든 리뷰를 합쳐서 처리\n",
    "#     - rate_merge: bool - True일 경우 평점별로 리뷰를 합쳐서 처리\n",
    "\n",
    "#     Returns:\n",
    "#     - result_df: pd.DataFrame - 키워드 열이 추가된 데이터프레임\n",
    "#     \"\"\"\n",
    "#     def extract_keywords(text, top_k):\n",
    "#         keywords = kw_model.extract_keywords(text, keyphrase_ngram_range=(2, 4), use_mmr= True, use_maxsum=True, top_n=top_k, diversity=0.3)\n",
    "#         return [keyword for keyword, score in keywords]\n",
    "\n",
    "\n",
    "#     if full_merge:\n",
    "#         # 모든 리뷰를 하나로 합쳐 처리\n",
    "#         merged_reviews = ' '.join(df[review_col].dropna())\n",
    "#         keywords = extract_keywords(merged_reviews, top_k)\n",
    "#         result_df = pd.DataFrame({'merge_type': ['full'], 'keywords': [keywords]})\n",
    "#         return result_df\n",
    "\n",
    "#     if rate_merge:\n",
    "#         # 평점별로 리뷰를 합쳐 처리\n",
    "#         if rate_col is None:\n",
    "#             raise ValueError(\"rate_merge=True 인 경우, rate_col을 지정해야 합니다.\")\n",
    "        \n",
    "#         rate_keywords = []\n",
    "#         for rate, group in df.groupby(rate_col):\n",
    "#             merged_reviews = ' '.join(group[review_col].dropna())\n",
    "#             keywords = extract_keywords(merged_reviews, top_k)\n",
    "#             rate_keywords.append({'rate': rate, 'keywords': keywords})\n",
    "        \n",
    "#         result_df = pd.DataFrame(rate_keywords)\n",
    "#         return result_df\n",
    "#     else: \n",
    "#         # 기본: 각 리뷰별 처리\n",
    "#         krwordrank_results = []\n",
    "#         for idx, row in df.iterrows():\n",
    "#             review_content = row[review_col]\n",
    "#             if pd.isna(review_content):\n",
    "#                 krwordrank_results.append(None)\n",
    "#                 continue\n",
    "            \n",
    "#             # 필터링 처리\n",
    "#             if filter:\n",
    "#                 for word in filter:\n",
    "#                     review_content = review_content.replace(word, '')\n",
    "            \n",
    "#             # 키워드 추출\n",
    "#             keywords = extract_keywords(review_content, top_k)\n",
    "#             krwordrank_results.append(keywords)\n",
    "\n",
    "#         # 새로운 열 추가\n",
    "#         df['keybert_keywords'] = krwordrank_results\n",
    "#         return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 1. 전체 리뷰를 합쳐 키워드 추출\n",
    "# full_merge_df = df_keybert_keywords(df, review_col='전처리된_리뷰', full_merge=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "시간이 5분정도 걸림, 너무 오래걸리지 않나..? 싶음 결과는 잘 나오는듯 다만 이상한 키워드도 많이 나옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>merge_type</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>full</td>\n",
       "      <td>[마라, 매운, 좋아, 맛이, 맛있, 구매, 짜파, 먹어, 조금, 생각]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  merge_type                                  keywords\n",
       "0       full  [마라, 매운, 좋아, 맛이, 맛있, 구매, 짜파, 먹어, 조금, 생각]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_merge_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 2. 평점별로 리뷰를 묶어서 키워드 추출\n",
    "# rate_merge_df = df_keybert_keywords(df, review_col='전처리된_리뷰', rate_col='평점', rate_merge=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rate</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[얼얼]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[맛, 강, 액상소스, 침샘, 폭발]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[맛, 정도, 느낌, 구매, 볶음면]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[짜파게티, 맛이, 맛, 조미유, 향]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[짜파게티, 맛, 맛이, 얼얼, 생각]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rate               keywords\n",
       "0     1                   [얼얼]\n",
       "1     2   [맛, 강, 액상소스, 침샘, 폭발]\n",
       "2     3   [맛, 정도, 느낌, 구매, 볶음면]\n",
       "3     4  [짜파게티, 맛이, 맛, 조미유, 향]\n",
       "4     5  [짜파게티, 맛, 맛이, 얼얼, 생각]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rate_merge_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 3. 각 리뷰별로 처리\n",
    "# individual_df = df_keybert_keywords(df, review_col='전처리된_리뷰', top_k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>이름</th>\n",
       "      <th>작성일자</th>\n",
       "      <th>평점</th>\n",
       "      <th>리뷰 내용</th>\n",
       "      <th>맛 만족도</th>\n",
       "      <th>preprocessed_review</th>\n",
       "      <th>krwordrank</th>\n",
       "      <th>soynlp_keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>박*혜</td>\n",
       "      <td>2025.01.14</td>\n",
       "      <td>5</td>\n",
       "      <td>짜파게티 마라, 어떤 제품일까?먼저 짜파게티 마라의 기본 정보를 알아보았어요. 이 ...</td>\n",
       "      <td>아주 넉넉해요</td>\n",
       "      <td>짜파게티 마라 어떤 제품 일까먼저 짜파게티 마라 기본 정보를 알아보았어요 제품 유명...</td>\n",
       "      <td>[마라, 제품, 있어, 정말, 느낀]</td>\n",
       "      <td>[맛, 저, 간편, 느낌, 점]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dimss</td>\n",
       "      <td>2025.01.13</td>\n",
       "      <td>4</td>\n",
       "      <td>안녕하세요!! 리뷰하는 dimss입니다^^오늘도 솔직 사용후기 들고 왔어요❤️⬇️⬇...</td>\n",
       "      <td>적당히 남았어요</td>\n",
       "      <td>안녕하세요 리뷰 하는 입니다 오늘도 솔직 사용후기 들고 왔어요짜파게티 마라 솔직 후...</td>\n",
       "      <td>None</td>\n",
       "      <td>[추, 보]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>이*람</td>\n",
       "      <td>2025.01.12</td>\n",
       "      <td>5</td>\n",
       "      <td>### 구매 계기매운 음식을 좋아하는 저는 최근 마라탕이나 마라샹궈와 같은 마라 요...</td>\n",
       "      <td>적당히 남았어요</td>\n",
       "      <td>구매 계기매운 음식 좋아 하는 저는 최근 마라 탕이나 마라 샹궈와 같은 마라 요리 ...</td>\n",
       "      <td>[마라, 했습니다, 짜파게티, 정말, 국물]</td>\n",
       "      <td>[맛, 점, 끓, 밥, 사용]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>시마에나가</td>\n",
       "      <td>2025.01.11</td>\n",
       "      <td>4</td>\n",
       "      <td>⏹️ 요약 ⏹️✅ 구성 - 면, 후레이크, 짜장스프, 마라조미유✅ 맛 - 맵찔이 먹...</td>\n",
       "      <td>적당히 남았어요</td>\n",
       "      <td>요약 구성 후레이크 짜장스프 마라 조미유 맵찔이 먹으면 안됨 그냥 매운 마라 구매 ...</td>\n",
       "      <td>None</td>\n",
       "      <td>[맛, 조미유, 면, 강, 추]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>김*수</td>\n",
       "      <td>2025.01.11</td>\n",
       "      <td>5</td>\n",
       "      <td>짜파게티 마라를 구매한 후기를 이모티콘을 활용하여 작성해 보겠습니다. 아래와 같은 ...</td>\n",
       "      <td>아주 넉넉해요</td>\n",
       "      <td>짜파게티 마라 구매 후기 이모티콘을 활용 하여 작성해 보겠습니다 아래와 같은 방식 ...</td>\n",
       "      <td>[마라, 매운, 맛이, 조금, 하는]</td>\n",
       "      <td>[맛, 사람, 강, 작성, 면]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>잔잔다에</td>\n",
       "      <td>2025.01.01</td>\n",
       "      <td>1</td>\n",
       "      <td>처음 입에 넣을 때 거부감 드는 향과 뒤에 매운 맛만 느껴짐참고서라도 먹고싶지 않은 맛</td>\n",
       "      <td>맛 평가 없음</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>코만도x</td>\n",
       "      <td>2025.01.10</td>\n",
       "      <td>1</td>\n",
       "      <td>맛과 어울리지도 않게 맵기만함고급스러운 매운맛이 아니고 싼매운맛. 유통기한 끝나가는...</td>\n",
       "      <td>적당히 남았어요</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>sssgg</td>\n",
       "      <td>2025.01.04</td>\n",
       "      <td>1</td>\n",
       "      <td>마라향이 뭔가 조화롭지않아서 좀 인위적인?느낌의 향만나고우선 진짜 너무 맵기만해요</td>\n",
       "      <td>적당히 남았어요</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>쿠리사</td>\n",
       "      <td>2025.01.13</td>\n",
       "      <td>1</td>\n",
       "      <td>짜파게티도 맛있고 블랙도 맛있는데이건 영.....마라향이 확 나는게 아니라서 이상함...</td>\n",
       "      <td>아주 넉넉해요</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>rtrtrt</td>\n",
       "      <td>2025.01.07</td>\n",
       "      <td>1</td>\n",
       "      <td>마라의 얼얼함이 아니라 그냥 캡사이신의 매움입니다;</td>\n",
       "      <td>아주 넉넉해요</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>264 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         이름        작성일자  평점  \\\n",
       "0       박*혜  2025.01.14   5   \n",
       "1     dimss  2025.01.13   4   \n",
       "2       이*람  2025.01.12   5   \n",
       "3     시마에나가  2025.01.11   4   \n",
       "4       김*수  2025.01.11   5   \n",
       "..      ...         ...  ..   \n",
       "283    잔잔다에  2025.01.01   1   \n",
       "284    코만도x  2025.01.10   1   \n",
       "285   sssgg  2025.01.04   1   \n",
       "286     쿠리사  2025.01.13   1   \n",
       "287  rtrtrt  2025.01.07   1   \n",
       "\n",
       "                                                 리뷰 내용     맛 만족도  \\\n",
       "0    짜파게티 마라, 어떤 제품일까?먼저 짜파게티 마라의 기본 정보를 알아보았어요. 이 ...   아주 넉넉해요   \n",
       "1    안녕하세요!! 리뷰하는 dimss입니다^^오늘도 솔직 사용후기 들고 왔어요❤️⬇️⬇...  적당히 남았어요   \n",
       "2    ### 구매 계기매운 음식을 좋아하는 저는 최근 마라탕이나 마라샹궈와 같은 마라 요...  적당히 남았어요   \n",
       "3    ⏹️ 요약 ⏹️✅ 구성 - 면, 후레이크, 짜장스프, 마라조미유✅ 맛 - 맵찔이 먹...  적당히 남았어요   \n",
       "4    짜파게티 마라를 구매한 후기를 이모티콘을 활용하여 작성해 보겠습니다. 아래와 같은 ...   아주 넉넉해요   \n",
       "..                                                 ...       ...   \n",
       "283   처음 입에 넣을 때 거부감 드는 향과 뒤에 매운 맛만 느껴짐참고서라도 먹고싶지 않은 맛   맛 평가 없음   \n",
       "284  맛과 어울리지도 않게 맵기만함고급스러운 매운맛이 아니고 싼매운맛. 유통기한 끝나가는...  적당히 남았어요   \n",
       "285      마라향이 뭔가 조화롭지않아서 좀 인위적인?느낌의 향만나고우선 진짜 너무 맵기만해요  적당히 남았어요   \n",
       "286  짜파게티도 맛있고 블랙도 맛있는데이건 영.....마라향이 확 나는게 아니라서 이상함...   아주 넉넉해요   \n",
       "287                       마라의 얼얼함이 아니라 그냥 캡사이신의 매움입니다;   아주 넉넉해요   \n",
       "\n",
       "                                   preprocessed_review  \\\n",
       "0    짜파게티 마라 어떤 제품 일까먼저 짜파게티 마라 기본 정보를 알아보았어요 제품 유명...   \n",
       "1    안녕하세요 리뷰 하는 입니다 오늘도 솔직 사용후기 들고 왔어요짜파게티 마라 솔직 후...   \n",
       "2    구매 계기매운 음식 좋아 하는 저는 최근 마라 탕이나 마라 샹궈와 같은 마라 요리 ...   \n",
       "3    요약 구성 후레이크 짜장스프 마라 조미유 맵찔이 먹으면 안됨 그냥 매운 마라 구매 ...   \n",
       "4    짜파게티 마라 구매 후기 이모티콘을 활용 하여 작성해 보겠습니다 아래와 같은 방식 ...   \n",
       "..                                                 ...   \n",
       "283                                                NaN   \n",
       "284                                                NaN   \n",
       "285                                                NaN   \n",
       "286                                                NaN   \n",
       "287                                                NaN   \n",
       "\n",
       "                   krwordrank    soynlp_keywords  \n",
       "0        [마라, 제품, 있어, 정말, 느낀]  [맛, 저, 간편, 느낌, 점]  \n",
       "1                        None             [추, 보]  \n",
       "2    [마라, 했습니다, 짜파게티, 정말, 국물]   [맛, 점, 끓, 밥, 사용]  \n",
       "3                        None  [맛, 조미유, 면, 강, 추]  \n",
       "4        [마라, 매운, 맛이, 조금, 하는]  [맛, 사람, 강, 작성, 면]  \n",
       "..                        ...                ...  \n",
       "283                      None               None  \n",
       "284                      None               None  \n",
       "285                      None               None  \n",
       "286                      None               None  \n",
       "287                      None               None  \n",
       "\n",
       "[264 rows x 8 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "individual_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coreview",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
