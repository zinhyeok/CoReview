{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import sys\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= pd.read_csv(\"../data/zapa_total.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 필터링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "등록된 리뷰내용이 있는 것만 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filtered_df = df[df[\"리뷰 내용\"] != \"등록된 리뷰내용이 없습니다\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = filtered_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "불용어 제거 & 특수문자 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Kkma #형태소 분석기\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "kkma = Kkma()\n",
    "okt = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training was done. used memory 0.244 Gby 0.233 Gb\n",
      "all cohesion probabilities was computed. # words = 1622\n",
      "all branching entropies was computed # words = 3061\n",
      "all accessor variety was computed # words = 3061\n"
     ]
    }
   ],
   "source": [
    "from soynlp.word import WordExtractor\n",
    "\n",
    "\n",
    "# WordExtractor를 사용하여 scores 생성\n",
    "word_extractor = WordExtractor()\n",
    "word_extractor.train(df['리뷰 내용'].tolist())\n",
    "word_scores = word_extractor.extract()\n",
    "\n",
    "# scores 사전 생성\n",
    "scores = {word: score.cohesion_forward for word, score in word_scores.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from soynlp.tokenizer import LTokenizer\n",
    "# LTokenizer 초기화\n",
    "ltokenizer = LTokenizer(scores=scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 불용어 리스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_lst = ['등록된', '리뷰', '조금', '수', '것', '없습니다', '도움이', '정말', '살짝', '또', '너무', '잘', '같아요', '엄청',  '바로', '한', '계속', '구매', '넣고', '먹기', '있어서', '다', '넘', '저는', '그냥', '맛이', '좋아요', \n",
    "                '아주', '펜슬', '좀', '좋고', '진짜', '완전', '있는', '때', '프로타주', '이', '좋아하는', '더', '좋은', '있습니다', '입니다', \n",
    "                '같아요', '있어', '좋은', '같습니다', '좋네요', '입니다', '있어요', '괜찮', '아니', '그런',\n",
    "                '같아', '좋습니다', '좋을', '있는데', '없어', '아니라', '좋은', '같은', '없는', '어요', '좋아', '좋앗', '입니', '있고', '없고',\n",
    "                '좋았', '좋습니', '생각',  '있을', '있습니', '있었', '아닌', '같습니', '습니', '니다', '정도', '쿠팡']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sys.path.append(os.path.dirname('PyKoSpacing/'))\n",
    "\n",
    "# spacing = Spacing()  # Spacing 객체 초기화\n",
    "# pip install git+https://github.com/haven-jeon/PyKoSpacing.git\n",
    "\n",
    "\n",
    "def preprocessing(df, review_column, istokenize=True, pos_tags=None, filter=None):\n",
    "    \"\"\"\n",
    "    리뷰 데이터 전처리 함수.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): 입력 데이터프레임.\n",
    "        review_column (str): 리뷰 내용이 있는 열의 이름.\n",
    "        pos_tags (list[str]): 추출할 품사 태그 리스트 (예: ['Noun', 'Adjective']).\n",
    "        istokenize (bool): True일 경우 토큰화 사용, False일 경우 원문을 그대로 처리.\n",
    "        filter (str): 제거할 단어 리스트 (옵션).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: 전처리된 결과를 추가한 데이터프레임.\n",
    "    \"\"\"\n",
    "    #spaceing 객체 정의 및 초기화\n",
    "    # spacing = Spacing()\n",
    "    processed_reviews  = []\n",
    "    #인풋리뷰\n",
    "    for idx, r in enumerate(df[review_column]):\n",
    "        #하나의 리뷰에서 문장 단위로 자르기\n",
    "        #불필요한 정보제거 name의 각 단어를 review에서 제거 \n",
    "        # 이름이 주어졌을 경우에만 이름 정보 제거\n",
    "        sentence = r\n",
    "\n",
    "        # #spacing 적용 \n",
    "        # sentence = sentence.replace(\" \", '')\n",
    "        \n",
    "        # sentence = spacing(sentence) \n",
    "\n",
    "        #특수문자, 영어 알파벳, 초성/중성/종성(예: \"ㄱ\", \"ㅏ\" 등)을 제거.\n",
    "        sentence = re.sub('\\n','',sentence)\n",
    "        sentence = re.sub('\\u200b','',sentence)\n",
    "        sentence = re.sub('\\xa0','',sentence)\n",
    "        sentence = re.sub('([a-zA-Z])','',sentence)\n",
    "        sentence = re.sub('[ㄱ-ㅎㅏ-ㅣ]+','',sentence)\n",
    "        sentence = re.sub('[-=+,#/\\?:^$.@*\\\"※~&%ㆍ!』\\\\‘|\\(\\)\\[\\]\\<\\>`\\'…》]','',sentence)\n",
    "        sentence = re.sub(r'\\s+', ' ', sentence)  # 다중 공백 -> 단일 공백\n",
    "        sentence = re.sub(r'[^\\w\\s]', '', sentence)  # 특수문자 제거\n",
    "        sentence = re.sub(r'\\d+', '', sentence)  # 숫자 제거\n",
    "        #전처리 후 문장이 비어있으면 다음 리뷰로 넘어감 \n",
    "        if len(sentence) == 0:\n",
    "            continue\n",
    "        \n",
    "        # 토큰화 여부 확인\n",
    "        if istokenize:\n",
    "            tokens = ltokenizer.tokenize(sentence)  # LTokenizer를 이용한 토큰화\n",
    "        else:\n",
    "            tokens = [sentence]  # 토큰화하지 않고 원문 사용\n",
    "        \n",
    "        # 불용어 필터링\n",
    "        if filter:\n",
    "            tokens = [token for token in tokens if token not in filter]\n",
    "        # 품사 필터링\n",
    "        if pos_tags:\n",
    "            filtered_tokens = []\n",
    "            for token in tokens:\n",
    "                pos = okt.pos(token, norm=True, stem=False)  # 품사 태깅\n",
    "                filtered_tokens += [word for word, tag in pos if tag in pos_tags]\n",
    "\n",
    "        else:\n",
    "            filtered_tokens = tokens\n",
    "\n",
    "\n",
    "        # 길이가 1인 단어 제거\n",
    "        filtered_tokens = [token for token in filtered_tokens if len(token) > 1]\n",
    "\n",
    "        # 토큰을 공백으로 연결하고 마침표 추가\n",
    "        processed_sentence = ' '.join(filtered_tokens)\n",
    "        processed_reviews.append(processed_sentence)\n",
    "        \n",
    "    return pd.Series(processed_reviews)  # 시리즈 형태로 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zin\\AppData\\Local\\Temp\\ipykernel_29208\\2540016584.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['preprocessed_review'] = preprocessing(\n"
     ]
    }
   ],
   "source": [
    "df['preprocessed_review'] = preprocessing(\n",
    "    df, \n",
    "    review_column='리뷰 내용', \n",
    "    istokenize=False # 토큰화 미사용\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "특정 단어 제거(이벤트, 체험단 등)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def remove_rows_with_keywords(dataframe, column_name, keywords):\n",
    "#     \"\"\"\n",
    "#     특정 단어가 포함된 문장을 제거하는 함수.\n",
    "\n",
    "#     Args:\n",
    "#         dataframe (pd.DataFrame): 데이터프레임\n",
    "#         column_name (str): 처리할 열 이름\n",
    "#         keywords (list): 제거할 단어 리스트\n",
    "\n",
    "#     Returns:\n",
    "#         pd.DataFrame: 특정 단어가 포함된 행이 제거된 데이터프레임\n",
    "#     \"\"\"\n",
    "#     # 특정 단어가 포함된 행 제거\n",
    "#     pattern = \"|\".join(keywords)  # 키워드 리스트를 정규식 패턴으로 변환\n",
    "#     filtered_df = dataframe[~dataframe[column_name].str.contains(pattern, na=False)]\n",
    "#     return filtered_df\n",
    "\n",
    "# # 사용 예시\n",
    "# keywords = [\"이벤트\", \"체험단\"]\n",
    "# filtered_data_oranda = remove_rows_with_keywords(data_oranda, \"리뷰 내용\", keywords)\n",
    "\n",
    "# # 결과 확인\n",
    "# print(filtered_data_oranda)\n",
    "# len(filtered_data_oranda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 키워드 뽑기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model1: summarize_with_sentences / KR-WordRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from krwordrank.sentence import summarize_with_sentences\n",
    "\n",
    "def df_sumWordSentence(df, review_col, rate_col=None, stopwords=None, top_k=5, num_keywords=5, num_keysents=2, full_merge=False, rate_merge=False):\n",
    "    \"\"\"\n",
    "    데이터프레임에서 특정 열을 전처리하고 키워드 추출 결과를 데이터프레임에 저장.\n",
    "\n",
    "    Parameters:\n",
    "    - df: pd.DataFrame - 입력 데이터프레임\n",
    "    - review_col: str - 리뷰 내용을 포함하는 열 이름\n",
    "    - rate_col: str - 평점 열의 이름 (rate_merge=True인 경우 필요)\n",
    "    - stopwords: list[str] 불용어어\n",
    "    - top_k: int - 각 리뷰별 상위 키워드 개수\n",
    "    - num_keywords: int - 추출할 키워드 개수\n",
    "    - num_keysents: int - 추출할 중요 문장 개수\n",
    "    - full_merge: bool - True일 경우 모든 리뷰를 합쳐서 처리\n",
    "    - rate_merge: bool - True일 경우 평점별로 리뷰를 합쳐서 처리\n",
    "\n",
    "    Returns:\n",
    "    - result_df: pd.DataFrame - 키워드 열이 추가된 데이터프레임\n",
    "    \"\"\"\n",
    "\n",
    "    if num_keywords < top_k:\n",
    "        num_keywords = top_k\n",
    "        \n",
    "    def extract_keywords(texts, stopwords=None):\n",
    "        try:\n",
    "            keywords, _ = summarize_with_sentences(\n",
    "                texts,\n",
    "                stopwords=stopwords,\n",
    "                num_keywords=num_keywords,\n",
    "                num_keysents=num_keysents\n",
    "            )\n",
    "            top_keywords = sorted(keywords.items(), key=lambda x: x[1], reverse=True)[:top_k]\n",
    "            return [word for word, _ in top_keywords]\n",
    "        except ValueError:\n",
    "            return None\n",
    "\n",
    "    if full_merge:\n",
    "        # 모든 리뷰를 하나로 합쳐 처리\n",
    "        merged_reviews = '. '.join(df[review_col].dropna())\n",
    "        texts = merged_reviews.split('. ')\n",
    "        keywords = extract_keywords(texts, stopwords=stopwords)\n",
    "        result_df = pd.DataFrame({'merge_type': ['full'], 'keywords': [keywords]})\n",
    "        return result_df\n",
    "\n",
    "    if rate_merge:\n",
    "        # 평점별로 리뷰를 합쳐 처리\n",
    "        if rate_col is None:\n",
    "            raise ValueError(\"rate_merge=True 인 경우, rate_col을 지정해야 합니다.\")\n",
    "        \n",
    "        rate_keywords = []\n",
    "        for rate, group in df.groupby(rate_col):\n",
    "            merged_reviews = '. '.join(group[review_col].dropna())\n",
    "            texts = merged_reviews.split('. ')\n",
    "            keywords = extract_keywords(texts, stopwords=stopwords)\n",
    "            rate_keywords.append({'rate': rate, 'keywords': keywords})\n",
    "        \n",
    "        result_df = pd.DataFrame(rate_keywords)\n",
    "        return result_df\n",
    "\n",
    "    # 기본: 각 리뷰별 처리\n",
    "    else:\n",
    "        krwordrank_results = []\n",
    "        for idx, row in df.iterrows():\n",
    "            review_content = row[review_col]\n",
    "            if pd.isna(review_content):\n",
    "                krwordrank_results.append(None)\n",
    "                continue\n",
    "            \n",
    "            # 문장 리스트\n",
    "            texts = review_content.split('. ')\n",
    "            keywords = extract_keywords(texts, stopwords=stopwords)\n",
    "            krwordrank_results.append(keywords)\n",
    "\n",
    "        # 새로운 열 추가\n",
    "        df['krwordrank'] = krwordrank_results\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 함수 호출\n",
    "full_merge_df  = df_sumWordSentence(df, review_col='preprocessed_review', stopwords=stopwords_lst, top_k=30, full_merge=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>merge_type</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>full</td>\n",
       "      <td>[마라, 짜파게티, 매운, 얼얼한, 맛있, 맛을, 기존, 라면, 많이, 분들, 사천...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  merge_type                                           keywords\n",
       "0       full  [마라, 짜파게티, 매운, 얼얼한, 맛있, 맛을, 기존, 라면, 많이, 분들, 사천..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_merge_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model2: KR-WordRank / KR-WordRank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "krwordrank beta 옵션 변경 필요(하이퍼파라미터 설정값 정할것)  \n",
    "키워드 개수 조정도 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from krwordrank.word import KRWordRank\n",
    "\n",
    "def df_krwordRank(df, review_col, rate_col=None, stopwords=None, top_k=5, num_keywords=10, min_count=1, max_length=50, full_merge=False, rate_merge=False):\n",
    "    \"\"\"\n",
    "    데이터프레임에서 특정 열을 전처리하고 키워드 추출 결과를 데이터프레임에 저장.\n",
    "\n",
    "    Parameters:\n",
    "    - df: pd.DataFrame - 입력 데이터프레임\n",
    "    - review_col: str - 리뷰 내용을 포함하는 열 이름\n",
    "    - rate_col: str - 평점 열의 이름 (rate_merge=True인 경우 필요)\n",
    "    - stopwords: list[str] 불용어 리스트\n",
    "    - top_k: int - 각 리뷰별 상위 키워드 개수\n",
    "    - num_keywords: int - 추출할 키워드 개수\n",
    "    - min_count: int - 단어 최소 등장 빈도\n",
    "    - max_length: int - 단어 최대 길이\n",
    "    - full_merge: bool - True일 경우 모든 리뷰를 합쳐서 처리\n",
    "    - rate_merge: bool - True일 경우 평점별로 리뷰를 합쳐서 처리\n",
    "\n",
    "    Returns:\n",
    "    - result_df: pd.DataFrame - 키워드 열이 추가된 데이터프레임\n",
    "    \"\"\"\n",
    "    if num_keywords < top_k:\n",
    "        num_keywords = top_k\n",
    "\n",
    "    def extract_keywords(texts, row=None):\n",
    "        if not texts or len(' '.join(texts).strip()) == 0:  # 텍스트가 비어있거나 공백만 포함된 경우\n",
    "            print(\"입력 텍스트가 유효하지 않습니다.\")\n",
    "            return None\n",
    "        \n",
    "        # KRWordRank 모델 초기화\n",
    "        krwordrank = KRWordRank(\n",
    "            min_count=min_count,\n",
    "            max_length=max_length,\n",
    "            verbose=True\n",
    "        )\n",
    "        \n",
    "        try:\n",
    "            result = krwordrank.extract(\n",
    "                texts, \n",
    "                beta=0.85, \n",
    "                max_iter=50, \n",
    "                num_keywords=num_keywords\n",
    "            )\n",
    "            keywords = result[0]\n",
    "\n",
    "            if keywords is None:\n",
    "                print(\"키워드 추출 실패: 결과가 None입니다.\")\n",
    "                return None\n",
    "            \n",
    "            top_keywords = sorted(keywords.items(), key=lambda x: x[1], reverse=True)[:top_k]\n",
    "            return [word for word, _ in top_keywords]\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(str(row) + \" error occurs:\")\n",
    "            print(e)\n",
    "            return None\n",
    "\n",
    "    if full_merge:\n",
    "        # 모든 리뷰를 하나로 합쳐 처리\n",
    "        merged_reviews = '. '.join(df[review_col].dropna())\n",
    "        \n",
    "        # 불용어 제거\n",
    "        if stopwords:\n",
    "            for word in stopwords:\n",
    "                merged_reviews = merged_reviews.replace(word, '')\n",
    "        \n",
    "        texts = merged_reviews.split('. ')\n",
    "        keywords = extract_keywords(texts)\n",
    "        result_df = pd.DataFrame({'merge_type': ['full'], 'keywords': [keywords]})\n",
    "        return result_df\n",
    "\n",
    "    if rate_merge:\n",
    "        # 평점별로 리뷰를 합쳐 처리\n",
    "        if rate_col is None:\n",
    "            raise ValueError(\"rate_merge=True 인 경우, rate_col을 지정해야 합니다.\")\n",
    "        \n",
    "        rate_keywords = []\n",
    "        for rate, group in df.groupby(rate_col):\n",
    "            merged_reviews = '. '.join(group[review_col].dropna())\n",
    "            \n",
    "            # 불용어 제거\n",
    "            if stopwords:\n",
    "                for word in stopwords:\n",
    "                    merged_reviews = merged_reviews.replace(word, '')\n",
    "            \n",
    "            texts = merged_reviews.split('. ')\n",
    "            keywords = extract_keywords(texts)\n",
    "            rate_keywords.append({'rate': rate, 'keywords': keywords})\n",
    "        \n",
    "        result_df = pd.DataFrame(rate_keywords)\n",
    "        return result_df\n",
    "    \n",
    "    else:\n",
    "        # 기본: 각 리뷰별 처리\n",
    "        krwordrank_results = []\n",
    "        for idx, row in df.iterrows():\n",
    "            review_content = row[review_col]\n",
    "\n",
    "            if pd.isna(review_content):\n",
    "                krwordrank_results.append(None)\n",
    "                continue\n",
    "            \n",
    "            # 불용어 제거\n",
    "            if stopwords:\n",
    "                for word in stopwords:\n",
    "                    review_content = review_content.replace(word, '')\n",
    "            \n",
    "            # 문장 리스트\n",
    "            texts = review_content.split('. ')\n",
    "            keywords = extract_keywords(texts, row=idx)\n",
    "            krwordrank_results.append(keywords)\n",
    "\n",
    "        # 새로운 열 추가\n",
    "        df['krwordrank'] = krwordrank_results\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scan vocabs ... \n",
      "num vocabs = 19837\n",
      "done = 12 Early stopped.\n"
     ]
    }
   ],
   "source": [
    "full_merge_df = df_krwordRank(df, review_col='preprocessed_review', stopwords=stopwords_lst, top_k=50, full_merge=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>merge_type</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>full</td>\n",
       "      <td>[마라, 짜파게티, 매운, 얼얼, 느낌, 해서, 맛을, 라면, 먹어, 기존, 들어,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  merge_type                                           keywords\n",
       "0       full  [마라, 짜파게티, 매운, 얼얼, 느낌, 해서, 맛을, 라면, 먹어, 기존, 들어,..."
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_merge_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_merge_df['keywords'].to_csv('col2_output.txt', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 품사 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(len('합'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "okt = Okt()\n",
    "\n",
    "def filter_keywords_by_pos(df, column, pos_tags):\n",
    "    \"\"\"\n",
    "    데이터프레임의 지정 열에서 리스트로 저장된 키워드들에 대해 특정 품사만 남기고, 단어 길이가 1 이하인 단어 제거.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): 입력 데이터프레임\n",
    "        column (str): 키워드가 저장된 열 이름\n",
    "        pos_tags (list[str]): 남길 품사 태그 리스트 (예: ['Noun', 'Adjective'])\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: 품사 필터링이 적용된 결과\n",
    "    \"\"\"\n",
    "    filtered_results = []\n",
    "    df = df.copy()\n",
    "\n",
    "    for keyword_list in df[column]:\n",
    "        if not isinstance(keyword_list, list):\n",
    "            filtered_results.append([])\n",
    "            continue\n",
    "\n",
    "        filtered_keywords = []\n",
    "        for keyword in keyword_list:\n",
    "            # 품사 태깅\n",
    "            pos = okt.pos(keyword)\n",
    "            # 지정한 품사만 필터링\n",
    "            filtered_keywords += [word for word, tag in pos if tag in pos_tags]\n",
    "\n",
    "        # 단어 길이가 1인 단어 제거\n",
    "        filtered_keywords = [word for word in filtered_keywords if len(word) > 1]\n",
    "\n",
    "        # 결과 저장\n",
    "        filtered_results.append(filtered_keywords)\n",
    "\n",
    "    # 데이터프레임에 새로운 열 추가\n",
    "    df[f'{column}_filtered'] = filtered_results\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 명사와 대명사사 남기기\n",
    "pos_tags = ['Noun', 'Pronoun']\n",
    "df_noun = filter_keywords_by_pos(full_merge_df, column='keywords', pos_tags=pos_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>merge_type</th>\n",
       "      <th>keywords</th>\n",
       "      <th>keywords_filtered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>full</td>\n",
       "      <td>[마라, 짜파게티, 매운, 얼얼, 느낌, 해서, 맛을, 라면, 먹어, 기존, 들어,...</td>\n",
       "      <td>[짜파게티, 얼얼, 느낌, 맛, 라면, 기존, 짜장, 사천, 일반, 맵, 특유, 쿠...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  merge_type                                           keywords  \\\n",
       "0       full  [마라, 짜파게티, 매운, 얼얼, 느낌, 해서, 맛을, 라면, 먹어, 기존, 들어,...   \n",
       "\n",
       "                                   keywords_filtered  \n",
       "0  [짜파게티, 얼얼, 느낌, 맛, 라면, 기존, 짜장, 사천, 일반, 맵, 특유, 쿠...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>merge_type</th>\n",
       "      <th>keywords</th>\n",
       "      <th>keywords_filtered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>full</td>\n",
       "      <td>[마라, 짜파게티, 매운, 얼얼, 느낌, 해서, 맛을, 라면, 먹어, 기존, 들어,...</td>\n",
       "      <td>[마라, 매운, 맛있게, 매워, 새로운]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  merge_type                                           keywords  \\\n",
       "0       full  [마라, 짜파게티, 매운, 얼얼, 느낌, 해서, 맛을, 라면, 먹어, 기존, 들어,...   \n",
       "\n",
       "        keywords_filtered  \n",
       "0  [마라, 매운, 맛있게, 매워, 새로운]  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 형용사 남기기\n",
    "pos_tags = ['Adjective']\n",
    "df_adj = filter_keywords_by_pos(full_merge_df, column='keywords', pos_tags=pos_tags)\n",
    "df_adj"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coreview",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
